{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCrWSPV04agL",
        "outputId": "5fdf3e97-7797-40cd-8d8d-971d22507a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/\"Colab Notebooks\"/521153S-3005-final-project.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSzCjhCf4e6D",
        "outputId": "a6a07c14-8654-4098-948a-725d2aec6b1a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Colab_Notebooks/521153S-3005-final-project.zip\n",
            "   creating: DeepDRiD/\n",
            " extracting: DeepDRiD/sample_submission.csv  \n",
            " extracting: DeepDRiD/test.csv       \n",
            "   creating: DeepDRiD/test/\n",
            "   creating: DeepDRiD/test/347/\n",
            " extracting: DeepDRiD/test/347/347_l1.jpg  \n",
            " extracting: DeepDRiD/test/347/347_l2.jpg  \n",
            " extracting: DeepDRiD/test/347/347_r1.jpg  \n",
            " extracting: DeepDRiD/test/347/347_r2.jpg  \n",
            "   creating: DeepDRiD/test/353/\n",
            " extracting: DeepDRiD/test/353/353_l1.jpg  \n",
            " extracting: DeepDRiD/test/353/353_l2.jpg  \n",
            " extracting: DeepDRiD/test/353/353_r1.jpg  \n",
            " extracting: DeepDRiD/test/353/353_r2.jpg  \n",
            "   creating: DeepDRiD/test/354/\n",
            " extracting: DeepDRiD/test/354/354_l1.jpg  \n",
            " extracting: DeepDRiD/test/354/354_l2.jpg  \n",
            " extracting: DeepDRiD/test/354/354_r1.jpg  \n",
            " extracting: DeepDRiD/test/354/354_r2.jpg  \n",
            "   creating: DeepDRiD/test/366/\n",
            " extracting: DeepDRiD/test/366/366_l1.jpg  \n",
            " extracting: DeepDRiD/test/366/366_l2.jpg  \n",
            " extracting: DeepDRiD/test/366/366_r1.jpg  \n",
            " extracting: DeepDRiD/test/366/366_r2.jpg  \n",
            "   creating: DeepDRiD/test/368/\n",
            " extracting: DeepDRiD/test/368/368_l1.jpg  \n",
            " extracting: DeepDRiD/test/368/368_l2.jpg  \n",
            " extracting: DeepDRiD/test/368/368_r1.jpg  \n",
            " extracting: DeepDRiD/test/368/368_r2.jpg  \n",
            "   creating: DeepDRiD/test/371/\n",
            " extracting: DeepDRiD/test/371/371_l1.jpg  \n",
            " extracting: DeepDRiD/test/371/371_l2.jpg  \n",
            " extracting: DeepDRiD/test/371/371_r1.jpg  \n",
            " extracting: DeepDRiD/test/371/371_r2.jpg  \n",
            "   creating: DeepDRiD/test/377/\n",
            " extracting: DeepDRiD/test/377/377_l1.jpg  \n",
            " extracting: DeepDRiD/test/377/377_l2.jpg  \n",
            " extracting: DeepDRiD/test/377/377_r1.jpg  \n",
            " extracting: DeepDRiD/test/377/377_r2.jpg  \n",
            "   creating: DeepDRiD/test/383/\n",
            " extracting: DeepDRiD/test/383/383_l1.jpg  \n",
            " extracting: DeepDRiD/test/383/383_l2.jpg  \n",
            " extracting: DeepDRiD/test/383/383_r1.jpg  \n",
            " extracting: DeepDRiD/test/383/383_r2.jpg  \n",
            "   creating: DeepDRiD/test/384/\n",
            " extracting: DeepDRiD/test/384/384_l1.jpg  \n",
            " extracting: DeepDRiD/test/384/384_l2.jpg  \n",
            " extracting: DeepDRiD/test/384/384_r1.jpg  \n",
            " extracting: DeepDRiD/test/384/384_r2.jpg  \n",
            "   creating: DeepDRiD/test/386/\n",
            " extracting: DeepDRiD/test/386/386_l1.jpg  \n",
            " extracting: DeepDRiD/test/386/386_l2.jpg  \n",
            " extracting: DeepDRiD/test/386/386_r1.jpg  \n",
            " extracting: DeepDRiD/test/386/386_r2.jpg  \n",
            "   creating: DeepDRiD/test/387/\n",
            " extracting: DeepDRiD/test/387/387_l1.jpg  \n",
            " extracting: DeepDRiD/test/387/387_l2.jpg  \n",
            " extracting: DeepDRiD/test/387/387_r1.jpg  \n",
            " extracting: DeepDRiD/test/387/387_r2.jpg  \n",
            "   creating: DeepDRiD/test/389/\n",
            " extracting: DeepDRiD/test/389/389_l1.jpg  \n",
            " extracting: DeepDRiD/test/389/389_l2.jpg  \n",
            " extracting: DeepDRiD/test/389/389_r1.jpg  \n",
            " extracting: DeepDRiD/test/389/389_r2.jpg  \n",
            "   creating: DeepDRiD/test/391/\n",
            " extracting: DeepDRiD/test/391/391_l1.jpg  \n",
            " extracting: DeepDRiD/test/391/391_l2.jpg  \n",
            " extracting: DeepDRiD/test/391/391_r1.jpg  \n",
            " extracting: DeepDRiD/test/391/391_r2.jpg  \n",
            "   creating: DeepDRiD/test/396/\n",
            " extracting: DeepDRiD/test/396/396_l1.jpg  \n",
            " extracting: DeepDRiD/test/396/396_l2.jpg  \n",
            " extracting: DeepDRiD/test/396/396_r1.jpg  \n",
            " extracting: DeepDRiD/test/396/396_r2.jpg  \n",
            "   creating: DeepDRiD/test/398/\n",
            " extracting: DeepDRiD/test/398/398_l1.jpg  \n",
            " extracting: DeepDRiD/test/398/398_l2.jpg  \n",
            " extracting: DeepDRiD/test/398/398_r1.jpg  \n",
            " extracting: DeepDRiD/test/398/398_r2.jpg  \n",
            "   creating: DeepDRiD/test/403/\n",
            " extracting: DeepDRiD/test/403/403_l1.jpg  \n",
            " extracting: DeepDRiD/test/403/403_l2.jpg  \n",
            " extracting: DeepDRiD/test/403/403_r1.jpg  \n",
            " extracting: DeepDRiD/test/403/403_r2.jpg  \n",
            "   creating: DeepDRiD/test/408/\n",
            " extracting: DeepDRiD/test/408/408_l1.jpg  \n",
            " extracting: DeepDRiD/test/408/408_l2.jpg  \n",
            " extracting: DeepDRiD/test/408/408_r1.jpg  \n",
            " extracting: DeepDRiD/test/408/408_r2.jpg  \n",
            "   creating: DeepDRiD/test/409/\n",
            " extracting: DeepDRiD/test/409/409_l1.jpg  \n",
            " extracting: DeepDRiD/test/409/409_l2.jpg  \n",
            " extracting: DeepDRiD/test/409/409_r1.jpg  \n",
            " extracting: DeepDRiD/test/409/409_r2.jpg  \n",
            "   creating: DeepDRiD/test/411/\n",
            " extracting: DeepDRiD/test/411/411_l1.jpg  \n",
            " extracting: DeepDRiD/test/411/411_l2.jpg  \n",
            " extracting: DeepDRiD/test/411/411_r1.jpg  \n",
            " extracting: DeepDRiD/test/411/411_r2.jpg  \n",
            "   creating: DeepDRiD/test/412/\n",
            " extracting: DeepDRiD/test/412/412_l1.jpg  \n",
            " extracting: DeepDRiD/test/412/412_l2.jpg  \n",
            " extracting: DeepDRiD/test/412/412_r1.jpg  \n",
            " extracting: DeepDRiD/test/412/412_r2.jpg  \n",
            "   creating: DeepDRiD/test/417/\n",
            " extracting: DeepDRiD/test/417/417_l1.jpg  \n",
            " extracting: DeepDRiD/test/417/417_l2.jpg  \n",
            " extracting: DeepDRiD/test/417/417_r1.jpg  \n",
            " extracting: DeepDRiD/test/417/417_r2.jpg  \n",
            "   creating: DeepDRiD/test/418/\n",
            " extracting: DeepDRiD/test/418/418_l1.jpg  \n",
            " extracting: DeepDRiD/test/418/418_l2.jpg  \n",
            " extracting: DeepDRiD/test/418/418_r1.jpg  \n",
            " extracting: DeepDRiD/test/418/418_r2.jpg  \n",
            "   creating: DeepDRiD/test/419/\n",
            " extracting: DeepDRiD/test/419/419_l1.jpg  \n",
            " extracting: DeepDRiD/test/419/419_l2.jpg  \n",
            " extracting: DeepDRiD/test/419/419_r1.jpg  \n",
            " extracting: DeepDRiD/test/419/419_r2.jpg  \n",
            "   creating: DeepDRiD/test/420/\n",
            " extracting: DeepDRiD/test/420/420_l1.jpg  \n",
            " extracting: DeepDRiD/test/420/420_l2.jpg  \n",
            " extracting: DeepDRiD/test/420/420_r1.jpg  \n",
            " extracting: DeepDRiD/test/420/420_r2.jpg  \n",
            "   creating: DeepDRiD/test/421/\n",
            " extracting: DeepDRiD/test/421/421_l1.jpg  \n",
            " extracting: DeepDRiD/test/421/421_l2.jpg  \n",
            " extracting: DeepDRiD/test/421/421_r1.jpg  \n",
            " extracting: DeepDRiD/test/421/421_r2.jpg  \n",
            "   creating: DeepDRiD/test/423/\n",
            " extracting: DeepDRiD/test/423/423_l1.jpg  \n",
            " extracting: DeepDRiD/test/423/423_l2.jpg  \n",
            " extracting: DeepDRiD/test/423/423_r1.jpg  \n",
            " extracting: DeepDRiD/test/423/423_r2.jpg  \n",
            "   creating: DeepDRiD/test/424/\n",
            " extracting: DeepDRiD/test/424/424_l1.jpg  \n",
            " extracting: DeepDRiD/test/424/424_l2.jpg  \n",
            " extracting: DeepDRiD/test/424/424_r1.jpg  \n",
            " extracting: DeepDRiD/test/424/424_r2.jpg  \n",
            "   creating: DeepDRiD/test/425/\n",
            " extracting: DeepDRiD/test/425/425_l1.jpg  \n",
            " extracting: DeepDRiD/test/425/425_l2.jpg  \n",
            " extracting: DeepDRiD/test/425/425_r1.jpg  \n",
            " extracting: DeepDRiD/test/425/425_r2.jpg  \n",
            "   creating: DeepDRiD/test/426/\n",
            " extracting: DeepDRiD/test/426/426_l1.jpg  \n",
            " extracting: DeepDRiD/test/426/426_l2.jpg  \n",
            " extracting: DeepDRiD/test/426/426_r1.jpg  \n",
            " extracting: DeepDRiD/test/426/426_r2.jpg  \n",
            "   creating: DeepDRiD/test/427/\n",
            " extracting: DeepDRiD/test/427/427_l1.jpg  \n",
            " extracting: DeepDRiD/test/427/427_l2.jpg  \n",
            " extracting: DeepDRiD/test/427/427_r1.jpg  \n",
            " extracting: DeepDRiD/test/427/427_r2.jpg  \n",
            "   creating: DeepDRiD/test/428/\n",
            " extracting: DeepDRiD/test/428/428_l1.jpg  \n",
            " extracting: DeepDRiD/test/428/428_l2.jpg  \n",
            " extracting: DeepDRiD/test/428/428_r1.jpg  \n",
            " extracting: DeepDRiD/test/428/428_r2.jpg  \n",
            "   creating: DeepDRiD/test/429/\n",
            " extracting: DeepDRiD/test/429/429_l1.jpg  \n",
            " extracting: DeepDRiD/test/429/429_l2.jpg  \n",
            " extracting: DeepDRiD/test/429/429_r1.jpg  \n",
            " extracting: DeepDRiD/test/429/429_r2.jpg  \n",
            "   creating: DeepDRiD/test/432/\n",
            " extracting: DeepDRiD/test/432/432_l1.jpg  \n",
            " extracting: DeepDRiD/test/432/432_l2.jpg  \n",
            " extracting: DeepDRiD/test/432/432_r1.jpg  \n",
            " extracting: DeepDRiD/test/432/432_r2.jpg  \n",
            "   creating: DeepDRiD/test/434/\n",
            " extracting: DeepDRiD/test/434/434_l1.jpg  \n",
            " extracting: DeepDRiD/test/434/434_l2.jpg  \n",
            " extracting: DeepDRiD/test/434/434_r1.jpg  \n",
            " extracting: DeepDRiD/test/434/434_r2.jpg  \n",
            "   creating: DeepDRiD/test/435/\n",
            " extracting: DeepDRiD/test/435/435_l1.jpg  \n",
            " extracting: DeepDRiD/test/435/435_l2.jpg  \n",
            " extracting: DeepDRiD/test/435/435_r1.jpg  \n",
            " extracting: DeepDRiD/test/435/435_r2.jpg  \n",
            "   creating: DeepDRiD/test/436/\n",
            " extracting: DeepDRiD/test/436/436_l1.jpg  \n",
            " extracting: DeepDRiD/test/436/436_l2.jpg  \n",
            " extracting: DeepDRiD/test/436/436_r1.jpg  \n",
            " extracting: DeepDRiD/test/436/436_r2.jpg  \n",
            "   creating: DeepDRiD/test/437/\n",
            " extracting: DeepDRiD/test/437/437_l1.jpg  \n",
            " extracting: DeepDRiD/test/437/437_l2.jpg  \n",
            " extracting: DeepDRiD/test/437/437_r1.jpg  \n",
            " extracting: DeepDRiD/test/437/437_r2.jpg  \n",
            "   creating: DeepDRiD/test/438/\n",
            " extracting: DeepDRiD/test/438/438_l1.jpg  \n",
            " extracting: DeepDRiD/test/438/438_l2.jpg  \n",
            " extracting: DeepDRiD/test/438/438_r1.jpg  \n",
            " extracting: DeepDRiD/test/438/438_r2.jpg  \n",
            "   creating: DeepDRiD/test/439/\n",
            " extracting: DeepDRiD/test/439/439_l1.jpg  \n",
            " extracting: DeepDRiD/test/439/439_l2.jpg  \n",
            " extracting: DeepDRiD/test/439/439_r1.jpg  \n",
            " extracting: DeepDRiD/test/439/439_r2.jpg  \n",
            "   creating: DeepDRiD/test/440/\n",
            " extracting: DeepDRiD/test/440/440_l1.jpg  \n",
            " extracting: DeepDRiD/test/440/440_l2.jpg  \n",
            " extracting: DeepDRiD/test/440/440_r1.jpg  \n",
            " extracting: DeepDRiD/test/440/440_r2.jpg  \n",
            "   creating: DeepDRiD/test/441/\n",
            " extracting: DeepDRiD/test/441/441_l1.jpg  \n",
            " extracting: DeepDRiD/test/441/441_l2.jpg  \n",
            " extracting: DeepDRiD/test/441/441_r1.jpg  \n",
            " extracting: DeepDRiD/test/441/441_r2.jpg  \n",
            "   creating: DeepDRiD/test/442/\n",
            " extracting: DeepDRiD/test/442/442_l1.jpg  \n",
            " extracting: DeepDRiD/test/442/442_l2.jpg  \n",
            " extracting: DeepDRiD/test/442/442_r1.jpg  \n",
            " extracting: DeepDRiD/test/442/442_r2.jpg  \n",
            "   creating: DeepDRiD/test/443/\n",
            " extracting: DeepDRiD/test/443/443_l1.jpg  \n",
            " extracting: DeepDRiD/test/443/443_l2.jpg  \n",
            " extracting: DeepDRiD/test/443/443_r1.jpg  \n",
            " extracting: DeepDRiD/test/443/443_r2.jpg  \n",
            "   creating: DeepDRiD/test/444/\n",
            " extracting: DeepDRiD/test/444/444_l1.jpg  \n",
            " extracting: DeepDRiD/test/444/444_l2.jpg  \n",
            " extracting: DeepDRiD/test/444/444_r1.jpg  \n",
            " extracting: DeepDRiD/test/444/444_r2.jpg  \n",
            "   creating: DeepDRiD/test/445/\n",
            " extracting: DeepDRiD/test/445/445_l1.jpg  \n",
            " extracting: DeepDRiD/test/445/445_l2.jpg  \n",
            " extracting: DeepDRiD/test/445/445_r1.jpg  \n",
            " extracting: DeepDRiD/test/445/445_r2.jpg  \n",
            "   creating: DeepDRiD/test/446/\n",
            " extracting: DeepDRiD/test/446/446_l1.jpg  \n",
            " extracting: DeepDRiD/test/446/446_l2.jpg  \n",
            " extracting: DeepDRiD/test/446/446_r1.jpg  \n",
            " extracting: DeepDRiD/test/446/446_r2.jpg  \n",
            "   creating: DeepDRiD/test/447/\n",
            " extracting: DeepDRiD/test/447/447_l1.jpg  \n",
            " extracting: DeepDRiD/test/447/447_l2.jpg  \n",
            " extracting: DeepDRiD/test/447/447_r1.jpg  \n",
            " extracting: DeepDRiD/test/447/447_r2.jpg  \n",
            "   creating: DeepDRiD/test/448/\n",
            " extracting: DeepDRiD/test/448/448_l1.jpg  \n",
            " extracting: DeepDRiD/test/448/448_l2.jpg  \n",
            " extracting: DeepDRiD/test/448/448_r1.jpg  \n",
            " extracting: DeepDRiD/test/448/448_r2.jpg  \n",
            "   creating: DeepDRiD/test/449/\n",
            " extracting: DeepDRiD/test/449/449_l1.jpg  \n",
            " extracting: DeepDRiD/test/449/449_l2.jpg  \n",
            " extracting: DeepDRiD/test/449/449_r1.jpg  \n",
            " extracting: DeepDRiD/test/449/449_r2.jpg  \n",
            "   creating: DeepDRiD/test/450/\n",
            " extracting: DeepDRiD/test/450/450_l1.jpg  \n",
            " extracting: DeepDRiD/test/450/450_l2.jpg  \n",
            " extracting: DeepDRiD/test/450/450_r1.jpg  \n",
            " extracting: DeepDRiD/test/450/450_r2.jpg  \n",
            "   creating: DeepDRiD/test/451/\n",
            " extracting: DeepDRiD/test/451/451_l1.jpg  \n",
            " extracting: DeepDRiD/test/451/451_l2.jpg  \n",
            " extracting: DeepDRiD/test/451/451_r1.jpg  \n",
            " extracting: DeepDRiD/test/451/451_r2.jpg  \n",
            "   creating: DeepDRiD/test/452/\n",
            " extracting: DeepDRiD/test/452/452_l1.jpg  \n",
            " extracting: DeepDRiD/test/452/452_l2.jpg  \n",
            " extracting: DeepDRiD/test/452/452_r1.jpg  \n",
            " extracting: DeepDRiD/test/452/452_r2.jpg  \n",
            "   creating: DeepDRiD/test/453/\n",
            " extracting: DeepDRiD/test/453/453_l1.jpg  \n",
            " extracting: DeepDRiD/test/453/453_l2.jpg  \n",
            " extracting: DeepDRiD/test/453/453_r1.jpg  \n",
            " extracting: DeepDRiD/test/453/453_r2.jpg  \n",
            "   creating: DeepDRiD/test/454/\n",
            " extracting: DeepDRiD/test/454/454_l1.jpg  \n",
            " extracting: DeepDRiD/test/454/454_l2.jpg  \n",
            " extracting: DeepDRiD/test/454/454_r1.jpg  \n",
            " extracting: DeepDRiD/test/454/454_r2.jpg  \n",
            "   creating: DeepDRiD/test/455/\n",
            " extracting: DeepDRiD/test/455/455_l1.jpg  \n",
            " extracting: DeepDRiD/test/455/455_l2.jpg  \n",
            " extracting: DeepDRiD/test/455/455_r1.jpg  \n",
            " extracting: DeepDRiD/test/455/455_r2.jpg  \n",
            "   creating: DeepDRiD/test/456/\n",
            " extracting: DeepDRiD/test/456/456_l1.jpg  \n",
            " extracting: DeepDRiD/test/456/456_l2.jpg  \n",
            " extracting: DeepDRiD/test/456/456_r1.jpg  \n",
            " extracting: DeepDRiD/test/456/456_r2.jpg  \n",
            "   creating: DeepDRiD/test/457/\n",
            " extracting: DeepDRiD/test/457/457_l1.jpg  \n",
            " extracting: DeepDRiD/test/457/457_l2.jpg  \n",
            " extracting: DeepDRiD/test/457/457_r1.jpg  \n",
            " extracting: DeepDRiD/test/457/457_r2.jpg  \n",
            "   creating: DeepDRiD/test/458/\n",
            " extracting: DeepDRiD/test/458/458_l1.jpg  \n",
            " extracting: DeepDRiD/test/458/458_l2.jpg  \n",
            " extracting: DeepDRiD/test/458/458_r1.jpg  \n",
            " extracting: DeepDRiD/test/458/458_r2.jpg  \n",
            "   creating: DeepDRiD/test/459/\n",
            " extracting: DeepDRiD/test/459/459_l1.jpg  \n",
            " extracting: DeepDRiD/test/459/459_l2.jpg  \n",
            " extracting: DeepDRiD/test/459/459_r1.jpg  \n",
            " extracting: DeepDRiD/test/459/459_r2.jpg  \n",
            "   creating: DeepDRiD/test/460/\n",
            " extracting: DeepDRiD/test/460/460_l1.jpg  \n",
            " extracting: DeepDRiD/test/460/460_l2.jpg  \n",
            " extracting: DeepDRiD/test/460/460_r1.jpg  \n",
            " extracting: DeepDRiD/test/460/460_r2.jpg  \n",
            "   creating: DeepDRiD/test/461/\n",
            " extracting: DeepDRiD/test/461/461_l1.jpg  \n",
            " extracting: DeepDRiD/test/461/461_l2.jpg  \n",
            " extracting: DeepDRiD/test/461/461_r1.jpg  \n",
            " extracting: DeepDRiD/test/461/461_r2.jpg  \n",
            "   creating: DeepDRiD/test/462/\n",
            " extracting: DeepDRiD/test/462/462_l1.jpg  \n",
            " extracting: DeepDRiD/test/462/462_l2.jpg  \n",
            " extracting: DeepDRiD/test/462/462_r1.jpg  \n",
            " extracting: DeepDRiD/test/462/462_r2.jpg  \n",
            "   creating: DeepDRiD/test/463/\n",
            " extracting: DeepDRiD/test/463/463_l1.jpg  \n",
            " extracting: DeepDRiD/test/463/463_l2.jpg  \n",
            " extracting: DeepDRiD/test/463/463_r1.jpg  \n",
            " extracting: DeepDRiD/test/463/463_r2.jpg  \n",
            "   creating: DeepDRiD/test/464/\n",
            " extracting: DeepDRiD/test/464/464_l1.jpg  \n",
            " extracting: DeepDRiD/test/464/464_l2.jpg  \n",
            " extracting: DeepDRiD/test/464/464_r1.jpg  \n",
            " extracting: DeepDRiD/test/464/464_r2.jpg  \n",
            "   creating: DeepDRiD/test/465/\n",
            " extracting: DeepDRiD/test/465/465_l1.jpg  \n",
            " extracting: DeepDRiD/test/465/465_l2.jpg  \n",
            " extracting: DeepDRiD/test/465/465_r1.jpg  \n",
            " extracting: DeepDRiD/test/465/465_r2.jpg  \n",
            "   creating: DeepDRiD/test/466/\n",
            " extracting: DeepDRiD/test/466/466_l1.jpg  \n",
            " extracting: DeepDRiD/test/466/466_l2.jpg  \n",
            " extracting: DeepDRiD/test/466/466_r1.jpg  \n",
            " extracting: DeepDRiD/test/466/466_r2.jpg  \n",
            "   creating: DeepDRiD/test/467/\n",
            " extracting: DeepDRiD/test/467/467_l1.jpg  \n",
            " extracting: DeepDRiD/test/467/467_l2.jpg  \n",
            " extracting: DeepDRiD/test/467/467_r1.jpg  \n",
            " extracting: DeepDRiD/test/467/467_r2.jpg  \n",
            "   creating: DeepDRiD/test/468/\n",
            " extracting: DeepDRiD/test/468/468_l1.jpg  \n",
            " extracting: DeepDRiD/test/468/468_l2.jpg  \n",
            " extracting: DeepDRiD/test/468/468_r1.jpg  \n",
            " extracting: DeepDRiD/test/468/468_r2.jpg  \n",
            "   creating: DeepDRiD/test/469/\n",
            " extracting: DeepDRiD/test/469/469_l1.jpg  \n",
            " extracting: DeepDRiD/test/469/469_l2.jpg  \n",
            " extracting: DeepDRiD/test/469/469_r1.jpg  \n",
            " extracting: DeepDRiD/test/469/469_r2.jpg  \n",
            "   creating: DeepDRiD/test/470/\n",
            " extracting: DeepDRiD/test/470/470_l1.jpg  \n",
            " extracting: DeepDRiD/test/470/470_l2.jpg  \n",
            " extracting: DeepDRiD/test/470/470_r1.jpg  \n",
            " extracting: DeepDRiD/test/470/470_r2.jpg  \n",
            "   creating: DeepDRiD/test/471/\n",
            " extracting: DeepDRiD/test/471/471_l1.jpg  \n",
            " extracting: DeepDRiD/test/471/471_l2.jpg  \n",
            " extracting: DeepDRiD/test/471/471_r1.jpg  \n",
            " extracting: DeepDRiD/test/471/471_r2.jpg  \n",
            "   creating: DeepDRiD/test/472/\n",
            " extracting: DeepDRiD/test/472/472_l1.jpg  \n",
            " extracting: DeepDRiD/test/472/472_l2.jpg  \n",
            " extracting: DeepDRiD/test/472/472_r1.jpg  \n",
            " extracting: DeepDRiD/test/472/472_r2.jpg  \n",
            "   creating: DeepDRiD/test/473/\n",
            " extracting: DeepDRiD/test/473/473_l1.jpg  \n",
            " extracting: DeepDRiD/test/473/473_l2.jpg  \n",
            " extracting: DeepDRiD/test/473/473_r1.jpg  \n",
            " extracting: DeepDRiD/test/473/473_r2.jpg  \n",
            "   creating: DeepDRiD/test/474/\n",
            " extracting: DeepDRiD/test/474/474_l1.jpg  \n",
            " extracting: DeepDRiD/test/474/474_l2.jpg  \n",
            " extracting: DeepDRiD/test/474/474_r1.jpg  \n",
            " extracting: DeepDRiD/test/474/474_r2.jpg  \n",
            "   creating: DeepDRiD/test/475/\n",
            " extracting: DeepDRiD/test/475/475_l1.jpg  \n",
            " extracting: DeepDRiD/test/475/475_l2.jpg  \n",
            " extracting: DeepDRiD/test/475/475_r1.jpg  \n",
            " extracting: DeepDRiD/test/475/475_r2.jpg  \n",
            "   creating: DeepDRiD/test/476/\n",
            " extracting: DeepDRiD/test/476/476_l1.jpg  \n",
            " extracting: DeepDRiD/test/476/476_l2.jpg  \n",
            " extracting: DeepDRiD/test/476/476_r1.jpg  \n",
            " extracting: DeepDRiD/test/476/476_r2.jpg  \n",
            "   creating: DeepDRiD/test/477/\n",
            " extracting: DeepDRiD/test/477/477_l1.jpg  \n",
            " extracting: DeepDRiD/test/477/477_l2.jpg  \n",
            " extracting: DeepDRiD/test/477/477_r1.jpg  \n",
            " extracting: DeepDRiD/test/477/477_r2.jpg  \n",
            "   creating: DeepDRiD/test/478/\n",
            " extracting: DeepDRiD/test/478/478_l1.jpg  \n",
            " extracting: DeepDRiD/test/478/478_l2.jpg  \n",
            " extracting: DeepDRiD/test/478/478_r1.jpg  \n",
            " extracting: DeepDRiD/test/478/478_r2.jpg  \n",
            "   creating: DeepDRiD/test/479/\n",
            " extracting: DeepDRiD/test/479/479_l1.jpg  \n",
            " extracting: DeepDRiD/test/479/479_l2.jpg  \n",
            " extracting: DeepDRiD/test/479/479_r1.jpg  \n",
            " extracting: DeepDRiD/test/479/479_r2.jpg  \n",
            "   creating: DeepDRiD/test/480/\n",
            " extracting: DeepDRiD/test/480/480_l1.jpg  \n",
            " extracting: DeepDRiD/test/480/480_l2.jpg  \n",
            " extracting: DeepDRiD/test/480/480_r1.jpg  \n",
            " extracting: DeepDRiD/test/480/480_r2.jpg  \n",
            "   creating: DeepDRiD/test/481/\n",
            " extracting: DeepDRiD/test/481/481_l1.jpg  \n",
            " extracting: DeepDRiD/test/481/481_l2.jpg  \n",
            " extracting: DeepDRiD/test/481/481_r1.jpg  \n",
            " extracting: DeepDRiD/test/481/481_r2.jpg  \n",
            "   creating: DeepDRiD/test/482/\n",
            " extracting: DeepDRiD/test/482/482_l1.jpg  \n",
            " extracting: DeepDRiD/test/482/482_l2.jpg  \n",
            " extracting: DeepDRiD/test/482/482_r1.jpg  \n",
            " extracting: DeepDRiD/test/482/482_r2.jpg  \n",
            "   creating: DeepDRiD/test/483/\n",
            " extracting: DeepDRiD/test/483/483_l1.jpg  \n",
            " extracting: DeepDRiD/test/483/483_l2.jpg  \n",
            " extracting: DeepDRiD/test/483/483_r1.jpg  \n",
            " extracting: DeepDRiD/test/483/483_r2.jpg  \n",
            "   creating: DeepDRiD/test/484/\n",
            " extracting: DeepDRiD/test/484/484_l1.jpg  \n",
            " extracting: DeepDRiD/test/484/484_l2.jpg  \n",
            " extracting: DeepDRiD/test/484/484_r1.jpg  \n",
            " extracting: DeepDRiD/test/484/484_r2.jpg  \n",
            "   creating: DeepDRiD/test/485/\n",
            " extracting: DeepDRiD/test/485/485_l1.jpg  \n",
            " extracting: DeepDRiD/test/485/485_l2.jpg  \n",
            " extracting: DeepDRiD/test/485/485_r1.jpg  \n",
            " extracting: DeepDRiD/test/485/485_r2.jpg  \n",
            "   creating: DeepDRiD/test/486/\n",
            " extracting: DeepDRiD/test/486/486_l1.jpg  \n",
            " extracting: DeepDRiD/test/486/486_l2.jpg  \n",
            " extracting: DeepDRiD/test/486/486_r1.jpg  \n",
            " extracting: DeepDRiD/test/486/486_r2.jpg  \n",
            "   creating: DeepDRiD/test/487/\n",
            " extracting: DeepDRiD/test/487/487_l1.jpg  \n",
            " extracting: DeepDRiD/test/487/487_l2.jpg  \n",
            " extracting: DeepDRiD/test/487/487_r1.jpg  \n",
            " extracting: DeepDRiD/test/487/487_r2.jpg  \n",
            "   creating: DeepDRiD/test/488/\n",
            " extracting: DeepDRiD/test/488/488_l1.jpg  \n",
            " extracting: DeepDRiD/test/488/488_l2.jpg  \n",
            " extracting: DeepDRiD/test/488/488_r1.jpg  \n",
            " extracting: DeepDRiD/test/488/488_r2.jpg  \n",
            "   creating: DeepDRiD/test/489/\n",
            " extracting: DeepDRiD/test/489/489_l1.jpg  \n",
            " extracting: DeepDRiD/test/489/489_l2.jpg  \n",
            " extracting: DeepDRiD/test/489/489_r1.jpg  \n",
            " extracting: DeepDRiD/test/489/489_r2.jpg  \n",
            "   creating: DeepDRiD/test/490/\n",
            " extracting: DeepDRiD/test/490/490_l1.jpg  \n",
            " extracting: DeepDRiD/test/490/490_l2.jpg  \n",
            " extracting: DeepDRiD/test/490/490_r1.jpg  \n",
            " extracting: DeepDRiD/test/490/490_r2.jpg  \n",
            "   creating: DeepDRiD/test/491/\n",
            " extracting: DeepDRiD/test/491/491_l1.jpg  \n",
            " extracting: DeepDRiD/test/491/491_l2.jpg  \n",
            " extracting: DeepDRiD/test/491/491_r1.jpg  \n",
            " extracting: DeepDRiD/test/491/491_r2.jpg  \n",
            "   creating: DeepDRiD/test/492/\n",
            " extracting: DeepDRiD/test/492/492_l1.jpg  \n",
            " extracting: DeepDRiD/test/492/492_l2.jpg  \n",
            " extracting: DeepDRiD/test/492/492_r1.jpg  \n",
            " extracting: DeepDRiD/test/492/492_r2.jpg  \n",
            "   creating: DeepDRiD/test/493/\n",
            " extracting: DeepDRiD/test/493/493_l1.jpg  \n",
            " extracting: DeepDRiD/test/493/493_l2.jpg  \n",
            " extracting: DeepDRiD/test/493/493_r1.jpg  \n",
            " extracting: DeepDRiD/test/493/493_r2.jpg  \n",
            "   creating: DeepDRiD/test/494/\n",
            " extracting: DeepDRiD/test/494/494_l1.jpg  \n",
            " extracting: DeepDRiD/test/494/494_l2.jpg  \n",
            " extracting: DeepDRiD/test/494/494_r1.jpg  \n",
            " extracting: DeepDRiD/test/494/494_r2.jpg  \n",
            "   creating: DeepDRiD/test/495/\n",
            " extracting: DeepDRiD/test/495/495_l1.jpg  \n",
            " extracting: DeepDRiD/test/495/495_l2.jpg  \n",
            " extracting: DeepDRiD/test/495/495_r1.jpg  \n",
            " extracting: DeepDRiD/test/495/495_r2.jpg  \n",
            "   creating: DeepDRiD/test/496/\n",
            " extracting: DeepDRiD/test/496/496_l1.jpg  \n",
            " extracting: DeepDRiD/test/496/496_l2.jpg  \n",
            " extracting: DeepDRiD/test/496/496_r1.jpg  \n",
            " extracting: DeepDRiD/test/496/496_r2.jpg  \n",
            "   creating: DeepDRiD/test/497/\n",
            " extracting: DeepDRiD/test/497/497_l1.jpg  \n",
            " extracting: DeepDRiD/test/497/497_l2.jpg  \n",
            " extracting: DeepDRiD/test/497/497_r1.jpg  \n",
            " extracting: DeepDRiD/test/497/497_r2.jpg  \n",
            "   creating: DeepDRiD/test/498/\n",
            " extracting: DeepDRiD/test/498/498_l1.jpg  \n",
            " extracting: DeepDRiD/test/498/498_l2.jpg  \n",
            " extracting: DeepDRiD/test/498/498_r1.jpg  \n",
            " extracting: DeepDRiD/test/498/498_r2.jpg  \n",
            "   creating: DeepDRiD/test/499/\n",
            " extracting: DeepDRiD/test/499/499_l1.jpg  \n",
            " extracting: DeepDRiD/test/499/499_l2.jpg  \n",
            " extracting: DeepDRiD/test/499/499_r1.jpg  \n",
            " extracting: DeepDRiD/test/499/499_r2.jpg  \n",
            "   creating: DeepDRiD/test/500/\n",
            " extracting: DeepDRiD/test/500/500_l1.jpg  \n",
            " extracting: DeepDRiD/test/500/500_l2.jpg  \n",
            " extracting: DeepDRiD/test/500/500_r1.jpg  \n",
            " extracting: DeepDRiD/test/500/500_r2.jpg  \n",
            " extracting: DeepDRiD/train.csv      \n",
            "   creating: DeepDRiD/train/\n",
            "   creating: DeepDRiD/train/1/\n",
            " extracting: DeepDRiD/train/1/1_l1.jpg  \n",
            " extracting: DeepDRiD/train/1/1_l2.jpg  \n",
            " extracting: DeepDRiD/train/1/1_r1.jpg  \n",
            " extracting: DeepDRiD/train/1/1_r2.jpg  \n",
            "   creating: DeepDRiD/train/10/\n",
            " extracting: DeepDRiD/train/10/10_l1.jpg  \n",
            " extracting: DeepDRiD/train/10/10_l2.jpg  \n",
            " extracting: DeepDRiD/train/10/10_r1.jpg  \n",
            " extracting: DeepDRiD/train/10/10_r2.jpg  \n",
            "   creating: DeepDRiD/train/100/\n",
            " extracting: DeepDRiD/train/100/100_l1.jpg  \n",
            " extracting: DeepDRiD/train/100/100_l2.jpg  \n",
            " extracting: DeepDRiD/train/100/100_r1.jpg  \n",
            " extracting: DeepDRiD/train/100/100_r2.jpg  \n",
            "   creating: DeepDRiD/train/101/\n",
            " extracting: DeepDRiD/train/101/101_l1.jpg  \n",
            " extracting: DeepDRiD/train/101/101_l2.jpg  \n",
            " extracting: DeepDRiD/train/101/101_r1.jpg  \n",
            " extracting: DeepDRiD/train/101/101_r2.jpg  \n",
            "   creating: DeepDRiD/train/102/\n",
            " extracting: DeepDRiD/train/102/102_l1.jpg  \n",
            " extracting: DeepDRiD/train/102/102_l2.jpg  \n",
            " extracting: DeepDRiD/train/102/102_r1.jpg  \n",
            " extracting: DeepDRiD/train/102/102_r2.jpg  \n",
            "   creating: DeepDRiD/train/103/\n",
            " extracting: DeepDRiD/train/103/103_l1.jpg  \n",
            " extracting: DeepDRiD/train/103/103_l2.jpg  \n",
            " extracting: DeepDRiD/train/103/103_r1.jpg  \n",
            " extracting: DeepDRiD/train/103/103_r2.jpg  \n",
            "   creating: DeepDRiD/train/104/\n",
            " extracting: DeepDRiD/train/104/104_l1.jpg  \n",
            " extracting: DeepDRiD/train/104/104_l2.jpg  \n",
            " extracting: DeepDRiD/train/104/104_r1.jpg  \n",
            " extracting: DeepDRiD/train/104/104_r2.jpg  \n",
            "   creating: DeepDRiD/train/105/\n",
            " extracting: DeepDRiD/train/105/105_l1.jpg  \n",
            " extracting: DeepDRiD/train/105/105_l2.jpg  \n",
            " extracting: DeepDRiD/train/105/105_r1.jpg  \n",
            " extracting: DeepDRiD/train/105/105_r2.jpg  \n",
            "   creating: DeepDRiD/train/106/\n",
            " extracting: DeepDRiD/train/106/106_l1.jpg  \n",
            " extracting: DeepDRiD/train/106/106_l2.jpg  \n",
            " extracting: DeepDRiD/train/106/106_r1.jpg  \n",
            " extracting: DeepDRiD/train/106/106_r2.jpg  \n",
            "   creating: DeepDRiD/train/107/\n",
            " extracting: DeepDRiD/train/107/107_l1.jpg  \n",
            " extracting: DeepDRiD/train/107/107_l2.jpg  \n",
            " extracting: DeepDRiD/train/107/107_r1.jpg  \n",
            " extracting: DeepDRiD/train/107/107_r2.jpg  \n",
            "   creating: DeepDRiD/train/108/\n",
            " extracting: DeepDRiD/train/108/108_l1.jpg  \n",
            " extracting: DeepDRiD/train/108/108_l2.jpg  \n",
            " extracting: DeepDRiD/train/108/108_r1.jpg  \n",
            " extracting: DeepDRiD/train/108/108_r2.jpg  \n",
            "   creating: DeepDRiD/train/109/\n",
            " extracting: DeepDRiD/train/109/109_l1.jpg  \n",
            " extracting: DeepDRiD/train/109/109_l2.jpg  \n",
            " extracting: DeepDRiD/train/109/109_r1.jpg  \n",
            " extracting: DeepDRiD/train/109/109_r2.jpg  \n",
            "   creating: DeepDRiD/train/11/\n",
            " extracting: DeepDRiD/train/11/11_l1.jpg  \n",
            " extracting: DeepDRiD/train/11/11_l2.jpg  \n",
            " extracting: DeepDRiD/train/11/11_r1.jpg  \n",
            " extracting: DeepDRiD/train/11/11_r2.jpg  \n",
            "   creating: DeepDRiD/train/110/\n",
            " extracting: DeepDRiD/train/110/110_l1.jpg  \n",
            " extracting: DeepDRiD/train/110/110_l2.jpg  \n",
            " extracting: DeepDRiD/train/110/110_r1.jpg  \n",
            " extracting: DeepDRiD/train/110/110_r2.jpg  \n",
            "   creating: DeepDRiD/train/111/\n",
            " extracting: DeepDRiD/train/111/111_l1.jpg  \n",
            " extracting: DeepDRiD/train/111/111_l2.jpg  \n",
            " extracting: DeepDRiD/train/111/111_r1.jpg  \n",
            " extracting: DeepDRiD/train/111/111_r2.jpg  \n",
            "   creating: DeepDRiD/train/112/\n",
            " extracting: DeepDRiD/train/112/112_l1.jpg  \n",
            " extracting: DeepDRiD/train/112/112_l2.jpg  \n",
            " extracting: DeepDRiD/train/112/112_r1.jpg  \n",
            " extracting: DeepDRiD/train/112/112_r2.jpg  \n",
            "   creating: DeepDRiD/train/113/\n",
            " extracting: DeepDRiD/train/113/113_l1.jpg  \n",
            " extracting: DeepDRiD/train/113/113_l2.jpg  \n",
            " extracting: DeepDRiD/train/113/113_r1.jpg  \n",
            " extracting: DeepDRiD/train/113/113_r2.jpg  \n",
            "   creating: DeepDRiD/train/114/\n",
            " extracting: DeepDRiD/train/114/114_l1.jpg  \n",
            " extracting: DeepDRiD/train/114/114_l2.jpg  \n",
            " extracting: DeepDRiD/train/114/114_r1.jpg  \n",
            " extracting: DeepDRiD/train/114/114_r2.jpg  \n",
            "   creating: DeepDRiD/train/115/\n",
            " extracting: DeepDRiD/train/115/115_l1.jpg  \n",
            " extracting: DeepDRiD/train/115/115_l2.jpg  \n",
            " extracting: DeepDRiD/train/115/115_r1.jpg  \n",
            " extracting: DeepDRiD/train/115/115_r2.jpg  \n",
            "   creating: DeepDRiD/train/116/\n",
            " extracting: DeepDRiD/train/116/116_l1.jpg  \n",
            " extracting: DeepDRiD/train/116/116_l2.jpg  \n",
            " extracting: DeepDRiD/train/116/116_r1.jpg  \n",
            " extracting: DeepDRiD/train/116/116_r2.jpg  \n",
            "   creating: DeepDRiD/train/117/\n",
            " extracting: DeepDRiD/train/117/117_l1.jpg  \n",
            " extracting: DeepDRiD/train/117/117_l2.jpg  \n",
            " extracting: DeepDRiD/train/117/117_r1.jpg  \n",
            " extracting: DeepDRiD/train/117/117_r2.jpg  \n",
            "   creating: DeepDRiD/train/118/\n",
            " extracting: DeepDRiD/train/118/118_l1.jpg  \n",
            " extracting: DeepDRiD/train/118/118_l2.jpg  \n",
            " extracting: DeepDRiD/train/118/118_r1.jpg  \n",
            " extracting: DeepDRiD/train/118/118_r2.jpg  \n",
            "   creating: DeepDRiD/train/119/\n",
            " extracting: DeepDRiD/train/119/119_l1.jpg  \n",
            " extracting: DeepDRiD/train/119/119_l2.jpg  \n",
            " extracting: DeepDRiD/train/119/119_r1.jpg  \n",
            " extracting: DeepDRiD/train/119/119_r2.jpg  \n",
            "   creating: DeepDRiD/train/12/\n",
            " extracting: DeepDRiD/train/12/12_l1.jpg  \n",
            " extracting: DeepDRiD/train/12/12_l2.jpg  \n",
            " extracting: DeepDRiD/train/12/12_r1.jpg  \n",
            " extracting: DeepDRiD/train/12/12_r2.jpg  \n",
            "   creating: DeepDRiD/train/120/\n",
            " extracting: DeepDRiD/train/120/120_l1.jpg  \n",
            " extracting: DeepDRiD/train/120/120_l2.jpg  \n",
            " extracting: DeepDRiD/train/120/120_r1.jpg  \n",
            " extracting: DeepDRiD/train/120/120_r2.jpg  \n",
            "   creating: DeepDRiD/train/121/\n",
            " extracting: DeepDRiD/train/121/121_l1.jpg  \n",
            " extracting: DeepDRiD/train/121/121_l2.jpg  \n",
            " extracting: DeepDRiD/train/121/121_r1.jpg  \n",
            " extracting: DeepDRiD/train/121/121_r2.jpg  \n",
            "   creating: DeepDRiD/train/122/\n",
            " extracting: DeepDRiD/train/122/122_l1.jpg  \n",
            " extracting: DeepDRiD/train/122/122_l2.jpg  \n",
            " extracting: DeepDRiD/train/122/122_r1.jpg  \n",
            " extracting: DeepDRiD/train/122/122_r2.jpg  \n",
            "   creating: DeepDRiD/train/123/\n",
            " extracting: DeepDRiD/train/123/123_l1.jpg  \n",
            " extracting: DeepDRiD/train/123/123_l2.jpg  \n",
            " extracting: DeepDRiD/train/123/123_r1.jpg  \n",
            " extracting: DeepDRiD/train/123/123_r2.jpg  \n",
            "   creating: DeepDRiD/train/124/\n",
            " extracting: DeepDRiD/train/124/124_l1.jpg  \n",
            " extracting: DeepDRiD/train/124/124_l2.jpg  \n",
            " extracting: DeepDRiD/train/124/124_r1.jpg  \n",
            " extracting: DeepDRiD/train/124/124_r2.jpg  \n",
            "   creating: DeepDRiD/train/125/\n",
            " extracting: DeepDRiD/train/125/125_l1.jpg  \n",
            " extracting: DeepDRiD/train/125/125_l2.jpg  \n",
            " extracting: DeepDRiD/train/125/125_r1.jpg  \n",
            " extracting: DeepDRiD/train/125/125_r2.jpg  \n",
            "   creating: DeepDRiD/train/126/\n",
            " extracting: DeepDRiD/train/126/126_l1.jpg  \n",
            " extracting: DeepDRiD/train/126/126_l2.jpg  \n",
            " extracting: DeepDRiD/train/126/126_r1.jpg  \n",
            " extracting: DeepDRiD/train/126/126_r2.jpg  \n",
            "   creating: DeepDRiD/train/127/\n",
            " extracting: DeepDRiD/train/127/127_l1.jpg  \n",
            " extracting: DeepDRiD/train/127/127_l2.jpg  \n",
            " extracting: DeepDRiD/train/127/127_r1.jpg  \n",
            " extracting: DeepDRiD/train/127/127_r2.jpg  \n",
            "   creating: DeepDRiD/train/128/\n",
            " extracting: DeepDRiD/train/128/128_l1.jpg  \n",
            " extracting: DeepDRiD/train/128/128_l2.jpg  \n",
            " extracting: DeepDRiD/train/128/128_r1.jpg  \n",
            " extracting: DeepDRiD/train/128/128_r2.jpg  \n",
            "   creating: DeepDRiD/train/129/\n",
            " extracting: DeepDRiD/train/129/129_l1.jpg  \n",
            " extracting: DeepDRiD/train/129/129_l2.jpg  \n",
            " extracting: DeepDRiD/train/129/129_r1.jpg  \n",
            " extracting: DeepDRiD/train/129/129_r2.jpg  \n",
            "   creating: DeepDRiD/train/13/\n",
            " extracting: DeepDRiD/train/13/13_l1.jpg  \n",
            " extracting: DeepDRiD/train/13/13_l2.jpg  \n",
            " extracting: DeepDRiD/train/13/13_r1.jpg  \n",
            " extracting: DeepDRiD/train/13/13_r2.jpg  \n",
            "   creating: DeepDRiD/train/130/\n",
            " extracting: DeepDRiD/train/130/130_l1.jpg  \n",
            " extracting: DeepDRiD/train/130/130_l2.jpg  \n",
            " extracting: DeepDRiD/train/130/130_r1.jpg  \n",
            " extracting: DeepDRiD/train/130/130_r2.jpg  \n",
            "   creating: DeepDRiD/train/131/\n",
            " extracting: DeepDRiD/train/131/131_l1.jpg  \n",
            " extracting: DeepDRiD/train/131/131_l2.jpg  \n",
            " extracting: DeepDRiD/train/131/131_r1.jpg  \n",
            " extracting: DeepDRiD/train/131/131_r2.jpg  \n",
            "   creating: DeepDRiD/train/132/\n",
            " extracting: DeepDRiD/train/132/132_l1.jpg  \n",
            " extracting: DeepDRiD/train/132/132_l2.jpg  \n",
            " extracting: DeepDRiD/train/132/132_r1.jpg  \n",
            " extracting: DeepDRiD/train/132/132_r2.jpg  \n",
            "   creating: DeepDRiD/train/133/\n",
            " extracting: DeepDRiD/train/133/133_l1.jpg  \n",
            " extracting: DeepDRiD/train/133/133_l2.jpg  \n",
            " extracting: DeepDRiD/train/133/133_r1.jpg  \n",
            " extracting: DeepDRiD/train/133/133_r2.jpg  \n",
            "   creating: DeepDRiD/train/134/\n",
            " extracting: DeepDRiD/train/134/134_l1.jpg  \n",
            " extracting: DeepDRiD/train/134/134_l2.jpg  \n",
            " extracting: DeepDRiD/train/134/134_r1.jpg  \n",
            " extracting: DeepDRiD/train/134/134_r2.jpg  \n",
            "   creating: DeepDRiD/train/135/\n",
            " extracting: DeepDRiD/train/135/135_l1.jpg  \n",
            " extracting: DeepDRiD/train/135/135_l2.jpg  \n",
            " extracting: DeepDRiD/train/135/135_r1.jpg  \n",
            " extracting: DeepDRiD/train/135/135_r2.jpg  \n",
            "   creating: DeepDRiD/train/136/\n",
            " extracting: DeepDRiD/train/136/136_l1.jpg  \n",
            " extracting: DeepDRiD/train/136/136_l2.jpg  \n",
            " extracting: DeepDRiD/train/136/136_r1.jpg  \n",
            " extracting: DeepDRiD/train/136/136_r2.jpg  \n",
            "   creating: DeepDRiD/train/137/\n",
            " extracting: DeepDRiD/train/137/137_l1.jpg  \n",
            " extracting: DeepDRiD/train/137/137_l2.jpg  \n",
            " extracting: DeepDRiD/train/137/137_r1.jpg  \n",
            " extracting: DeepDRiD/train/137/137_r2.jpg  \n",
            "   creating: DeepDRiD/train/138/\n",
            " extracting: DeepDRiD/train/138/138_l1.jpg  \n",
            " extracting: DeepDRiD/train/138/138_l2.jpg  \n",
            " extracting: DeepDRiD/train/138/138_r1.jpg  \n",
            " extracting: DeepDRiD/train/138/138_r2.jpg  \n",
            "   creating: DeepDRiD/train/139/\n",
            " extracting: DeepDRiD/train/139/139_l1.jpg  \n",
            " extracting: DeepDRiD/train/139/139_l2.jpg  \n",
            " extracting: DeepDRiD/train/139/139_r1.jpg  \n",
            " extracting: DeepDRiD/train/139/139_r2.jpg  \n",
            "   creating: DeepDRiD/train/14/\n",
            " extracting: DeepDRiD/train/14/14_l1.jpg  \n",
            " extracting: DeepDRiD/train/14/14_l2.jpg  \n",
            " extracting: DeepDRiD/train/14/14_r1.jpg  \n",
            " extracting: DeepDRiD/train/14/14_r2.jpg  \n",
            "   creating: DeepDRiD/train/140/\n",
            " extracting: DeepDRiD/train/140/140_l1.jpg  \n",
            " extracting: DeepDRiD/train/140/140_l2.jpg  \n",
            " extracting: DeepDRiD/train/140/140_r1.jpg  \n",
            " extracting: DeepDRiD/train/140/140_r2.jpg  \n",
            "   creating: DeepDRiD/train/141/\n",
            " extracting: DeepDRiD/train/141/141_l1.jpg  \n",
            " extracting: DeepDRiD/train/141/141_l2.jpg  \n",
            " extracting: DeepDRiD/train/141/141_r1.jpg  \n",
            " extracting: DeepDRiD/train/141/141_r2.jpg  \n",
            "   creating: DeepDRiD/train/142/\n",
            " extracting: DeepDRiD/train/142/142_l1.jpg  \n",
            " extracting: DeepDRiD/train/142/142_l2.jpg  \n",
            " extracting: DeepDRiD/train/142/142_r1.jpg  \n",
            " extracting: DeepDRiD/train/142/142_r2.jpg  \n",
            "   creating: DeepDRiD/train/143/\n",
            " extracting: DeepDRiD/train/143/143_l1.jpg  \n",
            " extracting: DeepDRiD/train/143/143_l2.jpg  \n",
            " extracting: DeepDRiD/train/143/143_r1.jpg  \n",
            " extracting: DeepDRiD/train/143/143_r2.jpg  \n",
            "   creating: DeepDRiD/train/144/\n",
            " extracting: DeepDRiD/train/144/144_l1.jpg  \n",
            " extracting: DeepDRiD/train/144/144_l2.jpg  \n",
            " extracting: DeepDRiD/train/144/144_r1.jpg  \n",
            " extracting: DeepDRiD/train/144/144_r2.jpg  \n",
            "   creating: DeepDRiD/train/145/\n",
            " extracting: DeepDRiD/train/145/145_l1.jpg  \n",
            " extracting: DeepDRiD/train/145/145_l2.jpg  \n",
            " extracting: DeepDRiD/train/145/145_r1.jpg  \n",
            " extracting: DeepDRiD/train/145/145_r2.jpg  \n",
            "   creating: DeepDRiD/train/146/\n",
            " extracting: DeepDRiD/train/146/146_l1.jpg  \n",
            " extracting: DeepDRiD/train/146/146_l2.jpg  \n",
            " extracting: DeepDRiD/train/146/146_r1.jpg  \n",
            " extracting: DeepDRiD/train/146/146_r2.jpg  \n",
            "   creating: DeepDRiD/train/147/\n",
            " extracting: DeepDRiD/train/147/147_l1.jpg  \n",
            " extracting: DeepDRiD/train/147/147_l2.jpg  \n",
            " extracting: DeepDRiD/train/147/147_r1.jpg  \n",
            " extracting: DeepDRiD/train/147/147_r2.jpg  \n",
            "   creating: DeepDRiD/train/148/\n",
            " extracting: DeepDRiD/train/148/148_l1.jpg  \n",
            " extracting: DeepDRiD/train/148/148_l2.jpg  \n",
            " extracting: DeepDRiD/train/148/148_r1.jpg  \n",
            " extracting: DeepDRiD/train/148/148_r2.jpg  \n",
            "   creating: DeepDRiD/train/149/\n",
            " extracting: DeepDRiD/train/149/149_l1.jpg  \n",
            " extracting: DeepDRiD/train/149/149_l2.jpg  \n",
            " extracting: DeepDRiD/train/149/149_r1.jpg  \n",
            " extracting: DeepDRiD/train/149/149_r2.jpg  \n",
            "   creating: DeepDRiD/train/15/\n",
            " extracting: DeepDRiD/train/15/15_l1.jpg  \n",
            " extracting: DeepDRiD/train/15/15_l2.jpg  \n",
            " extracting: DeepDRiD/train/15/15_r1.jpg  \n",
            " extracting: DeepDRiD/train/15/15_r2.jpg  \n",
            "   creating: DeepDRiD/train/150/\n",
            " extracting: DeepDRiD/train/150/150_l1.jpg  \n",
            " extracting: DeepDRiD/train/150/150_l2.jpg  \n",
            " extracting: DeepDRiD/train/150/150_r1.jpg  \n",
            " extracting: DeepDRiD/train/150/150_r2.jpg  \n",
            "   creating: DeepDRiD/train/151/\n",
            " extracting: DeepDRiD/train/151/151_l1.jpg  \n",
            " extracting: DeepDRiD/train/151/151_l2.jpg  \n",
            " extracting: DeepDRiD/train/151/151_r1.jpg  \n",
            " extracting: DeepDRiD/train/151/151_r2.jpg  \n",
            "   creating: DeepDRiD/train/152/\n",
            " extracting: DeepDRiD/train/152/152_l1.jpg  \n",
            " extracting: DeepDRiD/train/152/152_l2.jpg  \n",
            " extracting: DeepDRiD/train/152/152_r1.jpg  \n",
            " extracting: DeepDRiD/train/152/152_r2.jpg  \n",
            "   creating: DeepDRiD/train/153/\n",
            " extracting: DeepDRiD/train/153/153_l1.jpg  \n",
            " extracting: DeepDRiD/train/153/153_l2.jpg  \n",
            " extracting: DeepDRiD/train/153/153_r1.jpg  \n",
            " extracting: DeepDRiD/train/153/153_r2.jpg  \n",
            "   creating: DeepDRiD/train/154/\n",
            " extracting: DeepDRiD/train/154/154_l1.jpg  \n",
            " extracting: DeepDRiD/train/154/154_l2.jpg  \n",
            " extracting: DeepDRiD/train/154/154_r1.jpg  \n",
            " extracting: DeepDRiD/train/154/154_r2.jpg  \n",
            "   creating: DeepDRiD/train/155/\n",
            " extracting: DeepDRiD/train/155/155_l1.jpg  \n",
            " extracting: DeepDRiD/train/155/155_l2.jpg  \n",
            " extracting: DeepDRiD/train/155/155_r1.jpg  \n",
            " extracting: DeepDRiD/train/155/155_r2.jpg  \n",
            "   creating: DeepDRiD/train/156/\n",
            " extracting: DeepDRiD/train/156/156_l1.jpg  \n",
            " extracting: DeepDRiD/train/156/156_l2.jpg  \n",
            " extracting: DeepDRiD/train/156/156_r1.jpg  \n",
            " extracting: DeepDRiD/train/156/156_r2.jpg  \n",
            "   creating: DeepDRiD/train/157/\n",
            " extracting: DeepDRiD/train/157/157_l1.jpg  \n",
            " extracting: DeepDRiD/train/157/157_l2.jpg  \n",
            " extracting: DeepDRiD/train/157/157_r1.jpg  \n",
            " extracting: DeepDRiD/train/157/157_r2.jpg  \n",
            "   creating: DeepDRiD/train/158/\n",
            " extracting: DeepDRiD/train/158/158_l1.jpg  \n",
            " extracting: DeepDRiD/train/158/158_l2.jpg  \n",
            " extracting: DeepDRiD/train/158/158_r1.jpg  \n",
            " extracting: DeepDRiD/train/158/158_r2.jpg  \n",
            "   creating: DeepDRiD/train/159/\n",
            " extracting: DeepDRiD/train/159/159_l1.jpg  \n",
            " extracting: DeepDRiD/train/159/159_l2.jpg  \n",
            " extracting: DeepDRiD/train/159/159_r1.jpg  \n",
            " extracting: DeepDRiD/train/159/159_r2.jpg  \n",
            "   creating: DeepDRiD/train/16/\n",
            " extracting: DeepDRiD/train/16/16_l1.jpg  \n",
            " extracting: DeepDRiD/train/16/16_l2.jpg  \n",
            " extracting: DeepDRiD/train/16/16_r1.jpg  \n",
            " extracting: DeepDRiD/train/16/16_r2.jpg  \n",
            "   creating: DeepDRiD/train/160/\n",
            " extracting: DeepDRiD/train/160/160_l1.jpg  \n",
            " extracting: DeepDRiD/train/160/160_l2.jpg  \n",
            " extracting: DeepDRiD/train/160/160_r1.jpg  \n",
            " extracting: DeepDRiD/train/160/160_r2.jpg  \n",
            "   creating: DeepDRiD/train/161/\n",
            " extracting: DeepDRiD/train/161/161_l1.jpg  \n",
            " extracting: DeepDRiD/train/161/161_l2.jpg  \n",
            " extracting: DeepDRiD/train/161/161_r1.jpg  \n",
            " extracting: DeepDRiD/train/161/161_r2.jpg  \n",
            "   creating: DeepDRiD/train/162/\n",
            " extracting: DeepDRiD/train/162/162_l1.jpg  \n",
            " extracting: DeepDRiD/train/162/162_l2.jpg  \n",
            " extracting: DeepDRiD/train/162/162_r1.jpg  \n",
            " extracting: DeepDRiD/train/162/162_r2.jpg  \n",
            "   creating: DeepDRiD/train/163/\n",
            " extracting: DeepDRiD/train/163/163_l1.jpg  \n",
            " extracting: DeepDRiD/train/163/163_l2.jpg  \n",
            " extracting: DeepDRiD/train/163/163_r1.jpg  \n",
            " extracting: DeepDRiD/train/163/163_r2.jpg  \n",
            "   creating: DeepDRiD/train/164/\n",
            " extracting: DeepDRiD/train/164/164_l1.jpg  \n",
            " extracting: DeepDRiD/train/164/164_l2.jpg  \n",
            " extracting: DeepDRiD/train/164/164_r1.jpg  \n",
            " extracting: DeepDRiD/train/164/164_r2.jpg  \n",
            "   creating: DeepDRiD/train/165/\n",
            " extracting: DeepDRiD/train/165/165_l1.jpg  \n",
            " extracting: DeepDRiD/train/165/165_l2.jpg  \n",
            " extracting: DeepDRiD/train/165/165_r1.jpg  \n",
            " extracting: DeepDRiD/train/165/165_r2.jpg  \n",
            "   creating: DeepDRiD/train/166/\n",
            " extracting: DeepDRiD/train/166/166_l1.jpg  \n",
            " extracting: DeepDRiD/train/166/166_l2.jpg  \n",
            " extracting: DeepDRiD/train/166/166_r1.jpg  \n",
            " extracting: DeepDRiD/train/166/166_r2.jpg  \n",
            "   creating: DeepDRiD/train/167/\n",
            " extracting: DeepDRiD/train/167/167_l2.jpg  \n",
            " extracting: DeepDRiD/train/167/167_l3.jpg  \n",
            " extracting: DeepDRiD/train/167/167_r2.jpg  \n",
            " extracting: DeepDRiD/train/167/167_r3.jpg  \n",
            "   creating: DeepDRiD/train/168/\n",
            " extracting: DeepDRiD/train/168/168_l1.jpg  \n",
            " extracting: DeepDRiD/train/168/168_l2.jpg  \n",
            " extracting: DeepDRiD/train/168/168_r1.jpg  \n",
            " extracting: DeepDRiD/train/168/168_r2.jpg  \n",
            "   creating: DeepDRiD/train/169/\n",
            " extracting: DeepDRiD/train/169/169_l1.jpg  \n",
            " extracting: DeepDRiD/train/169/169_l2.jpg  \n",
            " extracting: DeepDRiD/train/169/169_r1.jpg  \n",
            " extracting: DeepDRiD/train/169/169_r2.jpg  \n",
            "   creating: DeepDRiD/train/17/\n",
            " extracting: DeepDRiD/train/17/17_l1.jpg  \n",
            " extracting: DeepDRiD/train/17/17_l2.jpg  \n",
            " extracting: DeepDRiD/train/17/17_r1.jpg  \n",
            " extracting: DeepDRiD/train/17/17_r2.jpg  \n",
            "   creating: DeepDRiD/train/170/\n",
            " extracting: DeepDRiD/train/170/170_l1.jpg  \n",
            " extracting: DeepDRiD/train/170/170_l2.jpg  \n",
            " extracting: DeepDRiD/train/170/170_r1.jpg  \n",
            " extracting: DeepDRiD/train/170/170_r2.jpg  \n",
            "   creating: DeepDRiD/train/171/\n",
            " extracting: DeepDRiD/train/171/171_l1.jpg  \n",
            " extracting: DeepDRiD/train/171/171_l2.jpg  \n",
            " extracting: DeepDRiD/train/171/171_r1.jpg  \n",
            " extracting: DeepDRiD/train/171/171_r2.jpg  \n",
            "   creating: DeepDRiD/train/172/\n",
            " extracting: DeepDRiD/train/172/172_l1.jpg  \n",
            " extracting: DeepDRiD/train/172/172_l2.jpg  \n",
            " extracting: DeepDRiD/train/172/172_r1.jpg  \n",
            " extracting: DeepDRiD/train/172/172_r2.jpg  \n",
            "   creating: DeepDRiD/train/173/\n",
            " extracting: DeepDRiD/train/173/173_l1.jpg  \n",
            " extracting: DeepDRiD/train/173/173_l2.jpg  \n",
            " extracting: DeepDRiD/train/173/173_r1.jpg  \n",
            " extracting: DeepDRiD/train/173/173_r2.jpg  \n",
            "   creating: DeepDRiD/train/174/\n",
            " extracting: DeepDRiD/train/174/174_l1.jpg  \n",
            " extracting: DeepDRiD/train/174/174_l2.jpg  \n",
            " extracting: DeepDRiD/train/174/174_r1.jpg  \n",
            " extracting: DeepDRiD/train/174/174_r2.jpg  \n",
            "   creating: DeepDRiD/train/175/\n",
            " extracting: DeepDRiD/train/175/175_l1.jpg  \n",
            " extracting: DeepDRiD/train/175/175_l2.jpg  \n",
            " extracting: DeepDRiD/train/175/175_r1.jpg  \n",
            " extracting: DeepDRiD/train/175/175_r2.jpg  \n",
            "   creating: DeepDRiD/train/176/\n",
            " extracting: DeepDRiD/train/176/176_l1.jpg  \n",
            " extracting: DeepDRiD/train/176/176_l2.jpg  \n",
            " extracting: DeepDRiD/train/176/176_r1.jpg  \n",
            " extracting: DeepDRiD/train/176/176_r2.jpg  \n",
            "   creating: DeepDRiD/train/177/\n",
            " extracting: DeepDRiD/train/177/177_l1.jpg  \n",
            " extracting: DeepDRiD/train/177/177_l2.jpg  \n",
            " extracting: DeepDRiD/train/177/177_r1.jpg  \n",
            " extracting: DeepDRiD/train/177/177_r2.jpg  \n",
            "   creating: DeepDRiD/train/178/\n",
            " extracting: DeepDRiD/train/178/178_l1.jpg  \n",
            " extracting: DeepDRiD/train/178/178_l2.jpg  \n",
            " extracting: DeepDRiD/train/178/178_r1.jpg  \n",
            " extracting: DeepDRiD/train/178/178_r2.jpg  \n",
            "   creating: DeepDRiD/train/179/\n",
            " extracting: DeepDRiD/train/179/179_l1.jpg  \n",
            " extracting: DeepDRiD/train/179/179_l2.jpg  \n",
            " extracting: DeepDRiD/train/179/179_r1.jpg  \n",
            " extracting: DeepDRiD/train/179/179_r2.jpg  \n",
            "   creating: DeepDRiD/train/18/\n",
            " extracting: DeepDRiD/train/18/18_l1.jpg  \n",
            " extracting: DeepDRiD/train/18/18_l2.jpg  \n",
            " extracting: DeepDRiD/train/18/18_r1.jpg  \n",
            " extracting: DeepDRiD/train/18/18_r2.jpg  \n",
            "   creating: DeepDRiD/train/180/\n",
            " extracting: DeepDRiD/train/180/180_l1.jpg  \n",
            " extracting: DeepDRiD/train/180/180_l2.jpg  \n",
            " extracting: DeepDRiD/train/180/180_r1.jpg  \n",
            " extracting: DeepDRiD/train/180/180_r2.jpg  \n",
            "   creating: DeepDRiD/train/181/\n",
            " extracting: DeepDRiD/train/181/181_l1.jpg  \n",
            " extracting: DeepDRiD/train/181/181_l2.jpg  \n",
            " extracting: DeepDRiD/train/181/181_r1.jpg  \n",
            " extracting: DeepDRiD/train/181/181_r2.jpg  \n",
            "   creating: DeepDRiD/train/182/\n",
            " extracting: DeepDRiD/train/182/182_l1.jpg  \n",
            " extracting: DeepDRiD/train/182/182_l2.jpg  \n",
            " extracting: DeepDRiD/train/182/182_r1.jpg  \n",
            " extracting: DeepDRiD/train/182/182_r2.jpg  \n",
            "   creating: DeepDRiD/train/183/\n",
            " extracting: DeepDRiD/train/183/183_l1.jpg  \n",
            " extracting: DeepDRiD/train/183/183_l2.jpg  \n",
            " extracting: DeepDRiD/train/183/183_r1.jpg  \n",
            " extracting: DeepDRiD/train/183/183_r2.jpg  \n",
            "   creating: DeepDRiD/train/184/\n",
            " extracting: DeepDRiD/train/184/184_l1.jpg  \n",
            " extracting: DeepDRiD/train/184/184_l2.jpg  \n",
            " extracting: DeepDRiD/train/184/184_r1.jpg  \n",
            " extracting: DeepDRiD/train/184/184_r2.jpg  \n",
            "   creating: DeepDRiD/train/185/\n",
            " extracting: DeepDRiD/train/185/185_l1.jpg  \n",
            " extracting: DeepDRiD/train/185/185_l2.jpg  \n",
            " extracting: DeepDRiD/train/185/185_r1.jpg  \n",
            " extracting: DeepDRiD/train/185/185_r2.jpg  \n",
            "   creating: DeepDRiD/train/186/\n",
            " extracting: DeepDRiD/train/186/186_l1.jpg  \n",
            " extracting: DeepDRiD/train/186/186_l2.jpg  \n",
            " extracting: DeepDRiD/train/186/186_r1.jpg  \n",
            " extracting: DeepDRiD/train/186/186_r2.jpg  \n",
            "   creating: DeepDRiD/train/187/\n",
            " extracting: DeepDRiD/train/187/187_l1.jpg  \n",
            " extracting: DeepDRiD/train/187/187_l2.jpg  \n",
            " extracting: DeepDRiD/train/187/187_r1.jpg  \n",
            " extracting: DeepDRiD/train/187/187_r2.jpg  \n",
            "   creating: DeepDRiD/train/188/\n",
            " extracting: DeepDRiD/train/188/188_l1.jpg  \n",
            " extracting: DeepDRiD/train/188/188_l2.jpg  \n",
            " extracting: DeepDRiD/train/188/188_r1.jpg  \n",
            " extracting: DeepDRiD/train/188/188_r2.jpg  \n",
            "   creating: DeepDRiD/train/189/\n",
            " extracting: DeepDRiD/train/189/189_l1.jpg  \n",
            " extracting: DeepDRiD/train/189/189_l2.jpg  \n",
            " extracting: DeepDRiD/train/189/189_r1.jpg  \n",
            " extracting: DeepDRiD/train/189/189_r2.jpg  \n",
            "   creating: DeepDRiD/train/19/\n",
            " extracting: DeepDRiD/train/19/19_l1.jpg  \n",
            " extracting: DeepDRiD/train/19/19_l2.jpg  \n",
            " extracting: DeepDRiD/train/19/19_r1.jpg  \n",
            " extracting: DeepDRiD/train/19/19_r2.jpg  \n",
            "   creating: DeepDRiD/train/190/\n",
            " extracting: DeepDRiD/train/190/190_l1.jpg  \n",
            " extracting: DeepDRiD/train/190/190_l2.jpg  \n",
            " extracting: DeepDRiD/train/190/190_r1.jpg  \n",
            " extracting: DeepDRiD/train/190/190_r2.jpg  \n",
            "   creating: DeepDRiD/train/191/\n",
            " extracting: DeepDRiD/train/191/191_l1.jpg  \n",
            " extracting: DeepDRiD/train/191/191_l2.jpg  \n",
            " extracting: DeepDRiD/train/191/191_r1.jpg  \n",
            " extracting: DeepDRiD/train/191/191_r2.jpg  \n",
            "   creating: DeepDRiD/train/192/\n",
            " extracting: DeepDRiD/train/192/192_l1.jpg  \n",
            " extracting: DeepDRiD/train/192/192_l2.jpg  \n",
            " extracting: DeepDRiD/train/192/192_r1.jpg  \n",
            " extracting: DeepDRiD/train/192/192_r2.jpg  \n",
            "   creating: DeepDRiD/train/193/\n",
            " extracting: DeepDRiD/train/193/193_l1.jpg  \n",
            " extracting: DeepDRiD/train/193/193_l2.jpg  \n",
            " extracting: DeepDRiD/train/193/193_r1.jpg  \n",
            " extracting: DeepDRiD/train/193/193_r2.jpg  \n",
            "   creating: DeepDRiD/train/194/\n",
            " extracting: DeepDRiD/train/194/194_l1.jpg  \n",
            " extracting: DeepDRiD/train/194/194_l2.jpg  \n",
            " extracting: DeepDRiD/train/194/194_r1.jpg  \n",
            " extracting: DeepDRiD/train/194/194_r2.jpg  \n",
            "   creating: DeepDRiD/train/195/\n",
            " extracting: DeepDRiD/train/195/195_l1.jpg  \n",
            " extracting: DeepDRiD/train/195/195_l2.jpg  \n",
            " extracting: DeepDRiD/train/195/195_r1.jpg  \n",
            " extracting: DeepDRiD/train/195/195_r2.jpg  \n",
            "   creating: DeepDRiD/train/196/\n",
            " extracting: DeepDRiD/train/196/196_l1.jpg  \n",
            " extracting: DeepDRiD/train/196/196_l2.jpg  \n",
            " extracting: DeepDRiD/train/196/196_r1.jpg  \n",
            " extracting: DeepDRiD/train/196/196_r2.jpg  \n",
            "   creating: DeepDRiD/train/197/\n",
            " extracting: DeepDRiD/train/197/197_l1.jpg  \n",
            " extracting: DeepDRiD/train/197/197_l2.jpg  \n",
            " extracting: DeepDRiD/train/197/197_r1.jpg  \n",
            " extracting: DeepDRiD/train/197/197_r2.jpg  \n",
            "   creating: DeepDRiD/train/198/\n",
            " extracting: DeepDRiD/train/198/198_l1.jpg  \n",
            " extracting: DeepDRiD/train/198/198_l2.jpg  \n",
            " extracting: DeepDRiD/train/198/198_r1.jpg  \n",
            " extracting: DeepDRiD/train/198/198_r2.jpg  \n",
            "   creating: DeepDRiD/train/199/\n",
            " extracting: DeepDRiD/train/199/199_l1.jpg  \n",
            " extracting: DeepDRiD/train/199/199_l2.jpg  \n",
            " extracting: DeepDRiD/train/199/199_r1.jpg  \n",
            " extracting: DeepDRiD/train/199/199_r2.jpg  \n",
            "   creating: DeepDRiD/train/2/\n",
            " extracting: DeepDRiD/train/2/2_l1.jpg  \n",
            " extracting: DeepDRiD/train/2/2_l2.jpg  \n",
            " extracting: DeepDRiD/train/2/2_r1.jpg  \n",
            " extracting: DeepDRiD/train/2/2_r2.jpg  \n",
            "   creating: DeepDRiD/train/20/\n",
            " extracting: DeepDRiD/train/20/20_l1.jpg  \n",
            " extracting: DeepDRiD/train/20/20_l2.jpg  \n",
            " extracting: DeepDRiD/train/20/20_r1.jpg  \n",
            " extracting: DeepDRiD/train/20/20_r2.jpg  \n",
            "   creating: DeepDRiD/train/200/\n",
            " extracting: DeepDRiD/train/200/200_l1.jpg  \n",
            " extracting: DeepDRiD/train/200/200_l2.jpg  \n",
            " extracting: DeepDRiD/train/200/200_r1.jpg  \n",
            " extracting: DeepDRiD/train/200/200_r2.jpg  \n",
            "   creating: DeepDRiD/train/201/\n",
            " extracting: DeepDRiD/train/201/201_l1.jpg  \n",
            " extracting: DeepDRiD/train/201/201_l2.jpg  \n",
            " extracting: DeepDRiD/train/201/201_r1.jpg  \n",
            " extracting: DeepDRiD/train/201/201_r2.jpg  \n",
            "   creating: DeepDRiD/train/202/\n",
            " extracting: DeepDRiD/train/202/202_l1.jpg  \n",
            " extracting: DeepDRiD/train/202/202_l2.jpg  \n",
            " extracting: DeepDRiD/train/202/202_r1.jpg  \n",
            " extracting: DeepDRiD/train/202/202_r2.jpg  \n",
            "   creating: DeepDRiD/train/203/\n",
            " extracting: DeepDRiD/train/203/203_l1.jpg  \n",
            " extracting: DeepDRiD/train/203/203_l2.jpg  \n",
            " extracting: DeepDRiD/train/203/203_r1.jpg  \n",
            " extracting: DeepDRiD/train/203/203_r2.jpg  \n",
            "   creating: DeepDRiD/train/204/\n",
            " extracting: DeepDRiD/train/204/204_l1.jpg  \n",
            " extracting: DeepDRiD/train/204/204_l2.jpg  \n",
            " extracting: DeepDRiD/train/204/204_r1.jpg  \n",
            " extracting: DeepDRiD/train/204/204_r2.jpg  \n",
            "   creating: DeepDRiD/train/205/\n",
            " extracting: DeepDRiD/train/205/205_l1.jpg  \n",
            " extracting: DeepDRiD/train/205/205_l2.jpg  \n",
            " extracting: DeepDRiD/train/205/205_r1.jpg  \n",
            " extracting: DeepDRiD/train/205/205_r2.jpg  \n",
            "   creating: DeepDRiD/train/206/\n",
            " extracting: DeepDRiD/train/206/206_l1.jpg  \n",
            " extracting: DeepDRiD/train/206/206_l2.jpg  \n",
            " extracting: DeepDRiD/train/206/206_r1.jpg  \n",
            " extracting: DeepDRiD/train/206/206_r2.jpg  \n",
            "   creating: DeepDRiD/train/207/\n",
            " extracting: DeepDRiD/train/207/207_l1.jpg  \n",
            " extracting: DeepDRiD/train/207/207_l2.jpg  \n",
            " extracting: DeepDRiD/train/207/207_r1.jpg  \n",
            " extracting: DeepDRiD/train/207/207_r2.jpg  \n",
            "   creating: DeepDRiD/train/208/\n",
            " extracting: DeepDRiD/train/208/208_l1.jpg  \n",
            " extracting: DeepDRiD/train/208/208_l2.jpg  \n",
            " extracting: DeepDRiD/train/208/208_r1.jpg  \n",
            " extracting: DeepDRiD/train/208/208_r2.jpg  \n",
            "   creating: DeepDRiD/train/209/\n",
            " extracting: DeepDRiD/train/209/209_l1.jpg  \n",
            " extracting: DeepDRiD/train/209/209_l2.jpg  \n",
            " extracting: DeepDRiD/train/209/209_r1.jpg  \n",
            " extracting: DeepDRiD/train/209/209_r2.jpg  \n",
            "   creating: DeepDRiD/train/21/\n",
            " extracting: DeepDRiD/train/21/21_l1.jpg  \n",
            " extracting: DeepDRiD/train/21/21_l2.jpg  \n",
            " extracting: DeepDRiD/train/21/21_r1.jpg  \n",
            " extracting: DeepDRiD/train/21/21_r2.jpg  \n",
            "   creating: DeepDRiD/train/210/\n",
            " extracting: DeepDRiD/train/210/210_l1.jpg  \n",
            " extracting: DeepDRiD/train/210/210_l2.jpg  \n",
            " extracting: DeepDRiD/train/210/210_r1.jpg  \n",
            " extracting: DeepDRiD/train/210/210_r2.jpg  \n",
            "   creating: DeepDRiD/train/211/\n",
            " extracting: DeepDRiD/train/211/211_l1.jpg  \n",
            " extracting: DeepDRiD/train/211/211_l2.jpg  \n",
            " extracting: DeepDRiD/train/211/211_r1.jpg  \n",
            " extracting: DeepDRiD/train/211/211_r2.jpg  \n",
            "   creating: DeepDRiD/train/212/\n",
            " extracting: DeepDRiD/train/212/212_l1.jpg  \n",
            " extracting: DeepDRiD/train/212/212_l2.jpg  \n",
            " extracting: DeepDRiD/train/212/212_r1.jpg  \n",
            " extracting: DeepDRiD/train/212/212_r2.jpg  \n",
            "   creating: DeepDRiD/train/213/\n",
            " extracting: DeepDRiD/train/213/213_l1.jpg  \n",
            " extracting: DeepDRiD/train/213/213_l2.jpg  \n",
            " extracting: DeepDRiD/train/213/213_r1.jpg  \n",
            " extracting: DeepDRiD/train/213/213_r2.jpg  \n",
            "   creating: DeepDRiD/train/214/\n",
            " extracting: DeepDRiD/train/214/214_l1.jpg  \n",
            " extracting: DeepDRiD/train/214/214_l2.jpg  \n",
            " extracting: DeepDRiD/train/214/214_r1.jpg  \n",
            " extracting: DeepDRiD/train/214/214_r2.jpg  \n",
            "   creating: DeepDRiD/train/215/\n",
            " extracting: DeepDRiD/train/215/215_l1.jpg  \n",
            " extracting: DeepDRiD/train/215/215_l2.jpg  \n",
            " extracting: DeepDRiD/train/215/215_r1.jpg  \n",
            " extracting: DeepDRiD/train/215/215_r2.jpg  \n",
            "   creating: DeepDRiD/train/216/\n",
            " extracting: DeepDRiD/train/216/216_l1.jpg  \n",
            " extracting: DeepDRiD/train/216/216_l2.jpg  \n",
            " extracting: DeepDRiD/train/216/216_r1.jpg  \n",
            " extracting: DeepDRiD/train/216/216_r2.jpg  \n",
            "   creating: DeepDRiD/train/217/\n",
            " extracting: DeepDRiD/train/217/217_l1.jpg  \n",
            " extracting: DeepDRiD/train/217/217_l2.jpg  \n",
            " extracting: DeepDRiD/train/217/217_r1.jpg  \n",
            " extracting: DeepDRiD/train/217/217_r2.jpg  \n",
            "   creating: DeepDRiD/train/218/\n",
            " extracting: DeepDRiD/train/218/218_l1.jpg  \n",
            " extracting: DeepDRiD/train/218/218_l2.jpg  \n",
            " extracting: DeepDRiD/train/218/218_r1.jpg  \n",
            " extracting: DeepDRiD/train/218/218_r2.jpg  \n",
            "   creating: DeepDRiD/train/219/\n",
            " extracting: DeepDRiD/train/219/219_l1.jpg  \n",
            " extracting: DeepDRiD/train/219/219_l2.jpg  \n",
            " extracting: DeepDRiD/train/219/219_r1.jpg  \n",
            " extracting: DeepDRiD/train/219/219_r2.jpg  \n",
            "   creating: DeepDRiD/train/22/\n",
            " extracting: DeepDRiD/train/22/22_l1.jpg  \n",
            " extracting: DeepDRiD/train/22/22_l2.jpg  \n",
            " extracting: DeepDRiD/train/22/22_r1.jpg  \n",
            " extracting: DeepDRiD/train/22/22_r2.jpg  \n",
            "   creating: DeepDRiD/train/220/\n",
            " extracting: DeepDRiD/train/220/220_l1.jpg  \n",
            " extracting: DeepDRiD/train/220/220_l2.jpg  \n",
            " extracting: DeepDRiD/train/220/220_r1.jpg  \n",
            " extracting: DeepDRiD/train/220/220_r2.jpg  \n",
            "   creating: DeepDRiD/train/221/\n",
            " extracting: DeepDRiD/train/221/221_l1.jpg  \n",
            " extracting: DeepDRiD/train/221/221_l2.jpg  \n",
            " extracting: DeepDRiD/train/221/221_r1.jpg  \n",
            " extracting: DeepDRiD/train/221/221_r2.jpg  \n",
            "   creating: DeepDRiD/train/222/\n",
            " extracting: DeepDRiD/train/222/222_l1.jpg  \n",
            " extracting: DeepDRiD/train/222/222_l2.jpg  \n",
            " extracting: DeepDRiD/train/222/222_r1.jpg  \n",
            " extracting: DeepDRiD/train/222/222_r2.jpg  \n",
            "   creating: DeepDRiD/train/223/\n",
            " extracting: DeepDRiD/train/223/223_l1.jpg  \n",
            " extracting: DeepDRiD/train/223/223_l2.jpg  \n",
            " extracting: DeepDRiD/train/223/223_r1.jpg  \n",
            " extracting: DeepDRiD/train/223/223_r2.jpg  \n",
            "   creating: DeepDRiD/train/224/\n",
            " extracting: DeepDRiD/train/224/224_l1.jpg  \n",
            " extracting: DeepDRiD/train/224/224_l2.jpg  \n",
            " extracting: DeepDRiD/train/224/224_r1.jpg  \n",
            " extracting: DeepDRiD/train/224/224_r2.jpg  \n",
            "   creating: DeepDRiD/train/225/\n",
            " extracting: DeepDRiD/train/225/225_l1.jpg  \n",
            " extracting: DeepDRiD/train/225/225_l2.jpg  \n",
            " extracting: DeepDRiD/train/225/225_r1.jpg  \n",
            " extracting: DeepDRiD/train/225/225_r2.jpg  \n",
            "   creating: DeepDRiD/train/226/\n",
            " extracting: DeepDRiD/train/226/226_l1.jpg  \n",
            " extracting: DeepDRiD/train/226/226_l2.jpg  \n",
            " extracting: DeepDRiD/train/226/226_r1.jpg  \n",
            " extracting: DeepDRiD/train/226/226_r2.jpg  \n",
            "   creating: DeepDRiD/train/227/\n",
            " extracting: DeepDRiD/train/227/227_l1.jpg  \n",
            " extracting: DeepDRiD/train/227/227_l2.jpg  \n",
            " extracting: DeepDRiD/train/227/227_r1.jpg  \n",
            " extracting: DeepDRiD/train/227/227_r2.jpg  \n",
            "   creating: DeepDRiD/train/228/\n",
            " extracting: DeepDRiD/train/228/228_l1.jpg  \n",
            " extracting: DeepDRiD/train/228/228_l2.jpg  \n",
            " extracting: DeepDRiD/train/228/228_r1.jpg  \n",
            " extracting: DeepDRiD/train/228/228_r2.jpg  \n",
            "   creating: DeepDRiD/train/229/\n",
            " extracting: DeepDRiD/train/229/229_l1.jpg  \n",
            " extracting: DeepDRiD/train/229/229_l2.jpg  \n",
            " extracting: DeepDRiD/train/229/229_r1.jpg  \n",
            " extracting: DeepDRiD/train/229/229_r2.jpg  \n",
            "   creating: DeepDRiD/train/23/\n",
            " extracting: DeepDRiD/train/23/23_l1.jpg  \n",
            " extracting: DeepDRiD/train/23/23_l2.jpg  \n",
            " extracting: DeepDRiD/train/23/23_r1.jpg  \n",
            " extracting: DeepDRiD/train/23/23_r2.jpg  \n",
            "   creating: DeepDRiD/train/230/\n",
            " extracting: DeepDRiD/train/230/230_l1.jpg  \n",
            " extracting: DeepDRiD/train/230/230_l2.jpg  \n",
            " extracting: DeepDRiD/train/230/230_r1.jpg  \n",
            " extracting: DeepDRiD/train/230/230_r2.jpg  \n",
            "   creating: DeepDRiD/train/231/\n",
            " extracting: DeepDRiD/train/231/231_l1.jpg  \n",
            " extracting: DeepDRiD/train/231/231_l2.jpg  \n",
            " extracting: DeepDRiD/train/231/231_r1.jpg  \n",
            " extracting: DeepDRiD/train/231/231_r2.jpg  \n",
            "   creating: DeepDRiD/train/232/\n",
            " extracting: DeepDRiD/train/232/232_l1.jpg  \n",
            " extracting: DeepDRiD/train/232/232_l2.jpg  \n",
            " extracting: DeepDRiD/train/232/232_r1.jpg  \n",
            " extracting: DeepDRiD/train/232/232_r2.jpg  \n",
            "   creating: DeepDRiD/train/233/\n",
            " extracting: DeepDRiD/train/233/233_l1.jpg  \n",
            " extracting: DeepDRiD/train/233/233_l2.jpg  \n",
            " extracting: DeepDRiD/train/233/233_r1.jpg  \n",
            " extracting: DeepDRiD/train/233/233_r2.jpg  \n",
            "   creating: DeepDRiD/train/234/\n",
            " extracting: DeepDRiD/train/234/234_l1.jpg  \n",
            " extracting: DeepDRiD/train/234/234_l2.jpg  \n",
            " extracting: DeepDRiD/train/234/234_r1.jpg  \n",
            " extracting: DeepDRiD/train/234/234_r2.jpg  \n",
            "   creating: DeepDRiD/train/235/\n",
            " extracting: DeepDRiD/train/235/235_l1.jpg  \n",
            " extracting: DeepDRiD/train/235/235_l2.jpg  \n",
            " extracting: DeepDRiD/train/235/235_r1.jpg  \n",
            " extracting: DeepDRiD/train/235/235_r2.jpg  \n",
            "   creating: DeepDRiD/train/236/\n",
            " extracting: DeepDRiD/train/236/236_l1.jpg  \n",
            " extracting: DeepDRiD/train/236/236_l2.jpg  \n",
            " extracting: DeepDRiD/train/236/236_r1.jpg  \n",
            " extracting: DeepDRiD/train/236/236_r2.jpg  \n",
            "   creating: DeepDRiD/train/237/\n",
            " extracting: DeepDRiD/train/237/237_l1.jpg  \n",
            " extracting: DeepDRiD/train/237/237_l2.jpg  \n",
            " extracting: DeepDRiD/train/237/237_r1.jpg  \n",
            " extracting: DeepDRiD/train/237/237_r2.jpg  \n",
            "   creating: DeepDRiD/train/238/\n",
            " extracting: DeepDRiD/train/238/238_l1.jpg  \n",
            " extracting: DeepDRiD/train/238/238_l2.jpg  \n",
            " extracting: DeepDRiD/train/238/238_r1.jpg  \n",
            " extracting: DeepDRiD/train/238/238_r2.jpg  \n",
            "   creating: DeepDRiD/train/239/\n",
            " extracting: DeepDRiD/train/239/239_l1.jpg  \n",
            " extracting: DeepDRiD/train/239/239_l2.jpg  \n",
            " extracting: DeepDRiD/train/239/239_r1.jpg  \n",
            " extracting: DeepDRiD/train/239/239_r2.jpg  \n",
            "   creating: DeepDRiD/train/24/\n",
            " extracting: DeepDRiD/train/24/24_l1.jpg  \n",
            " extracting: DeepDRiD/train/24/24_l2.jpg  \n",
            " extracting: DeepDRiD/train/24/24_r1.jpg  \n",
            " extracting: DeepDRiD/train/24/24_r2.jpg  \n",
            "   creating: DeepDRiD/train/240/\n",
            " extracting: DeepDRiD/train/240/240_l1.jpg  \n",
            " extracting: DeepDRiD/train/240/240_l2.jpg  \n",
            " extracting: DeepDRiD/train/240/240_r1.jpg  \n",
            " extracting: DeepDRiD/train/240/240_r2.jpg  \n",
            "   creating: DeepDRiD/train/241/\n",
            " extracting: DeepDRiD/train/241/241_l1.jpg  \n",
            " extracting: DeepDRiD/train/241/241_l2.jpg  \n",
            " extracting: DeepDRiD/train/241/241_r1.jpg  \n",
            " extracting: DeepDRiD/train/241/241_r2.jpg  \n",
            "   creating: DeepDRiD/train/242/\n",
            " extracting: DeepDRiD/train/242/242_l1.jpg  \n",
            " extracting: DeepDRiD/train/242/242_l2.jpg  \n",
            " extracting: DeepDRiD/train/242/242_r1.jpg  \n",
            " extracting: DeepDRiD/train/242/242_r2.jpg  \n",
            "   creating: DeepDRiD/train/243/\n",
            " extracting: DeepDRiD/train/243/243_l1.jpg  \n",
            " extracting: DeepDRiD/train/243/243_l2.jpg  \n",
            " extracting: DeepDRiD/train/243/243_r1.jpg  \n",
            " extracting: DeepDRiD/train/243/243_r2.jpg  \n",
            "   creating: DeepDRiD/train/244/\n",
            " extracting: DeepDRiD/train/244/244_l1.jpg  \n",
            " extracting: DeepDRiD/train/244/244_l2.jpg  \n",
            " extracting: DeepDRiD/train/244/244_r1.jpg  \n",
            " extracting: DeepDRiD/train/244/244_r2.jpg  \n",
            "   creating: DeepDRiD/train/245/\n",
            " extracting: DeepDRiD/train/245/245_l1.jpg  \n",
            " extracting: DeepDRiD/train/245/245_l2.jpg  \n",
            " extracting: DeepDRiD/train/245/245_r1.jpg  \n",
            " extracting: DeepDRiD/train/245/245_r2.jpg  \n",
            "   creating: DeepDRiD/train/246/\n",
            " extracting: DeepDRiD/train/246/246_l1.jpg  \n",
            " extracting: DeepDRiD/train/246/246_l2.jpg  \n",
            " extracting: DeepDRiD/train/246/246_r1.jpg  \n",
            " extracting: DeepDRiD/train/246/246_r2.jpg  \n",
            "   creating: DeepDRiD/train/247/\n",
            " extracting: DeepDRiD/train/247/247_l1.jpg  \n",
            " extracting: DeepDRiD/train/247/247_l2.jpg  \n",
            " extracting: DeepDRiD/train/247/247_r1.jpg  \n",
            " extracting: DeepDRiD/train/247/247_r2.jpg  \n",
            "   creating: DeepDRiD/train/248/\n",
            " extracting: DeepDRiD/train/248/248_l1.jpg  \n",
            " extracting: DeepDRiD/train/248/248_l2.jpg  \n",
            " extracting: DeepDRiD/train/248/248_r1.jpg  \n",
            " extracting: DeepDRiD/train/248/248_r2.jpg  \n",
            "   creating: DeepDRiD/train/249/\n",
            " extracting: DeepDRiD/train/249/249_l1.jpg  \n",
            " extracting: DeepDRiD/train/249/249_l2.jpg  \n",
            " extracting: DeepDRiD/train/249/249_r1.jpg  \n",
            " extracting: DeepDRiD/train/249/249_r2.jpg  \n",
            "   creating: DeepDRiD/train/25/\n",
            " extracting: DeepDRiD/train/25/25_l1.jpg  \n",
            " extracting: DeepDRiD/train/25/25_l2.jpg  \n",
            " extracting: DeepDRiD/train/25/25_r1.jpg  \n",
            " extracting: DeepDRiD/train/25/25_r2.jpg  \n",
            "   creating: DeepDRiD/train/250/\n",
            " extracting: DeepDRiD/train/250/250_l1.jpg  \n",
            " extracting: DeepDRiD/train/250/250_l2.jpg  \n",
            " extracting: DeepDRiD/train/250/250_r1.jpg  \n",
            " extracting: DeepDRiD/train/250/250_r2.jpg  \n",
            "   creating: DeepDRiD/train/251/\n",
            " extracting: DeepDRiD/train/251/251_l1.jpg  \n",
            " extracting: DeepDRiD/train/251/251_l2.jpg  \n",
            " extracting: DeepDRiD/train/251/251_r1.jpg  \n",
            " extracting: DeepDRiD/train/251/251_r2.jpg  \n",
            "   creating: DeepDRiD/train/252/\n",
            " extracting: DeepDRiD/train/252/252_l1.jpg  \n",
            " extracting: DeepDRiD/train/252/252_l2.jpg  \n",
            " extracting: DeepDRiD/train/252/252_r1.jpg  \n",
            " extracting: DeepDRiD/train/252/252_r2.jpg  \n",
            "   creating: DeepDRiD/train/253/\n",
            " extracting: DeepDRiD/train/253/253_l1.jpg  \n",
            " extracting: DeepDRiD/train/253/253_l2.jpg  \n",
            " extracting: DeepDRiD/train/253/253_r1.jpg  \n",
            " extracting: DeepDRiD/train/253/253_r2.jpg  \n",
            "   creating: DeepDRiD/train/254/\n",
            " extracting: DeepDRiD/train/254/254_l1.jpg  \n",
            " extracting: DeepDRiD/train/254/254_l2.jpg  \n",
            " extracting: DeepDRiD/train/254/254_r1.jpg  \n",
            " extracting: DeepDRiD/train/254/254_r2.jpg  \n",
            "   creating: DeepDRiD/train/255/\n",
            " extracting: DeepDRiD/train/255/255_l1.jpg  \n",
            " extracting: DeepDRiD/train/255/255_l2.jpg  \n",
            " extracting: DeepDRiD/train/255/255_r1.jpg  \n",
            " extracting: DeepDRiD/train/255/255_r2.jpg  \n",
            "   creating: DeepDRiD/train/256/\n",
            " extracting: DeepDRiD/train/256/256_l1.jpg  \n",
            " extracting: DeepDRiD/train/256/256_l2.jpg  \n",
            " extracting: DeepDRiD/train/256/256_r1.jpg  \n",
            " extracting: DeepDRiD/train/256/256_r2.jpg  \n",
            "   creating: DeepDRiD/train/257/\n",
            " extracting: DeepDRiD/train/257/257_l1.jpg  \n",
            " extracting: DeepDRiD/train/257/257_l2.jpg  \n",
            " extracting: DeepDRiD/train/257/257_r1.jpg  \n",
            " extracting: DeepDRiD/train/257/257_r2.jpg  \n",
            "   creating: DeepDRiD/train/258/\n",
            " extracting: DeepDRiD/train/258/258_l1.jpg  \n",
            " extracting: DeepDRiD/train/258/258_l2.jpg  \n",
            " extracting: DeepDRiD/train/258/258_r1.jpg  \n",
            " extracting: DeepDRiD/train/258/258_r2.jpg  \n",
            "   creating: DeepDRiD/train/259/\n",
            " extracting: DeepDRiD/train/259/259_l1.jpg  \n",
            " extracting: DeepDRiD/train/259/259_l2.jpg  \n",
            " extracting: DeepDRiD/train/259/259_r1.jpg  \n",
            " extracting: DeepDRiD/train/259/259_r2.jpg  \n",
            "   creating: DeepDRiD/train/26/\n",
            " extracting: DeepDRiD/train/26/26_l1.jpg  \n",
            " extracting: DeepDRiD/train/26/26_l2.jpg  \n",
            " extracting: DeepDRiD/train/26/26_r1.jpg  \n",
            " extracting: DeepDRiD/train/26/26_r2.jpg  \n",
            "   creating: DeepDRiD/train/260/\n",
            " extracting: DeepDRiD/train/260/260_l1.jpg  \n",
            " extracting: DeepDRiD/train/260/260_l2.jpg  \n",
            " extracting: DeepDRiD/train/260/260_r1.jpg  \n",
            " extracting: DeepDRiD/train/260/260_r2.jpg  \n",
            "   creating: DeepDRiD/train/261/\n",
            " extracting: DeepDRiD/train/261/261_l1.jpg  \n",
            " extracting: DeepDRiD/train/261/261_l2.jpg  \n",
            " extracting: DeepDRiD/train/261/261_r1.jpg  \n",
            " extracting: DeepDRiD/train/261/261_r2.jpg  \n",
            "   creating: DeepDRiD/train/262/\n",
            " extracting: DeepDRiD/train/262/262_l1.jpg  \n",
            " extracting: DeepDRiD/train/262/262_l2.jpg  \n",
            " extracting: DeepDRiD/train/262/262_r1.jpg  \n",
            " extracting: DeepDRiD/train/262/262_r2.jpg  \n",
            "   creating: DeepDRiD/train/263/\n",
            " extracting: DeepDRiD/train/263/263_l1.jpg  \n",
            " extracting: DeepDRiD/train/263/263_l2.jpg  \n",
            " extracting: DeepDRiD/train/263/263_r1.jpg  \n",
            " extracting: DeepDRiD/train/263/263_r2.jpg  \n",
            "   creating: DeepDRiD/train/264/\n",
            " extracting: DeepDRiD/train/264/264_l1.jpg  \n",
            " extracting: DeepDRiD/train/264/264_l2.jpg  \n",
            " extracting: DeepDRiD/train/264/264_r1.jpg  \n",
            " extracting: DeepDRiD/train/264/264_r2.jpg  \n",
            "   creating: DeepDRiD/train/266/\n",
            " extracting: DeepDRiD/train/266/266_l1.jpg  \n",
            " extracting: DeepDRiD/train/266/266_l2.jpg  \n",
            " extracting: DeepDRiD/train/266/266_r1.jpg  \n",
            " extracting: DeepDRiD/train/266/266_r2.jpg  \n",
            "   creating: DeepDRiD/train/268/\n",
            " extracting: DeepDRiD/train/268/268_l1.jpg  \n",
            " extracting: DeepDRiD/train/268/268_l2.jpg  \n",
            " extracting: DeepDRiD/train/268/268_r1.jpg  \n",
            " extracting: DeepDRiD/train/268/268_r2.jpg  \n",
            "   creating: DeepDRiD/train/269/\n",
            " extracting: DeepDRiD/train/269/269_l1.jpg  \n",
            " extracting: DeepDRiD/train/269/269_l2.jpg  \n",
            " extracting: DeepDRiD/train/269/269_r1.jpg  \n",
            " extracting: DeepDRiD/train/269/269_r2.jpg  \n",
            "   creating: DeepDRiD/train/27/\n",
            " extracting: DeepDRiD/train/27/27_l1.jpg  \n",
            " extracting: DeepDRiD/train/27/27_l2.jpg  \n",
            " extracting: DeepDRiD/train/27/27_r1.jpg  \n",
            " extracting: DeepDRiD/train/27/27_r2.jpg  \n",
            "   creating: DeepDRiD/train/270/\n",
            " extracting: DeepDRiD/train/270/270_l1.jpg  \n",
            " extracting: DeepDRiD/train/270/270_l2.jpg  \n",
            " extracting: DeepDRiD/train/270/270_r1.jpg  \n",
            " extracting: DeepDRiD/train/270/270_r2.jpg  \n",
            "   creating: DeepDRiD/train/271/\n",
            " extracting: DeepDRiD/train/271/271_l1.jpg  \n",
            " extracting: DeepDRiD/train/271/271_l2.jpg  \n",
            " extracting: DeepDRiD/train/271/271_r1.jpg  \n",
            " extracting: DeepDRiD/train/271/271_r2.jpg  \n",
            "   creating: DeepDRiD/train/272/\n",
            " extracting: DeepDRiD/train/272/272_l1.jpg  \n",
            " extracting: DeepDRiD/train/272/272_l2.jpg  \n",
            " extracting: DeepDRiD/train/272/272_r1.jpg  \n",
            " extracting: DeepDRiD/train/272/272_r2.jpg  \n",
            "   creating: DeepDRiD/train/273/\n",
            " extracting: DeepDRiD/train/273/273_l1.jpg  \n",
            " extracting: DeepDRiD/train/273/273_l2.jpg  \n",
            " extracting: DeepDRiD/train/273/273_r1.jpg  \n",
            " extracting: DeepDRiD/train/273/273_r2.jpg  \n",
            "   creating: DeepDRiD/train/274/\n",
            " extracting: DeepDRiD/train/274/274_l1.jpg  \n",
            " extracting: DeepDRiD/train/274/274_l2.jpg  \n",
            " extracting: DeepDRiD/train/274/274_r1.jpg  \n",
            " extracting: DeepDRiD/train/274/274_r2.jpg  \n",
            "   creating: DeepDRiD/train/275/\n",
            " extracting: DeepDRiD/train/275/275_l1.jpg  \n",
            " extracting: DeepDRiD/train/275/275_l2.jpg  \n",
            " extracting: DeepDRiD/train/275/275_r1.jpg  \n",
            " extracting: DeepDRiD/train/275/275_r2.jpg  \n",
            "   creating: DeepDRiD/train/276/\n",
            " extracting: DeepDRiD/train/276/276_l1.jpg  \n",
            " extracting: DeepDRiD/train/276/276_l2.jpg  \n",
            " extracting: DeepDRiD/train/276/276_r1.jpg  \n",
            " extracting: DeepDRiD/train/276/276_r2.jpg  \n",
            "   creating: DeepDRiD/train/278/\n",
            " extracting: DeepDRiD/train/278/278_l1.jpg  \n",
            " extracting: DeepDRiD/train/278/278_l2.jpg  \n",
            " extracting: DeepDRiD/train/278/278_r1.jpg  \n",
            " extracting: DeepDRiD/train/278/278_r2.jpg  \n",
            "   creating: DeepDRiD/train/279/\n",
            " extracting: DeepDRiD/train/279/279_l1.jpg  \n",
            " extracting: DeepDRiD/train/279/279_l2.jpg  \n",
            " extracting: DeepDRiD/train/279/279_r1.jpg  \n",
            " extracting: DeepDRiD/train/279/279_r2.jpg  \n",
            "   creating: DeepDRiD/train/28/\n",
            " extracting: DeepDRiD/train/28/28_l1.jpg  \n",
            " extracting: DeepDRiD/train/28/28_l2.jpg  \n",
            " extracting: DeepDRiD/train/28/28_r1.jpg  \n",
            " extracting: DeepDRiD/train/28/28_r2.jpg  \n",
            "   creating: DeepDRiD/train/280/\n",
            " extracting: DeepDRiD/train/280/280_l1.jpg  \n",
            " extracting: DeepDRiD/train/280/280_l2.jpg  \n",
            " extracting: DeepDRiD/train/280/280_r1.jpg  \n",
            " extracting: DeepDRiD/train/280/280_r2.jpg  \n",
            "   creating: DeepDRiD/train/281/\n",
            " extracting: DeepDRiD/train/281/281_l1.jpg  \n",
            " extracting: DeepDRiD/train/281/281_l2.jpg  \n",
            " extracting: DeepDRiD/train/281/281_r1.jpg  \n",
            " extracting: DeepDRiD/train/281/281_r2.jpg  \n",
            "   creating: DeepDRiD/train/282/\n",
            " extracting: DeepDRiD/train/282/282_l1.jpg  \n",
            " extracting: DeepDRiD/train/282/282_l2.jpg  \n",
            " extracting: DeepDRiD/train/282/282_r1.jpg  \n",
            " extracting: DeepDRiD/train/282/282_r2.jpg  \n",
            "   creating: DeepDRiD/train/283/\n",
            " extracting: DeepDRiD/train/283/283_l1.jpg  \n",
            " extracting: DeepDRiD/train/283/283_l2.jpg  \n",
            " extracting: DeepDRiD/train/283/283_r1.jpg  \n",
            " extracting: DeepDRiD/train/283/283_r2.jpg  \n",
            "   creating: DeepDRiD/train/284/\n",
            " extracting: DeepDRiD/train/284/284_l1.jpg  \n",
            " extracting: DeepDRiD/train/284/284_l2.jpg  \n",
            " extracting: DeepDRiD/train/284/284_r1.jpg  \n",
            " extracting: DeepDRiD/train/284/284_r2.jpg  \n",
            "   creating: DeepDRiD/train/285/\n",
            " extracting: DeepDRiD/train/285/285_l1.jpg  \n",
            " extracting: DeepDRiD/train/285/285_l2.jpg  \n",
            " extracting: DeepDRiD/train/285/285_r1.jpg  \n",
            " extracting: DeepDRiD/train/285/285_r2.jpg  \n",
            "   creating: DeepDRiD/train/286/\n",
            " extracting: DeepDRiD/train/286/286_l1.jpg  \n",
            " extracting: DeepDRiD/train/286/286_l2.jpg  \n",
            " extracting: DeepDRiD/train/286/286_r1.jpg  \n",
            " extracting: DeepDRiD/train/286/286_r2.jpg  \n",
            "   creating: DeepDRiD/train/287/\n",
            " extracting: DeepDRiD/train/287/287_l1.jpg  \n",
            " extracting: DeepDRiD/train/287/287_l2.jpg  \n",
            " extracting: DeepDRiD/train/287/287_r1.jpg  \n",
            " extracting: DeepDRiD/train/287/287_r2.jpg  \n",
            "   creating: DeepDRiD/train/288/\n",
            " extracting: DeepDRiD/train/288/288_l1.jpg  \n",
            " extracting: DeepDRiD/train/288/288_l2.jpg  \n",
            " extracting: DeepDRiD/train/288/288_r1.jpg  \n",
            " extracting: DeepDRiD/train/288/288_r2.jpg  \n",
            "   creating: DeepDRiD/train/289/\n",
            " extracting: DeepDRiD/train/289/289_l1.jpg  \n",
            " extracting: DeepDRiD/train/289/289_l2.jpg  \n",
            " extracting: DeepDRiD/train/289/289_r1.jpg  \n",
            " extracting: DeepDRiD/train/289/289_r2.jpg  \n",
            "   creating: DeepDRiD/train/29/\n",
            " extracting: DeepDRiD/train/29/29_l1.jpg  \n",
            " extracting: DeepDRiD/train/29/29_l2.jpg  \n",
            " extracting: DeepDRiD/train/29/29_r1.jpg  \n",
            " extracting: DeepDRiD/train/29/29_r2.jpg  \n",
            "   creating: DeepDRiD/train/290/\n",
            " extracting: DeepDRiD/train/290/290_l1.jpg  \n",
            " extracting: DeepDRiD/train/290/290_l2.jpg  \n",
            " extracting: DeepDRiD/train/290/290_r1.jpg  \n",
            " extracting: DeepDRiD/train/290/290_r2.jpg  \n",
            "   creating: DeepDRiD/train/291/\n",
            " extracting: DeepDRiD/train/291/291_l1.jpg  \n",
            " extracting: DeepDRiD/train/291/291_l2.jpg  \n",
            " extracting: DeepDRiD/train/291/291_r1.jpg  \n",
            " extracting: DeepDRiD/train/291/291_r2.jpg  \n",
            "   creating: DeepDRiD/train/292/\n",
            " extracting: DeepDRiD/train/292/292_l1.jpg  \n",
            " extracting: DeepDRiD/train/292/292_l2.jpg  \n",
            " extracting: DeepDRiD/train/292/292_r1.jpg  \n",
            " extracting: DeepDRiD/train/292/292_r2.jpg  \n",
            "   creating: DeepDRiD/train/293/\n",
            " extracting: DeepDRiD/train/293/293_l1.jpg  \n",
            " extracting: DeepDRiD/train/293/293_l2.jpg  \n",
            " extracting: DeepDRiD/train/293/293_r1.jpg  \n",
            " extracting: DeepDRiD/train/293/293_r2.jpg  \n",
            "   creating: DeepDRiD/train/295/\n",
            " extracting: DeepDRiD/train/295/295_l1.jpg  \n",
            " extracting: DeepDRiD/train/295/295_l2.jpg  \n",
            " extracting: DeepDRiD/train/295/295_r1.jpg  \n",
            " extracting: DeepDRiD/train/295/295_r2.jpg  \n",
            "   creating: DeepDRiD/train/297/\n",
            " extracting: DeepDRiD/train/297/297_l1.jpg  \n",
            " extracting: DeepDRiD/train/297/297_l2.jpg  \n",
            " extracting: DeepDRiD/train/297/297_r1.jpg  \n",
            " extracting: DeepDRiD/train/297/297_r2.jpg  \n",
            "   creating: DeepDRiD/train/3/\n",
            " extracting: DeepDRiD/train/3/3_l1.jpg  \n",
            " extracting: DeepDRiD/train/3/3_l2.jpg  \n",
            " extracting: DeepDRiD/train/3/3_r1.jpg  \n",
            " extracting: DeepDRiD/train/3/3_r2.jpg  \n",
            "   creating: DeepDRiD/train/30/\n",
            " extracting: DeepDRiD/train/30/30_l1.jpg  \n",
            " extracting: DeepDRiD/train/30/30_l2.jpg  \n",
            " extracting: DeepDRiD/train/30/30_r1.jpg  \n",
            " extracting: DeepDRiD/train/30/30_r2.jpg  \n",
            "   creating: DeepDRiD/train/302/\n",
            " extracting: DeepDRiD/train/302/302_l1.jpg  \n",
            " extracting: DeepDRiD/train/302/302_l2.jpg  \n",
            " extracting: DeepDRiD/train/302/302_r1.jpg  \n",
            " extracting: DeepDRiD/train/302/302_r2.jpg  \n",
            "   creating: DeepDRiD/train/308/\n",
            " extracting: DeepDRiD/train/308/308_l1.jpg  \n",
            " extracting: DeepDRiD/train/308/308_l2.jpg  \n",
            " extracting: DeepDRiD/train/308/308_r1.jpg  \n",
            " extracting: DeepDRiD/train/308/308_r2.jpg  \n",
            "   creating: DeepDRiD/train/31/\n",
            " extracting: DeepDRiD/train/31/31_l1.jpg  \n",
            " extracting: DeepDRiD/train/31/31_l2.jpg  \n",
            " extracting: DeepDRiD/train/31/31_r1.jpg  \n",
            " extracting: DeepDRiD/train/31/31_r2.jpg  \n",
            "   creating: DeepDRiD/train/312/\n",
            " extracting: DeepDRiD/train/312/312_l1.jpg  \n",
            " extracting: DeepDRiD/train/312/312_l2.jpg  \n",
            " extracting: DeepDRiD/train/312/312_r1.jpg  \n",
            " extracting: DeepDRiD/train/312/312_r2.jpg  \n",
            "   creating: DeepDRiD/train/313/\n",
            " extracting: DeepDRiD/train/313/313_l1.jpg  \n",
            " extracting: DeepDRiD/train/313/313_l2.jpg  \n",
            " extracting: DeepDRiD/train/313/313_r1.jpg  \n",
            " extracting: DeepDRiD/train/313/313_r2.jpg  \n",
            "   creating: DeepDRiD/train/32/\n",
            " extracting: DeepDRiD/train/32/32_l1.jpg  \n",
            " extracting: DeepDRiD/train/32/32_l2.jpg  \n",
            " extracting: DeepDRiD/train/32/32_r1.jpg  \n",
            " extracting: DeepDRiD/train/32/32_r2.jpg  \n",
            "   creating: DeepDRiD/train/324/\n",
            " extracting: DeepDRiD/train/324/324_l1.jpg  \n",
            " extracting: DeepDRiD/train/324/324_l2.jpg  \n",
            " extracting: DeepDRiD/train/324/324_r1.jpg  \n",
            " extracting: DeepDRiD/train/324/324_r2.jpg  \n",
            "   creating: DeepDRiD/train/327/\n",
            " extracting: DeepDRiD/train/327/327_l1.jpg  \n",
            " extracting: DeepDRiD/train/327/327_l2.jpg  \n",
            " extracting: DeepDRiD/train/327/327_r1.jpg  \n",
            " extracting: DeepDRiD/train/327/327_r2.jpg  \n",
            "   creating: DeepDRiD/train/329/\n",
            " extracting: DeepDRiD/train/329/329_l1.jpg  \n",
            " extracting: DeepDRiD/train/329/329_l2.jpg  \n",
            " extracting: DeepDRiD/train/329/329_r1.jpg  \n",
            " extracting: DeepDRiD/train/329/329_r2.jpg  \n",
            "   creating: DeepDRiD/train/33/\n",
            " extracting: DeepDRiD/train/33/33_l1.jpg  \n",
            " extracting: DeepDRiD/train/33/33_l2.jpg  \n",
            " extracting: DeepDRiD/train/33/33_r1.jpg  \n",
            " extracting: DeepDRiD/train/33/33_r2.jpg  \n",
            "   creating: DeepDRiD/train/330/\n",
            " extracting: DeepDRiD/train/330/330_l1.jpg  \n",
            " extracting: DeepDRiD/train/330/330_l2.jpg  \n",
            " extracting: DeepDRiD/train/330/330_r1.jpg  \n",
            " extracting: DeepDRiD/train/330/330_r2.jpg  \n",
            "   creating: DeepDRiD/train/34/\n",
            " extracting: DeepDRiD/train/34/34_l1.jpg  \n",
            " extracting: DeepDRiD/train/34/34_l2.jpg  \n",
            " extracting: DeepDRiD/train/34/34_r1.jpg  \n",
            " extracting: DeepDRiD/train/34/34_r2.jpg  \n",
            "   creating: DeepDRiD/train/35/\n",
            " extracting: DeepDRiD/train/35/35_l1.jpg  \n",
            " extracting: DeepDRiD/train/35/35_l2.jpg  \n",
            " extracting: DeepDRiD/train/35/35_r1.jpg  \n",
            " extracting: DeepDRiD/train/35/35_r2.jpg  \n",
            "   creating: DeepDRiD/train/36/\n",
            " extracting: DeepDRiD/train/36/36_l1.jpg  \n",
            " extracting: DeepDRiD/train/36/36_l2.jpg  \n",
            " extracting: DeepDRiD/train/36/36_r1.jpg  \n",
            " extracting: DeepDRiD/train/36/36_r2.jpg  \n",
            "   creating: DeepDRiD/train/37/\n",
            " extracting: DeepDRiD/train/37/37_l1.jpg  \n",
            " extracting: DeepDRiD/train/37/37_l2.jpg  \n",
            " extracting: DeepDRiD/train/37/37_r1.jpg  \n",
            " extracting: DeepDRiD/train/37/37_r2.jpg  \n",
            "   creating: DeepDRiD/train/38/\n",
            " extracting: DeepDRiD/train/38/38_l1.jpg  \n",
            " extracting: DeepDRiD/train/38/38_l2.jpg  \n",
            " extracting: DeepDRiD/train/38/38_r1.jpg  \n",
            " extracting: DeepDRiD/train/38/38_r2.jpg  \n",
            "   creating: DeepDRiD/train/39/\n",
            " extracting: DeepDRiD/train/39/39_l1.jpg  \n",
            " extracting: DeepDRiD/train/39/39_l2.jpg  \n",
            " extracting: DeepDRiD/train/39/39_r1.jpg  \n",
            " extracting: DeepDRiD/train/39/39_r2.jpg  \n",
            "   creating: DeepDRiD/train/4/\n",
            " extracting: DeepDRiD/train/4/4_l1.jpg  \n",
            " extracting: DeepDRiD/train/4/4_l2.jpg  \n",
            " extracting: DeepDRiD/train/4/4_r1.jpg  \n",
            " extracting: DeepDRiD/train/4/4_r2.jpg  \n",
            "   creating: DeepDRiD/train/40/\n",
            " extracting: DeepDRiD/train/40/40_l1.jpg  \n",
            " extracting: DeepDRiD/train/40/40_l2.jpg  \n",
            " extracting: DeepDRiD/train/40/40_r1.jpg  \n",
            " extracting: DeepDRiD/train/40/40_r2.jpg  \n",
            "   creating: DeepDRiD/train/41/\n",
            " extracting: DeepDRiD/train/41/41_l1.jpg  \n",
            " extracting: DeepDRiD/train/41/41_l2.jpg  \n",
            " extracting: DeepDRiD/train/41/41_r1.jpg  \n",
            " extracting: DeepDRiD/train/41/41_r2.jpg  \n",
            "   creating: DeepDRiD/train/42/\n",
            " extracting: DeepDRiD/train/42/42_l1.jpg  \n",
            " extracting: DeepDRiD/train/42/42_l2.jpg  \n",
            " extracting: DeepDRiD/train/42/42_r1.jpg  \n",
            " extracting: DeepDRiD/train/42/42_r2.jpg  \n",
            "   creating: DeepDRiD/train/43/\n",
            " extracting: DeepDRiD/train/43/43_l1.jpg  \n",
            " extracting: DeepDRiD/train/43/43_l2.jpg  \n",
            " extracting: DeepDRiD/train/43/43_r1.jpg  \n",
            " extracting: DeepDRiD/train/43/43_r2.jpg  \n",
            "   creating: DeepDRiD/train/44/\n",
            " extracting: DeepDRiD/train/44/44_l1.jpg  \n",
            " extracting: DeepDRiD/train/44/44_l2.jpg  \n",
            " extracting: DeepDRiD/train/44/44_r1.jpg  \n",
            " extracting: DeepDRiD/train/44/44_r2.jpg  \n",
            "   creating: DeepDRiD/train/45/\n",
            " extracting: DeepDRiD/train/45/45_l1.jpg  \n",
            " extracting: DeepDRiD/train/45/45_l2.jpg  \n",
            " extracting: DeepDRiD/train/45/45_r1.jpg  \n",
            " extracting: DeepDRiD/train/45/45_r2.jpg  \n",
            "   creating: DeepDRiD/train/46/\n",
            " extracting: DeepDRiD/train/46/46_l1.jpg  \n",
            " extracting: DeepDRiD/train/46/46_l2.jpg  \n",
            " extracting: DeepDRiD/train/46/46_r1.jpg  \n",
            " extracting: DeepDRiD/train/46/46_r2.jpg  \n",
            "   creating: DeepDRiD/train/47/\n",
            " extracting: DeepDRiD/train/47/47_l1.jpg  \n",
            " extracting: DeepDRiD/train/47/47_l2.jpg  \n",
            " extracting: DeepDRiD/train/47/47_r1.jpg  \n",
            " extracting: DeepDRiD/train/47/47_r2.jpg  \n",
            "   creating: DeepDRiD/train/48/\n",
            " extracting: DeepDRiD/train/48/48_l1.jpg  \n",
            " extracting: DeepDRiD/train/48/48_l2.jpg  \n",
            " extracting: DeepDRiD/train/48/48_r1.jpg  \n",
            " extracting: DeepDRiD/train/48/48_r2.jpg  \n",
            "   creating: DeepDRiD/train/49/\n",
            " extracting: DeepDRiD/train/49/49_l1.jpg  \n",
            " extracting: DeepDRiD/train/49/49_l2.jpg  \n",
            " extracting: DeepDRiD/train/49/49_r1.jpg  \n",
            " extracting: DeepDRiD/train/49/49_r2.jpg  \n",
            "   creating: DeepDRiD/train/5/\n",
            " extracting: DeepDRiD/train/5/5_l1.jpg  \n",
            " extracting: DeepDRiD/train/5/5_l2.jpg  \n",
            " extracting: DeepDRiD/train/5/5_r1.jpg  \n",
            " extracting: DeepDRiD/train/5/5_r2.jpg  \n",
            "   creating: DeepDRiD/train/50/\n",
            " extracting: DeepDRiD/train/50/50_l1.jpg  \n",
            " extracting: DeepDRiD/train/50/50_l2.jpg  \n",
            " extracting: DeepDRiD/train/50/50_r1.jpg  \n",
            " extracting: DeepDRiD/train/50/50_r2.jpg  \n",
            "   creating: DeepDRiD/train/51/\n",
            " extracting: DeepDRiD/train/51/51_l1.jpg  \n",
            " extracting: DeepDRiD/train/51/51_l2.jpg  \n",
            " extracting: DeepDRiD/train/51/51_r1.jpg  \n",
            " extracting: DeepDRiD/train/51/51_r2.jpg  \n",
            "   creating: DeepDRiD/train/52/\n",
            " extracting: DeepDRiD/train/52/52_l1.jpg  \n",
            " extracting: DeepDRiD/train/52/52_l2.jpg  \n",
            " extracting: DeepDRiD/train/52/52_r1.jpg  \n",
            " extracting: DeepDRiD/train/52/52_r2.jpg  \n",
            "   creating: DeepDRiD/train/53/\n",
            " extracting: DeepDRiD/train/53/53_l1.jpg  \n",
            " extracting: DeepDRiD/train/53/53_l2.jpg  \n",
            " extracting: DeepDRiD/train/53/53_r1.jpg  \n",
            " extracting: DeepDRiD/train/53/53_r2.jpg  \n",
            "   creating: DeepDRiD/train/54/\n",
            " extracting: DeepDRiD/train/54/54_l1.jpg  \n",
            " extracting: DeepDRiD/train/54/54_l2.jpg  \n",
            " extracting: DeepDRiD/train/54/54_r1.jpg  \n",
            " extracting: DeepDRiD/train/54/54_r2.jpg  \n",
            "   creating: DeepDRiD/train/55/\n",
            " extracting: DeepDRiD/train/55/55_l1.jpg  \n",
            " extracting: DeepDRiD/train/55/55_l2.jpg  \n",
            " extracting: DeepDRiD/train/55/55_r1.jpg  \n",
            " extracting: DeepDRiD/train/55/55_r2.jpg  \n",
            "   creating: DeepDRiD/train/56/\n",
            " extracting: DeepDRiD/train/56/56_l1.jpg  \n",
            " extracting: DeepDRiD/train/56/56_l3.jpg  \n",
            " extracting: DeepDRiD/train/56/56_r2.jpg  \n",
            " extracting: DeepDRiD/train/56/56_r3.jpg  \n",
            "   creating: DeepDRiD/train/57/\n",
            " extracting: DeepDRiD/train/57/57_l1.jpg  \n",
            " extracting: DeepDRiD/train/57/57_l2.jpg  \n",
            " extracting: DeepDRiD/train/57/57_r1.jpg  \n",
            " extracting: DeepDRiD/train/57/57_r2.jpg  \n",
            "   creating: DeepDRiD/train/58/\n",
            " extracting: DeepDRiD/train/58/58_l1.jpg  \n",
            " extracting: DeepDRiD/train/58/58_l2.jpg  \n",
            " extracting: DeepDRiD/train/58/58_r1.jpg  \n",
            " extracting: DeepDRiD/train/58/58_r2.jpg  \n",
            "   creating: DeepDRiD/train/59/\n",
            " extracting: DeepDRiD/train/59/59_l1.jpg  \n",
            " extracting: DeepDRiD/train/59/59_l2.jpg  \n",
            " extracting: DeepDRiD/train/59/59_r1.jpg  \n",
            " extracting: DeepDRiD/train/59/59_r2.jpg  \n",
            "   creating: DeepDRiD/train/6/\n",
            " extracting: DeepDRiD/train/6/6_l1.jpg  \n",
            " extracting: DeepDRiD/train/6/6_l2.jpg  \n",
            " extracting: DeepDRiD/train/6/6_r1.jpg  \n",
            " extracting: DeepDRiD/train/6/6_r2.jpg  \n",
            "   creating: DeepDRiD/train/60/\n",
            " extracting: DeepDRiD/train/60/60_l1.jpg  \n",
            " extracting: DeepDRiD/train/60/60_l2.jpg  \n",
            " extracting: DeepDRiD/train/60/60_r1.jpg  \n",
            " extracting: DeepDRiD/train/60/60_r2.jpg  \n",
            "   creating: DeepDRiD/train/61/\n",
            " extracting: DeepDRiD/train/61/61_l1.jpg  \n",
            " extracting: DeepDRiD/train/61/61_l2.jpg  \n",
            " extracting: DeepDRiD/train/61/61_r1.jpg  \n",
            " extracting: DeepDRiD/train/61/61_r2.jpg  \n",
            "   creating: DeepDRiD/train/62/\n",
            " extracting: DeepDRiD/train/62/62_l1.jpg  \n",
            " extracting: DeepDRiD/train/62/62_l2.jpg  \n",
            " extracting: DeepDRiD/train/62/62_r1.jpg  \n",
            " extracting: DeepDRiD/train/62/62_r2.jpg  \n",
            "   creating: DeepDRiD/train/63/\n",
            " extracting: DeepDRiD/train/63/63_l1.jpg  \n",
            " extracting: DeepDRiD/train/63/63_l2.jpg  \n",
            " extracting: DeepDRiD/train/63/63_r1.jpg  \n",
            " extracting: DeepDRiD/train/63/63_r2.jpg  \n",
            "   creating: DeepDRiD/train/64/\n",
            " extracting: DeepDRiD/train/64/64_l1.jpg  \n",
            " extracting: DeepDRiD/train/64/64_l2.jpg  \n",
            " extracting: DeepDRiD/train/64/64_r1.jpg  \n",
            " extracting: DeepDRiD/train/64/64_r2.jpg  \n",
            "   creating: DeepDRiD/train/65/\n",
            " extracting: DeepDRiD/train/65/65_l1.jpg  \n",
            " extracting: DeepDRiD/train/65/65_l2.jpg  \n",
            " extracting: DeepDRiD/train/65/65_r1.jpg  \n",
            " extracting: DeepDRiD/train/65/65_r2.jpg  \n",
            "   creating: DeepDRiD/train/66/\n",
            " extracting: DeepDRiD/train/66/66_l1.jpg  \n",
            " extracting: DeepDRiD/train/66/66_l2.jpg  \n",
            " extracting: DeepDRiD/train/66/66_r1.jpg  \n",
            " extracting: DeepDRiD/train/66/66_r2.jpg  \n",
            "   creating: DeepDRiD/train/67/\n",
            " extracting: DeepDRiD/train/67/67_l1.jpg  \n",
            " extracting: DeepDRiD/train/67/67_l2.jpg  \n",
            " extracting: DeepDRiD/train/67/67_r1.jpg  \n",
            " extracting: DeepDRiD/train/67/67_r2.jpg  \n",
            "   creating: DeepDRiD/train/68/\n",
            " extracting: DeepDRiD/train/68/68_l1.jpg  \n",
            " extracting: DeepDRiD/train/68/68_l2.jpg  \n",
            " extracting: DeepDRiD/train/68/68_r1.jpg  \n",
            " extracting: DeepDRiD/train/68/68_r2.jpg  \n",
            "   creating: DeepDRiD/train/69/\n",
            " extracting: DeepDRiD/train/69/69_l1.jpg  \n",
            " extracting: DeepDRiD/train/69/69_l2.jpg  \n",
            " extracting: DeepDRiD/train/69/69_r1.jpg  \n",
            " extracting: DeepDRiD/train/69/69_r2.jpg  \n",
            "   creating: DeepDRiD/train/7/\n",
            " extracting: DeepDRiD/train/7/7_l1.jpg  \n",
            " extracting: DeepDRiD/train/7/7_l2.jpg  \n",
            " extracting: DeepDRiD/train/7/7_r1.jpg  \n",
            " extracting: DeepDRiD/train/7/7_r2.jpg  \n",
            "   creating: DeepDRiD/train/70/\n",
            " extracting: DeepDRiD/train/70/70_l1.jpg  \n",
            " extracting: DeepDRiD/train/70/70_l2.jpg  \n",
            " extracting: DeepDRiD/train/70/70_r1.jpg  \n",
            " extracting: DeepDRiD/train/70/70_r2.jpg  \n",
            "   creating: DeepDRiD/train/71/\n",
            " extracting: DeepDRiD/train/71/71_l1.jpg  \n",
            " extracting: DeepDRiD/train/71/71_l2.jpg  \n",
            " extracting: DeepDRiD/train/71/71_r1.jpg  \n",
            " extracting: DeepDRiD/train/71/71_r2.jpg  \n",
            "   creating: DeepDRiD/train/72/\n",
            " extracting: DeepDRiD/train/72/72_l1.jpg  \n",
            " extracting: DeepDRiD/train/72/72_l2.jpg  \n",
            " extracting: DeepDRiD/train/72/72_r1.jpg  \n",
            " extracting: DeepDRiD/train/72/72_r2.jpg  \n",
            "   creating: DeepDRiD/train/73/\n",
            " extracting: DeepDRiD/train/73/73_l1.jpg  \n",
            " extracting: DeepDRiD/train/73/73_l2.jpg  \n",
            " extracting: DeepDRiD/train/73/73_r1.jpg  \n",
            " extracting: DeepDRiD/train/73/73_r2.jpg  \n",
            "   creating: DeepDRiD/train/74/\n",
            " extracting: DeepDRiD/train/74/74_l1.jpg  \n",
            " extracting: DeepDRiD/train/74/74_l2.jpg  \n",
            " extracting: DeepDRiD/train/74/74_r1.jpg  \n",
            " extracting: DeepDRiD/train/74/74_r2.jpg  \n",
            "   creating: DeepDRiD/train/75/\n",
            " extracting: DeepDRiD/train/75/75_l1.jpg  \n",
            " extracting: DeepDRiD/train/75/75_l2.jpg  \n",
            " extracting: DeepDRiD/train/75/75_r1.jpg  \n",
            " extracting: DeepDRiD/train/75/75_r2.jpg  \n",
            "   creating: DeepDRiD/train/76/\n",
            " extracting: DeepDRiD/train/76/76_l1.jpg  \n",
            " extracting: DeepDRiD/train/76/76_l2.jpg  \n",
            " extracting: DeepDRiD/train/76/76_r1.jpg  \n",
            " extracting: DeepDRiD/train/76/76_r2.jpg  \n",
            "   creating: DeepDRiD/train/77/\n",
            " extracting: DeepDRiD/train/77/77_l3.jpg  \n",
            " extracting: DeepDRiD/train/77/77_l4.jpg  \n",
            " extracting: DeepDRiD/train/77/77_r3.jpg  \n",
            " extracting: DeepDRiD/train/77/77_r4.jpg  \n",
            "   creating: DeepDRiD/train/78/\n",
            " extracting: DeepDRiD/train/78/78_l1.jpg  \n",
            " extracting: DeepDRiD/train/78/78_l2.jpg  \n",
            " extracting: DeepDRiD/train/78/78_r1.jpg  \n",
            " extracting: DeepDRiD/train/78/78_r2.jpg  \n",
            "   creating: DeepDRiD/train/79/\n",
            " extracting: DeepDRiD/train/79/79_l1.jpg  \n",
            " extracting: DeepDRiD/train/79/79_l2.jpg  \n",
            " extracting: DeepDRiD/train/79/79_r1.jpg  \n",
            " extracting: DeepDRiD/train/79/79_r2.jpg  \n",
            "   creating: DeepDRiD/train/8/\n",
            " extracting: DeepDRiD/train/8/8_l1.jpg  \n",
            " extracting: DeepDRiD/train/8/8_l2.jpg  \n",
            " extracting: DeepDRiD/train/8/8_r1.jpg  \n",
            " extracting: DeepDRiD/train/8/8_r2.jpg  \n",
            "   creating: DeepDRiD/train/80/\n",
            " extracting: DeepDRiD/train/80/80_l1.jpg  \n",
            " extracting: DeepDRiD/train/80/80_l2.jpg  \n",
            " extracting: DeepDRiD/train/80/80_r1.jpg  \n",
            " extracting: DeepDRiD/train/80/80_r2.jpg  \n",
            "   creating: DeepDRiD/train/81/\n",
            " extracting: DeepDRiD/train/81/81_l1.jpg  \n",
            " extracting: DeepDRiD/train/81/81_l2.jpg  \n",
            " extracting: DeepDRiD/train/81/81_r1.jpg  \n",
            " extracting: DeepDRiD/train/81/81_r2.jpg  \n",
            "   creating: DeepDRiD/train/82/\n",
            " extracting: DeepDRiD/train/82/82_l1.jpg  \n",
            " extracting: DeepDRiD/train/82/82_l2.jpg  \n",
            " extracting: DeepDRiD/train/82/82_r1.jpg  \n",
            " extracting: DeepDRiD/train/82/82_r2.jpg  \n",
            "   creating: DeepDRiD/train/83/\n",
            " extracting: DeepDRiD/train/83/83_l1.jpg  \n",
            " extracting: DeepDRiD/train/83/83_l2.jpg  \n",
            " extracting: DeepDRiD/train/83/83_r1.jpg  \n",
            " extracting: DeepDRiD/train/83/83_r2.jpg  \n",
            "   creating: DeepDRiD/train/84/\n",
            " extracting: DeepDRiD/train/84/84_l1.jpg  \n",
            " extracting: DeepDRiD/train/84/84_l2.jpg  \n",
            " extracting: DeepDRiD/train/84/84_r1.jpg  \n",
            " extracting: DeepDRiD/train/84/84_r2.jpg  \n",
            "   creating: DeepDRiD/train/85/\n",
            " extracting: DeepDRiD/train/85/85_l1.jpg  \n",
            " extracting: DeepDRiD/train/85/85_l2.jpg  \n",
            " extracting: DeepDRiD/train/85/85_r1.jpg  \n",
            " extracting: DeepDRiD/train/85/85_r2.jpg  \n",
            "   creating: DeepDRiD/train/86/\n",
            " extracting: DeepDRiD/train/86/86_l1.jpg  \n",
            " extracting: DeepDRiD/train/86/86_l2.jpg  \n",
            " extracting: DeepDRiD/train/86/86_r1.jpg  \n",
            " extracting: DeepDRiD/train/86/86_r2.jpg  \n",
            "   creating: DeepDRiD/train/87/\n",
            " extracting: DeepDRiD/train/87/87_l1.jpg  \n",
            " extracting: DeepDRiD/train/87/87_l2.jpg  \n",
            " extracting: DeepDRiD/train/87/87_r1.jpg  \n",
            " extracting: DeepDRiD/train/87/87_r2.jpg  \n",
            "   creating: DeepDRiD/train/88/\n",
            " extracting: DeepDRiD/train/88/88_l1.jpg  \n",
            " extracting: DeepDRiD/train/88/88_l2.jpg  \n",
            " extracting: DeepDRiD/train/88/88_r1.jpg  \n",
            " extracting: DeepDRiD/train/88/88_r2.jpg  \n",
            "   creating: DeepDRiD/train/89/\n",
            " extracting: DeepDRiD/train/89/89_l1.jpg  \n",
            " extracting: DeepDRiD/train/89/89_l2.jpg  \n",
            " extracting: DeepDRiD/train/89/89_r1.jpg  \n",
            " extracting: DeepDRiD/train/89/89_r2.jpg  \n",
            "   creating: DeepDRiD/train/9/\n",
            " extracting: DeepDRiD/train/9/9_l1.jpg  \n",
            " extracting: DeepDRiD/train/9/9_l2.jpg  \n",
            " extracting: DeepDRiD/train/9/9_r1.jpg  \n",
            " extracting: DeepDRiD/train/9/9_r2.jpg  \n",
            "   creating: DeepDRiD/train/90/\n",
            " extracting: DeepDRiD/train/90/90_l1.jpg  \n",
            " extracting: DeepDRiD/train/90/90_l2.jpg  \n",
            " extracting: DeepDRiD/train/90/90_r1.jpg  \n",
            " extracting: DeepDRiD/train/90/90_r2.jpg  \n",
            "   creating: DeepDRiD/train/91/\n",
            " extracting: DeepDRiD/train/91/91_l1.jpg  \n",
            " extracting: DeepDRiD/train/91/91_l2.jpg  \n",
            " extracting: DeepDRiD/train/91/91_r1.jpg  \n",
            " extracting: DeepDRiD/train/91/91_r2.jpg  \n",
            "   creating: DeepDRiD/train/92/\n",
            " extracting: DeepDRiD/train/92/92_l1.jpg  \n",
            " extracting: DeepDRiD/train/92/92_l2.jpg  \n",
            " extracting: DeepDRiD/train/92/92_r1.jpg  \n",
            " extracting: DeepDRiD/train/92/92_r2.jpg  \n",
            "   creating: DeepDRiD/train/93/\n",
            " extracting: DeepDRiD/train/93/93_l1.jpg  \n",
            " extracting: DeepDRiD/train/93/93_l2.jpg  \n",
            " extracting: DeepDRiD/train/93/93_r1.jpg  \n",
            " extracting: DeepDRiD/train/93/93_r2.jpg  \n",
            "   creating: DeepDRiD/train/94/\n",
            " extracting: DeepDRiD/train/94/94_l1.jpg  \n",
            " extracting: DeepDRiD/train/94/94_l2.jpg  \n",
            " extracting: DeepDRiD/train/94/94_r1.jpg  \n",
            " extracting: DeepDRiD/train/94/94_r2.jpg  \n",
            "   creating: DeepDRiD/train/95/\n",
            " extracting: DeepDRiD/train/95/95_l1.jpg  \n",
            " extracting: DeepDRiD/train/95/95_l2.jpg  \n",
            " extracting: DeepDRiD/train/95/95_r1.jpg  \n",
            " extracting: DeepDRiD/train/95/95_r2.jpg  \n",
            "   creating: DeepDRiD/train/96/\n",
            " extracting: DeepDRiD/train/96/96_l1.jpg  \n",
            " extracting: DeepDRiD/train/96/96_l2.jpg  \n",
            " extracting: DeepDRiD/train/96/96_r1.jpg  \n",
            " extracting: DeepDRiD/train/96/96_r2.jpg  \n",
            "   creating: DeepDRiD/train/97/\n",
            " extracting: DeepDRiD/train/97/97_l1.jpg  \n",
            " extracting: DeepDRiD/train/97/97_l2.jpg  \n",
            " extracting: DeepDRiD/train/97/97_r1.jpg  \n",
            " extracting: DeepDRiD/train/97/97_r2.jpg  \n",
            "   creating: DeepDRiD/train/98/\n",
            " extracting: DeepDRiD/train/98/98_l1.jpg  \n",
            " extracting: DeepDRiD/train/98/98_l2.jpg  \n",
            " extracting: DeepDRiD/train/98/98_r1.jpg  \n",
            " extracting: DeepDRiD/train/98/98_r2.jpg  \n",
            "   creating: DeepDRiD/train/99/\n",
            " extracting: DeepDRiD/train/99/99_l1.jpg  \n",
            " extracting: DeepDRiD/train/99/99_l2.jpg  \n",
            " extracting: DeepDRiD/train/99/99_r1.jpg  \n",
            " extracting: DeepDRiD/train/99/99_r2.jpg  \n",
            " extracting: DeepDRiD/val.csv        \n",
            "   creating: DeepDRiD/val/\n",
            "   creating: DeepDRiD/val/265/\n",
            " extracting: DeepDRiD/val/265/265_l1.jpg  \n",
            " extracting: DeepDRiD/val/265/265_l2.jpg  \n",
            " extracting: DeepDRiD/val/265/265_r1.jpg  \n",
            " extracting: DeepDRiD/val/265/265_r2.jpg  \n",
            "   creating: DeepDRiD/val/267/\n",
            " extracting: DeepDRiD/val/267/267_l1.jpg  \n",
            " extracting: DeepDRiD/val/267/267_l2.jpg  \n",
            " extracting: DeepDRiD/val/267/267_r1.jpg  \n",
            " extracting: DeepDRiD/val/267/267_r2.jpg  \n",
            "   creating: DeepDRiD/val/277/\n",
            " extracting: DeepDRiD/val/277/277_l1.jpg  \n",
            " extracting: DeepDRiD/val/277/277_l2.jpg  \n",
            " extracting: DeepDRiD/val/277/277_r1.jpg  \n",
            " extracting: DeepDRiD/val/277/277_r2.jpg  \n",
            "   creating: DeepDRiD/val/294/\n",
            " extracting: DeepDRiD/val/294/294_l1.jpg  \n",
            " extracting: DeepDRiD/val/294/294_l2.jpg  \n",
            " extracting: DeepDRiD/val/294/294_r1.jpg  \n",
            " extracting: DeepDRiD/val/294/294_r2.jpg  \n",
            "   creating: DeepDRiD/val/296/\n",
            " extracting: DeepDRiD/val/296/296_l1.jpg  \n",
            " extracting: DeepDRiD/val/296/296_l2.jpg  \n",
            " extracting: DeepDRiD/val/296/296_r1.jpg  \n",
            " extracting: DeepDRiD/val/296/296_r2.jpg  \n",
            "   creating: DeepDRiD/val/298/\n",
            " extracting: DeepDRiD/val/298/298_l1.jpg  \n",
            " extracting: DeepDRiD/val/298/298_l2.jpg  \n",
            " extracting: DeepDRiD/val/298/298_r1.jpg  \n",
            " extracting: DeepDRiD/val/298/298_r2.jpg  \n",
            "   creating: DeepDRiD/val/299/\n",
            " extracting: DeepDRiD/val/299/299_l1.jpg  \n",
            " extracting: DeepDRiD/val/299/299_l2.jpg  \n",
            " extracting: DeepDRiD/val/299/299_r1.jpg  \n",
            " extracting: DeepDRiD/val/299/299_r2.jpg  \n",
            "   creating: DeepDRiD/val/300/\n",
            " extracting: DeepDRiD/val/300/300_l1.jpg  \n",
            " extracting: DeepDRiD/val/300/300_l2.jpg  \n",
            " extracting: DeepDRiD/val/300/300_r1.jpg  \n",
            " extracting: DeepDRiD/val/300/300_r2.jpg  \n",
            "   creating: DeepDRiD/val/301/\n",
            " extracting: DeepDRiD/val/301/301_l1.jpg  \n",
            " extracting: DeepDRiD/val/301/301_l2.jpg  \n",
            " extracting: DeepDRiD/val/301/301_r1.jpg  \n",
            " extracting: DeepDRiD/val/301/301_r2.jpg  \n",
            "   creating: DeepDRiD/val/303/\n",
            " extracting: DeepDRiD/val/303/303_l1.jpg  \n",
            " extracting: DeepDRiD/val/303/303_l2.jpg  \n",
            " extracting: DeepDRiD/val/303/303_r1.jpg  \n",
            " extracting: DeepDRiD/val/303/303_r2.jpg  \n",
            "   creating: DeepDRiD/val/304/\n",
            " extracting: DeepDRiD/val/304/304_l1.jpg  \n",
            " extracting: DeepDRiD/val/304/304_l2.jpg  \n",
            " extracting: DeepDRiD/val/304/304_r1.jpg  \n",
            " extracting: DeepDRiD/val/304/304_r2.jpg  \n",
            "   creating: DeepDRiD/val/305/\n",
            " extracting: DeepDRiD/val/305/305_l1.jpg  \n",
            " extracting: DeepDRiD/val/305/305_l2.jpg  \n",
            " extracting: DeepDRiD/val/305/305_r1.jpg  \n",
            " extracting: DeepDRiD/val/305/305_r2.jpg  \n",
            "   creating: DeepDRiD/val/306/\n",
            " extracting: DeepDRiD/val/306/306_l1.jpg  \n",
            " extracting: DeepDRiD/val/306/306_l2.jpg  \n",
            " extracting: DeepDRiD/val/306/306_r1.jpg  \n",
            " extracting: DeepDRiD/val/306/306_r2.jpg  \n",
            "   creating: DeepDRiD/val/307/\n",
            " extracting: DeepDRiD/val/307/307_l1.jpg  \n",
            " extracting: DeepDRiD/val/307/307_l2.jpg  \n",
            " extracting: DeepDRiD/val/307/307_r1.jpg  \n",
            " extracting: DeepDRiD/val/307/307_r2.jpg  \n",
            "   creating: DeepDRiD/val/309/\n",
            " extracting: DeepDRiD/val/309/309_l1.jpg  \n",
            " extracting: DeepDRiD/val/309/309_l2.jpg  \n",
            " extracting: DeepDRiD/val/309/309_r1.jpg  \n",
            " extracting: DeepDRiD/val/309/309_r2.jpg  \n",
            "   creating: DeepDRiD/val/310/\n",
            " extracting: DeepDRiD/val/310/310_l1.jpg  \n",
            " extracting: DeepDRiD/val/310/310_l2.jpg  \n",
            " extracting: DeepDRiD/val/310/310_r1.jpg  \n",
            " extracting: DeepDRiD/val/310/310_r2.jpg  \n",
            "   creating: DeepDRiD/val/311/\n",
            " extracting: DeepDRiD/val/311/311_l1.jpg  \n",
            " extracting: DeepDRiD/val/311/311_l2.jpg  \n",
            " extracting: DeepDRiD/val/311/311_r1.jpg  \n",
            " extracting: DeepDRiD/val/311/311_r2.jpg  \n",
            "   creating: DeepDRiD/val/314/\n",
            " extracting: DeepDRiD/val/314/314_l1.jpg  \n",
            " extracting: DeepDRiD/val/314/314_l2.jpg  \n",
            " extracting: DeepDRiD/val/314/314_r1.jpg  \n",
            " extracting: DeepDRiD/val/314/314_r2.jpg  \n",
            "   creating: DeepDRiD/val/315/\n",
            " extracting: DeepDRiD/val/315/315_l1.jpg  \n",
            " extracting: DeepDRiD/val/315/315_l2.jpg  \n",
            " extracting: DeepDRiD/val/315/315_r1.jpg  \n",
            " extracting: DeepDRiD/val/315/315_r2.jpg  \n",
            "   creating: DeepDRiD/val/316/\n",
            " extracting: DeepDRiD/val/316/316_l1.jpg  \n",
            " extracting: DeepDRiD/val/316/316_l2.jpg  \n",
            " extracting: DeepDRiD/val/316/316_r1.jpg  \n",
            " extracting: DeepDRiD/val/316/316_r2.jpg  \n",
            "   creating: DeepDRiD/val/317/\n",
            " extracting: DeepDRiD/val/317/317_l1.jpg  \n",
            " extracting: DeepDRiD/val/317/317_l2.jpg  \n",
            " extracting: DeepDRiD/val/317/317_r1.jpg  \n",
            " extracting: DeepDRiD/val/317/317_r2.jpg  \n",
            "   creating: DeepDRiD/val/318/\n",
            " extracting: DeepDRiD/val/318/318_l1.jpg  \n",
            " extracting: DeepDRiD/val/318/318_l2.jpg  \n",
            " extracting: DeepDRiD/val/318/318_r1.jpg  \n",
            " extracting: DeepDRiD/val/318/318_r2.jpg  \n",
            "   creating: DeepDRiD/val/319/\n",
            " extracting: DeepDRiD/val/319/319_l1.jpg  \n",
            " extracting: DeepDRiD/val/319/319_l2.jpg  \n",
            " extracting: DeepDRiD/val/319/319_r1.jpg  \n",
            " extracting: DeepDRiD/val/319/319_r2.jpg  \n",
            "   creating: DeepDRiD/val/320/\n",
            " extracting: DeepDRiD/val/320/320_l1.jpg  \n",
            " extracting: DeepDRiD/val/320/320_l2.jpg  \n",
            " extracting: DeepDRiD/val/320/320_r1.jpg  \n",
            " extracting: DeepDRiD/val/320/320_r2.jpg  \n",
            "   creating: DeepDRiD/val/321/\n",
            " extracting: DeepDRiD/val/321/321_l1.jpg  \n",
            " extracting: DeepDRiD/val/321/321_l2.jpg  \n",
            " extracting: DeepDRiD/val/321/321_r1.jpg  \n",
            " extracting: DeepDRiD/val/321/321_r2.jpg  \n",
            "   creating: DeepDRiD/val/322/\n",
            " extracting: DeepDRiD/val/322/322_l1.jpg  \n",
            " extracting: DeepDRiD/val/322/322_l2.jpg  \n",
            " extracting: DeepDRiD/val/322/322_r1.jpg  \n",
            " extracting: DeepDRiD/val/322/322_r2.jpg  \n",
            "   creating: DeepDRiD/val/323/\n",
            " extracting: DeepDRiD/val/323/323_l1.jpg  \n",
            " extracting: DeepDRiD/val/323/323_l2.jpg  \n",
            " extracting: DeepDRiD/val/323/323_r1.jpg  \n",
            " extracting: DeepDRiD/val/323/323_r2.jpg  \n",
            "   creating: DeepDRiD/val/325/\n",
            " extracting: DeepDRiD/val/325/325_l1.jpg  \n",
            " extracting: DeepDRiD/val/325/325_l2.jpg  \n",
            " extracting: DeepDRiD/val/325/325_r1.jpg  \n",
            " extracting: DeepDRiD/val/325/325_r2.jpg  \n",
            "   creating: DeepDRiD/val/326/\n",
            " extracting: DeepDRiD/val/326/326_l1.jpg  \n",
            " extracting: DeepDRiD/val/326/326_l2.jpg  \n",
            " extracting: DeepDRiD/val/326/326_r1.jpg  \n",
            " extracting: DeepDRiD/val/326/326_r2.jpg  \n",
            "   creating: DeepDRiD/val/328/\n",
            " extracting: DeepDRiD/val/328/328_l1.jpg  \n",
            " extracting: DeepDRiD/val/328/328_l2.jpg  \n",
            " extracting: DeepDRiD/val/328/328_r1.jpg  \n",
            " extracting: DeepDRiD/val/328/328_r2.jpg  \n",
            "   creating: DeepDRiD/val/331/\n",
            " extracting: DeepDRiD/val/331/331_l1.jpg  \n",
            " extracting: DeepDRiD/val/331/331_l2.jpg  \n",
            " extracting: DeepDRiD/val/331/331_r1.jpg  \n",
            " extracting: DeepDRiD/val/331/331_r2.jpg  \n",
            "   creating: DeepDRiD/val/332/\n",
            " extracting: DeepDRiD/val/332/332_l1.jpg  \n",
            " extracting: DeepDRiD/val/332/332_l2.jpg  \n",
            " extracting: DeepDRiD/val/332/332_r1.jpg  \n",
            " extracting: DeepDRiD/val/332/332_r2.jpg  \n",
            "   creating: DeepDRiD/val/333/\n",
            " extracting: DeepDRiD/val/333/333_l1.jpg  \n",
            " extracting: DeepDRiD/val/333/333_l2.jpg  \n",
            " extracting: DeepDRiD/val/333/333_r1.jpg  \n",
            " extracting: DeepDRiD/val/333/333_r2.jpg  \n",
            "   creating: DeepDRiD/val/334/\n",
            " extracting: DeepDRiD/val/334/334_l1.jpg  \n",
            " extracting: DeepDRiD/val/334/334_l2.jpg  \n",
            " extracting: DeepDRiD/val/334/334_r1.jpg  \n",
            " extracting: DeepDRiD/val/334/334_r2.jpg  \n",
            "   creating: DeepDRiD/val/335/\n",
            " extracting: DeepDRiD/val/335/335_l1.jpg  \n",
            " extracting: DeepDRiD/val/335/335_l2.jpg  \n",
            " extracting: DeepDRiD/val/335/335_r1.jpg  \n",
            " extracting: DeepDRiD/val/335/335_r2.jpg  \n",
            "   creating: DeepDRiD/val/336/\n",
            " extracting: DeepDRiD/val/336/336_l1.jpg  \n",
            " extracting: DeepDRiD/val/336/336_l2.jpg  \n",
            " extracting: DeepDRiD/val/336/336_r1.jpg  \n",
            " extracting: DeepDRiD/val/336/336_r2.jpg  \n",
            "   creating: DeepDRiD/val/337/\n",
            " extracting: DeepDRiD/val/337/337_l1.jpg  \n",
            " extracting: DeepDRiD/val/337/337_l2.jpg  \n",
            " extracting: DeepDRiD/val/337/337_r1.jpg  \n",
            " extracting: DeepDRiD/val/337/337_r2.jpg  \n",
            "   creating: DeepDRiD/val/338/\n",
            " extracting: DeepDRiD/val/338/338_l1.jpg  \n",
            " extracting: DeepDRiD/val/338/338_l2.jpg  \n",
            " extracting: DeepDRiD/val/338/338_r1.jpg  \n",
            " extracting: DeepDRiD/val/338/338_r2.jpg  \n",
            "   creating: DeepDRiD/val/339/\n",
            " extracting: DeepDRiD/val/339/339_l1.jpg  \n",
            " extracting: DeepDRiD/val/339/339_l2.jpg  \n",
            " extracting: DeepDRiD/val/339/339_r1.jpg  \n",
            " extracting: DeepDRiD/val/339/339_r2.jpg  \n",
            "   creating: DeepDRiD/val/340/\n",
            " extracting: DeepDRiD/val/340/340_l1.jpg  \n",
            " extracting: DeepDRiD/val/340/340_l2.jpg  \n",
            " extracting: DeepDRiD/val/340/340_r1.jpg  \n",
            " extracting: DeepDRiD/val/340/340_r2.jpg  \n",
            "   creating: DeepDRiD/val/341/\n",
            " extracting: DeepDRiD/val/341/341_l1.jpg  \n",
            " extracting: DeepDRiD/val/341/341_l2.jpg  \n",
            " extracting: DeepDRiD/val/341/341_r1.jpg  \n",
            " extracting: DeepDRiD/val/341/341_r2.jpg  \n",
            "   creating: DeepDRiD/val/342/\n",
            " extracting: DeepDRiD/val/342/342_l1.jpg  \n",
            " extracting: DeepDRiD/val/342/342_l2.jpg  \n",
            " extracting: DeepDRiD/val/342/342_r1.jpg  \n",
            " extracting: DeepDRiD/val/342/342_r2.jpg  \n",
            "   creating: DeepDRiD/val/343/\n",
            " extracting: DeepDRiD/val/343/343_l1.jpg  \n",
            " extracting: DeepDRiD/val/343/343_l2.jpg  \n",
            " extracting: DeepDRiD/val/343/343_r1.jpg  \n",
            " extracting: DeepDRiD/val/343/343_r2.jpg  \n",
            "   creating: DeepDRiD/val/344/\n",
            " extracting: DeepDRiD/val/344/344_l1.jpg  \n",
            " extracting: DeepDRiD/val/344/344_l2.jpg  \n",
            " extracting: DeepDRiD/val/344/344_r1.jpg  \n",
            " extracting: DeepDRiD/val/344/344_r2.jpg  \n",
            "   creating: DeepDRiD/val/345/\n",
            " extracting: DeepDRiD/val/345/345_l1.jpg  \n",
            " extracting: DeepDRiD/val/345/345_l2.jpg  \n",
            " extracting: DeepDRiD/val/345/345_r1.jpg  \n",
            " extracting: DeepDRiD/val/345/345_r2.jpg  \n",
            "   creating: DeepDRiD/val/346/\n",
            " extracting: DeepDRiD/val/346/346_l1.jpg  \n",
            " extracting: DeepDRiD/val/346/346_l2.jpg  \n",
            " extracting: DeepDRiD/val/346/346_r1.jpg  \n",
            " extracting: DeepDRiD/val/346/346_r2.jpg  \n",
            "   creating: DeepDRiD/val/348/\n",
            " extracting: DeepDRiD/val/348/348_l1.jpg  \n",
            " extracting: DeepDRiD/val/348/348_l2.jpg  \n",
            " extracting: DeepDRiD/val/348/348_r1.jpg  \n",
            " extracting: DeepDRiD/val/348/348_r2.jpg  \n",
            "   creating: DeepDRiD/val/349/\n",
            " extracting: DeepDRiD/val/349/349_l1.jpg  \n",
            " extracting: DeepDRiD/val/349/349_l2.jpg  \n",
            " extracting: DeepDRiD/val/349/349_r1.jpg  \n",
            " extracting: DeepDRiD/val/349/349_r2.jpg  \n",
            "   creating: DeepDRiD/val/350/\n",
            " extracting: DeepDRiD/val/350/350_l1.jpg  \n",
            " extracting: DeepDRiD/val/350/350_l2.jpg  \n",
            " extracting: DeepDRiD/val/350/350_r1.jpg  \n",
            " extracting: DeepDRiD/val/350/350_r2.jpg  \n",
            "   creating: DeepDRiD/val/351/\n",
            " extracting: DeepDRiD/val/351/351_l1.jpg  \n",
            " extracting: DeepDRiD/val/351/351_l2.jpg  \n",
            " extracting: DeepDRiD/val/351/351_r1.jpg  \n",
            " extracting: DeepDRiD/val/351/351_r2.jpg  \n",
            "   creating: DeepDRiD/val/352/\n",
            " extracting: DeepDRiD/val/352/352_l1.jpg  \n",
            " extracting: DeepDRiD/val/352/352_l2.jpg  \n",
            " extracting: DeepDRiD/val/352/352_r1.jpg  \n",
            " extracting: DeepDRiD/val/352/352_r2.jpg  \n",
            "   creating: DeepDRiD/val/355/\n",
            " extracting: DeepDRiD/val/355/355_l1.jpg  \n",
            " extracting: DeepDRiD/val/355/355_l2.jpg  \n",
            " extracting: DeepDRiD/val/355/355_r1.jpg  \n",
            " extracting: DeepDRiD/val/355/355_r2.jpg  \n",
            "   creating: DeepDRiD/val/356/\n",
            " extracting: DeepDRiD/val/356/356_l1.jpg  \n",
            " extracting: DeepDRiD/val/356/356_l2.jpg  \n",
            " extracting: DeepDRiD/val/356/356_r1.jpg  \n",
            " extracting: DeepDRiD/val/356/356_r2.jpg  \n",
            "   creating: DeepDRiD/val/357/\n",
            " extracting: DeepDRiD/val/357/357_l1.jpg  \n",
            " extracting: DeepDRiD/val/357/357_l2.jpg  \n",
            " extracting: DeepDRiD/val/357/357_r1.jpg  \n",
            " extracting: DeepDRiD/val/357/357_r2.jpg  \n",
            "   creating: DeepDRiD/val/358/\n",
            " extracting: DeepDRiD/val/358/358_l1.jpg  \n",
            " extracting: DeepDRiD/val/358/358_l2.jpg  \n",
            " extracting: DeepDRiD/val/358/358_r1.jpg  \n",
            " extracting: DeepDRiD/val/358/358_r2.jpg  \n",
            "   creating: DeepDRiD/val/359/\n",
            " extracting: DeepDRiD/val/359/359_l1.jpg  \n",
            " extracting: DeepDRiD/val/359/359_l2.jpg  \n",
            " extracting: DeepDRiD/val/359/359_r1.jpg  \n",
            " extracting: DeepDRiD/val/359/359_r2.jpg  \n",
            "   creating: DeepDRiD/val/360/\n",
            " extracting: DeepDRiD/val/360/360_l1.jpg  \n",
            " extracting: DeepDRiD/val/360/360_l2.jpg  \n",
            " extracting: DeepDRiD/val/360/360_r1.jpg  \n",
            " extracting: DeepDRiD/val/360/360_r2.jpg  \n",
            "   creating: DeepDRiD/val/361/\n",
            " extracting: DeepDRiD/val/361/361_l1.jpg  \n",
            " extracting: DeepDRiD/val/361/361_l2.jpg  \n",
            " extracting: DeepDRiD/val/361/361_r1.jpg  \n",
            " extracting: DeepDRiD/val/361/361_r2.jpg  \n",
            "   creating: DeepDRiD/val/362/\n",
            " extracting: DeepDRiD/val/362/362_l1.jpg  \n",
            " extracting: DeepDRiD/val/362/362_l2.jpg  \n",
            " extracting: DeepDRiD/val/362/362_r1.jpg  \n",
            " extracting: DeepDRiD/val/362/362_r2.jpg  \n",
            "   creating: DeepDRiD/val/363/\n",
            " extracting: DeepDRiD/val/363/363_l1.jpg  \n",
            " extracting: DeepDRiD/val/363/363_l2.jpg  \n",
            " extracting: DeepDRiD/val/363/363_r1.jpg  \n",
            " extracting: DeepDRiD/val/363/363_r2.jpg  \n",
            "   creating: DeepDRiD/val/364/\n",
            " extracting: DeepDRiD/val/364/364_l1.jpg  \n",
            " extracting: DeepDRiD/val/364/364_l2.jpg  \n",
            " extracting: DeepDRiD/val/364/364_r1.jpg  \n",
            " extracting: DeepDRiD/val/364/364_r2.jpg  \n",
            "   creating: DeepDRiD/val/365/\n",
            " extracting: DeepDRiD/val/365/365_l1.jpg  \n",
            " extracting: DeepDRiD/val/365/365_l2.jpg  \n",
            " extracting: DeepDRiD/val/365/365_r1.jpg  \n",
            " extracting: DeepDRiD/val/365/365_r2.jpg  \n",
            "   creating: DeepDRiD/val/367/\n",
            " extracting: DeepDRiD/val/367/367_l1.jpg  \n",
            " extracting: DeepDRiD/val/367/367_l2.jpg  \n",
            " extracting: DeepDRiD/val/367/367_r1.jpg  \n",
            " extracting: DeepDRiD/val/367/367_r2.jpg  \n",
            "   creating: DeepDRiD/val/369/\n",
            " extracting: DeepDRiD/val/369/369_l1.jpg  \n",
            " extracting: DeepDRiD/val/369/369_l2.jpg  \n",
            " extracting: DeepDRiD/val/369/369_r1.jpg  \n",
            " extracting: DeepDRiD/val/369/369_r2.jpg  \n",
            "   creating: DeepDRiD/val/370/\n",
            " extracting: DeepDRiD/val/370/370_l1.jpg  \n",
            " extracting: DeepDRiD/val/370/370_l2.jpg  \n",
            " extracting: DeepDRiD/val/370/370_r1.jpg  \n",
            " extracting: DeepDRiD/val/370/370_r2.jpg  \n",
            "   creating: DeepDRiD/val/372/\n",
            " extracting: DeepDRiD/val/372/372_l1.jpg  \n",
            " extracting: DeepDRiD/val/372/372_l2.jpg  \n",
            " extracting: DeepDRiD/val/372/372_r1.jpg  \n",
            " extracting: DeepDRiD/val/372/372_r2.jpg  \n",
            "   creating: DeepDRiD/val/373/\n",
            " extracting: DeepDRiD/val/373/373_l1.jpg  \n",
            " extracting: DeepDRiD/val/373/373_l2.jpg  \n",
            " extracting: DeepDRiD/val/373/373_r1.jpg  \n",
            " extracting: DeepDRiD/val/373/373_r2.jpg  \n",
            "   creating: DeepDRiD/val/374/\n",
            " extracting: DeepDRiD/val/374/374_l1.jpg  \n",
            " extracting: DeepDRiD/val/374/374_l2.jpg  \n",
            " extracting: DeepDRiD/val/374/374_r1.jpg  \n",
            " extracting: DeepDRiD/val/374/374_r2.jpg  \n",
            "   creating: DeepDRiD/val/375/\n",
            " extracting: DeepDRiD/val/375/375_l1.jpg  \n",
            " extracting: DeepDRiD/val/375/375_l2.jpg  \n",
            " extracting: DeepDRiD/val/375/375_r1.jpg  \n",
            " extracting: DeepDRiD/val/375/375_r2.jpg  \n",
            "   creating: DeepDRiD/val/376/\n",
            " extracting: DeepDRiD/val/376/376_l1.jpg  \n",
            " extracting: DeepDRiD/val/376/376_l2.jpg  \n",
            " extracting: DeepDRiD/val/376/376_r1.jpg  \n",
            " extracting: DeepDRiD/val/376/376_r2.jpg  \n",
            "   creating: DeepDRiD/val/378/\n",
            " extracting: DeepDRiD/val/378/378_l1.jpg  \n",
            " extracting: DeepDRiD/val/378/378_l2.jpg  \n",
            " extracting: DeepDRiD/val/378/378_r1.jpg  \n",
            " extracting: DeepDRiD/val/378/378_r2.jpg  \n",
            "   creating: DeepDRiD/val/379/\n",
            " extracting: DeepDRiD/val/379/379_l1.jpg  \n",
            " extracting: DeepDRiD/val/379/379_l2.jpg  \n",
            " extracting: DeepDRiD/val/379/379_r1.jpg  \n",
            " extracting: DeepDRiD/val/379/379_r2.jpg  \n",
            "   creating: DeepDRiD/val/380/\n",
            " extracting: DeepDRiD/val/380/380_l1.jpg  \n",
            " extracting: DeepDRiD/val/380/380_l2.jpg  \n",
            " extracting: DeepDRiD/val/380/380_r1.jpg  \n",
            " extracting: DeepDRiD/val/380/380_r2.jpg  \n",
            "   creating: DeepDRiD/val/381/\n",
            " extracting: DeepDRiD/val/381/381_l1.jpg  \n",
            " extracting: DeepDRiD/val/381/381_l2.jpg  \n",
            " extracting: DeepDRiD/val/381/381_r1.jpg  \n",
            " extracting: DeepDRiD/val/381/381_r2.jpg  \n",
            "   creating: DeepDRiD/val/382/\n",
            " extracting: DeepDRiD/val/382/382_l1.jpg  \n",
            " extracting: DeepDRiD/val/382/382_l2.jpg  \n",
            " extracting: DeepDRiD/val/382/382_r1.jpg  \n",
            " extracting: DeepDRiD/val/382/382_r2.jpg  \n",
            "   creating: DeepDRiD/val/385/\n",
            " extracting: DeepDRiD/val/385/385_l1.jpg  \n",
            " extracting: DeepDRiD/val/385/385_l2.jpg  \n",
            " extracting: DeepDRiD/val/385/385_r1.jpg  \n",
            " extracting: DeepDRiD/val/385/385_r2.jpg  \n",
            "   creating: DeepDRiD/val/388/\n",
            " extracting: DeepDRiD/val/388/388_l1.jpg  \n",
            " extracting: DeepDRiD/val/388/388_l2.jpg  \n",
            " extracting: DeepDRiD/val/388/388_r1.jpg  \n",
            " extracting: DeepDRiD/val/388/388_r2.jpg  \n",
            "   creating: DeepDRiD/val/390/\n",
            " extracting: DeepDRiD/val/390/390_l1.jpg  \n",
            " extracting: DeepDRiD/val/390/390_l2.jpg  \n",
            " extracting: DeepDRiD/val/390/390_r1.jpg  \n",
            " extracting: DeepDRiD/val/390/390_r2.jpg  \n",
            "   creating: DeepDRiD/val/392/\n",
            " extracting: DeepDRiD/val/392/392_l1.jpg  \n",
            " extracting: DeepDRiD/val/392/392_l2.jpg  \n",
            " extracting: DeepDRiD/val/392/392_r1.jpg  \n",
            " extracting: DeepDRiD/val/392/392_r2.jpg  \n",
            "   creating: DeepDRiD/val/393/\n",
            " extracting: DeepDRiD/val/393/393_l1.jpg  \n",
            " extracting: DeepDRiD/val/393/393_l2.jpg  \n",
            " extracting: DeepDRiD/val/393/393_r1.jpg  \n",
            " extracting: DeepDRiD/val/393/393_r2.jpg  \n",
            "   creating: DeepDRiD/val/394/\n",
            " extracting: DeepDRiD/val/394/394_l1.jpg  \n",
            " extracting: DeepDRiD/val/394/394_l2.jpg  \n",
            " extracting: DeepDRiD/val/394/394_r1.jpg  \n",
            " extracting: DeepDRiD/val/394/394_r2.jpg  \n",
            "   creating: DeepDRiD/val/395/\n",
            " extracting: DeepDRiD/val/395/395_l1.jpg  \n",
            " extracting: DeepDRiD/val/395/395_l2.jpg  \n",
            " extracting: DeepDRiD/val/395/395_r1.jpg  \n",
            " extracting: DeepDRiD/val/395/395_r2.jpg  \n",
            "   creating: DeepDRiD/val/397/\n",
            " extracting: DeepDRiD/val/397/397_l1.jpg  \n",
            " extracting: DeepDRiD/val/397/397_l2.jpg  \n",
            " extracting: DeepDRiD/val/397/397_r1.jpg  \n",
            " extracting: DeepDRiD/val/397/397_r2.jpg  \n",
            "   creating: DeepDRiD/val/399/\n",
            " extracting: DeepDRiD/val/399/399_l1.jpg  \n",
            " extracting: DeepDRiD/val/399/399_l2.jpg  \n",
            " extracting: DeepDRiD/val/399/399_r1.jpg  \n",
            " extracting: DeepDRiD/val/399/399_r2.jpg  \n",
            "   creating: DeepDRiD/val/400/\n",
            " extracting: DeepDRiD/val/400/400_l1.jpg  \n",
            " extracting: DeepDRiD/val/400/400_l2.jpg  \n",
            " extracting: DeepDRiD/val/400/400_r1.jpg  \n",
            " extracting: DeepDRiD/val/400/400_r2.jpg  \n",
            "   creating: DeepDRiD/val/401/\n",
            " extracting: DeepDRiD/val/401/401_l1.jpg  \n",
            " extracting: DeepDRiD/val/401/401_l2.jpg  \n",
            " extracting: DeepDRiD/val/401/401_r1.jpg  \n",
            " extracting: DeepDRiD/val/401/401_r2.jpg  \n",
            "   creating: DeepDRiD/val/402/\n",
            " extracting: DeepDRiD/val/402/402_l1.jpg  \n",
            " extracting: DeepDRiD/val/402/402_l2.jpg  \n",
            " extracting: DeepDRiD/val/402/402_r1.jpg  \n",
            " extracting: DeepDRiD/val/402/402_r2.jpg  \n",
            "   creating: DeepDRiD/val/404/\n",
            " extracting: DeepDRiD/val/404/404_l1.jpg  \n",
            " extracting: DeepDRiD/val/404/404_l2.jpg  \n",
            " extracting: DeepDRiD/val/404/404_r1.jpg  \n",
            " extracting: DeepDRiD/val/404/404_r2.jpg  \n",
            "   creating: DeepDRiD/val/405/\n",
            " extracting: DeepDRiD/val/405/405_l1.jpg  \n",
            " extracting: DeepDRiD/val/405/405_l2.jpg  \n",
            " extracting: DeepDRiD/val/405/405_r1.jpg  \n",
            " extracting: DeepDRiD/val/405/405_r2.jpg  \n",
            "   creating: DeepDRiD/val/406/\n",
            " extracting: DeepDRiD/val/406/406_l1.jpg  \n",
            " extracting: DeepDRiD/val/406/406_l2.jpg  \n",
            " extracting: DeepDRiD/val/406/406_r1.jpg  \n",
            " extracting: DeepDRiD/val/406/406_r2.jpg  \n",
            "   creating: DeepDRiD/val/407/\n",
            " extracting: DeepDRiD/val/407/407_l1.jpg  \n",
            " extracting: DeepDRiD/val/407/407_l2.jpg  \n",
            " extracting: DeepDRiD/val/407/407_r1.jpg  \n",
            " extracting: DeepDRiD/val/407/407_r2.jpg  \n",
            "   creating: DeepDRiD/val/410/\n",
            " extracting: DeepDRiD/val/410/410_l1.jpg  \n",
            " extracting: DeepDRiD/val/410/410_l2.jpg  \n",
            " extracting: DeepDRiD/val/410/410_r1.jpg  \n",
            " extracting: DeepDRiD/val/410/410_r2.jpg  \n",
            "   creating: DeepDRiD/val/413/\n",
            " extracting: DeepDRiD/val/413/413_l1.jpg  \n",
            " extracting: DeepDRiD/val/413/413_l2.jpg  \n",
            " extracting: DeepDRiD/val/413/413_r1.jpg  \n",
            " extracting: DeepDRiD/val/413/413_r2.jpg  \n",
            "   creating: DeepDRiD/val/414/\n",
            " extracting: DeepDRiD/val/414/414_l1.jpg  \n",
            " extracting: DeepDRiD/val/414/414_l2.jpg  \n",
            " extracting: DeepDRiD/val/414/414_r1.jpg  \n",
            " extracting: DeepDRiD/val/414/414_r2.jpg  \n",
            "   creating: DeepDRiD/val/415/\n",
            " extracting: DeepDRiD/val/415/415_l1.jpg  \n",
            " extracting: DeepDRiD/val/415/415_l2.jpg  \n",
            " extracting: DeepDRiD/val/415/415_r1.jpg  \n",
            " extracting: DeepDRiD/val/415/415_r2.jpg  \n",
            "   creating: DeepDRiD/val/416/\n",
            " extracting: DeepDRiD/val/416/416_l1.jpg  \n",
            " extracting: DeepDRiD/val/416/416_l2.jpg  \n",
            " extracting: DeepDRiD/val/416/416_r1.jpg  \n",
            " extracting: DeepDRiD/val/416/416_r2.jpg  \n",
            "   creating: DeepDRiD/val/422/\n",
            " extracting: DeepDRiD/val/422/422_l1.jpg  \n",
            " extracting: DeepDRiD/val/422/422_l2.jpg  \n",
            " extracting: DeepDRiD/val/422/422_r1.jpg  \n",
            " extracting: DeepDRiD/val/422/422_r2.jpg  \n",
            "   creating: DeepDRiD/val/430/\n",
            " extracting: DeepDRiD/val/430/430_l1.jpg  \n",
            " extracting: DeepDRiD/val/430/430_l2.jpg  \n",
            " extracting: DeepDRiD/val/430/430_r1.jpg  \n",
            " extracting: DeepDRiD/val/430/430_r2.jpg  \n",
            "   creating: DeepDRiD/val/431/\n",
            " extracting: DeepDRiD/val/431/431_l1.jpg  \n",
            " extracting: DeepDRiD/val/431/431_l2.jpg  \n",
            " extracting: DeepDRiD/val/431/431_r1.jpg  \n",
            " extracting: DeepDRiD/val/431/431_r2.jpg  \n",
            "   creating: DeepDRiD/val/433/\n",
            " extracting: DeepDRiD/val/433/433_l1.jpg  \n",
            " extracting: DeepDRiD/val/433/433_l2.jpg  \n",
            " extracting: DeepDRiD/val/433/433_r1.jpg  \n",
            " extracting: DeepDRiD/val/433/433_r2.jpg  \n",
            "   creating: pretrained_DR_resize/\n",
            " extracting: pretrained_DR_resize/how_to_use.py  \n",
            "   creating: pretrained_DR_resize/pretrained/\n",
            " extracting: pretrained_DR_resize/pretrained/densenet121.pth  \n",
            " extracting: pretrained_DR_resize/pretrained/efficientnet_b0.pth  \n",
            " extracting: pretrained_DR_resize/pretrained/resnet18.pth  \n",
            " extracting: pretrained_DR_resize/pretrained/resnet34.pth  \n",
            " extracting: pretrained_DR_resize/pretrained/vgg16.pth  \n",
            " extracting: template_code.py        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from sklearn.metrics import cohen_kappa_score, precision_score, recall_score, accuracy_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Hyper Parameters\n",
        "batch_size = 24\n",
        "num_classes = 5  # 5 DR levels\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "V-awh3Z_4hxy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RetinopathyDataset(Dataset):\n",
        "    def __init__(self, ann_file, image_dir, transform=None, mode='single', test=False):\n",
        "        self.ann_file = ann_file\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.test = test\n",
        "        self.mode = mode\n",
        "\n",
        "        if self.mode == 'single':\n",
        "            self.data = self.load_data()\n",
        "        else:\n",
        "            self.data = self.load_data_dual()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.mode == 'single':\n",
        "            return self.get_item(index)\n",
        "        else:\n",
        "            return self.get_item_dual(index)\n",
        "\n",
        "    # 1. single image\n",
        "    def load_data(self):\n",
        "        df = pd.read_csv(self.ann_file)\n",
        "\n",
        "        data = []\n",
        "        for _, row in df.iterrows():\n",
        "            file_info = dict()\n",
        "            file_info['img_path'] = os.path.join(self.image_dir, row['img_path'])\n",
        "            if not self.test:\n",
        "                file_info['dr_level'] = int(row['patient_DR_Level'])\n",
        "            data.append(file_info)\n",
        "        return data\n",
        "\n",
        "    def get_item(self, index):\n",
        "        data = self.data[index]\n",
        "        img = Image.open(data['img_path']).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if not self.test:\n",
        "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
        "            return img, label\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "    # 2. dual image\n",
        "    def load_data_dual(self):\n",
        "        df = pd.read_csv(self.ann_file)\n",
        "\n",
        "        df['prefix'] = df['image_id'].str.split('_').str[0]  # The patient id of each image\n",
        "        df['suffix'] = df['image_id'].str.split('_').str[1].str[0]  # The left or right eye\n",
        "        grouped = df.groupby(['prefix', 'suffix'])\n",
        "\n",
        "        data = []\n",
        "        for (prefix, suffix), group in grouped:\n",
        "            file_info = dict()\n",
        "            file_info['img_path1'] = os.path.join(self.image_dir, group.iloc[0]['img_path'])\n",
        "            file_info['img_path2'] = os.path.join(self.image_dir, group.iloc[1]['img_path'])\n",
        "            if not self.test:\n",
        "                file_info['dr_level'] = int(group.iloc[0]['patient_DR_Level'])\n",
        "            data.append(file_info)\n",
        "        return data\n",
        "\n",
        "    def get_item_dual(self, index):\n",
        "        data = self.data[index]\n",
        "        img1 = Image.open(data['img_path1']).convert('RGB')\n",
        "        img2 = Image.open(data['img_path2']).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "\n",
        "        if not self.test:\n",
        "            label = torch.tensor(data['dr_level'], dtype=torch.int64)\n",
        "            return [img1, img2], label\n",
        "        else:\n",
        "            return [img1, img2]"
      ],
      "metadata": {
        "id": "uoovQrv_4nG8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CutOut(object):\n",
        "    def __init__(self, mask_size, p=0.5):\n",
        "        self.mask_size = mask_size\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if np.random.rand() > self.p:\n",
        "            return img\n",
        "\n",
        "        # Ensure the image is a tensor\n",
        "        if not isinstance(img, torch.Tensor):\n",
        "            raise TypeError('Input image must be a torch.Tensor')\n",
        "\n",
        "        # Get height and width of the image\n",
        "        h, w = img.shape[1], img.shape[2]\n",
        "        mask_size_half = self.mask_size // 2\n",
        "        offset = 1 if self.mask_size % 2 == 0 else 0\n",
        "\n",
        "        cx = np.random.randint(mask_size_half, w + offset - mask_size_half)\n",
        "        cy = np.random.randint(mask_size_half, h + offset - mask_size_half)\n",
        "\n",
        "        xmin, xmax = cx - mask_size_half, cx + mask_size_half + offset\n",
        "        ymin, ymax = cy - mask_size_half, cy + mask_size_half + offset\n",
        "        xmin, xmax = max(0, xmin), min(w, xmax)\n",
        "        ymin, ymax = max(0, ymin), min(h, ymax)\n",
        "\n",
        "        img[:, ymin:ymax, xmin:xmax] = 0\n",
        "        return img\n"
      ],
      "metadata": {
        "id": "H2C8Xc9T4qn6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SLORandomPad:\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "\n",
        "    def __call__(self, img):\n",
        "        pad_width = max(0, self.size[0] - img.width)\n",
        "        pad_height = max(0, self.size[1] - img.height)\n",
        "        pad_left = random.randint(0, pad_width)\n",
        "        pad_top = random.randint(0, pad_height)\n",
        "        pad_right = pad_width - pad_left\n",
        "        pad_bottom = pad_height - pad_top\n",
        "        return transforms.functional.pad(img, (pad_left, pad_top, pad_right, pad_bottom))"
      ],
      "metadata": {
        "id": "MJ5YNxPp4s_b"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FundRandomRotate:\n",
        "    def __init__(self, prob, degree):\n",
        "        self.prob = prob\n",
        "        self.degree = degree\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if random.random() < self.prob:\n",
        "            angle = random.uniform(-self.degree, self.degree)\n",
        "            return transforms.functional.rotate(img, angle)\n",
        "        return img"
      ],
      "metadata": {
        "id": "kKjseHOz4uSz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop((210, 210)),\n",
        "    SLORandomPad((224, 224)),\n",
        "    FundRandomRotate(prob=0.5, degree=30),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "OCu-ybAj4wr7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs,\n",
        "                checkpoint_path='/content/drive/MyDrive/models/model1.pth'):\n",
        "    best_model = model.state_dict()\n",
        "    best_epoch = None\n",
        "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
        "        running_loss = []\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
        "            for images, labels in train_loader:\n",
        "                if not isinstance(images, list):\n",
        "                    images = images.to(device)  # single image case\n",
        "                else:\n",
        "                    images = [x.to(device) for x in images]  # dual images case\n",
        "\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels.long())\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                preds = torch.argmax(outputs, 1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                running_loss.append(loss.item())\n",
        "\n",
        "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
        "                pbar.update(1)\n",
        "\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        epoch_loss = sum(running_loss) / len(running_loss)\n",
        "\n",
        "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n",
        "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
        "\n",
        "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
        "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
        "\n",
        "        if len(train_metrics) > 4:\n",
        "            precision_per_class, recall_per_class = train_metrics[4:]\n",
        "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
        "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
        "\n",
        "        # Evaluation on the validation set at the end of each epoch\n",
        "        val_metrics = evaluate_model(model, val_loader, device)\n",
        "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
        "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
        "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
        "\n",
        "        if val_kappa > best_val_kappa:\n",
        "            best_val_kappa = val_kappa\n",
        "            best_epoch = epoch\n",
        "            best_model = model.state_dict()\n",
        "            torch.save(best_model, checkpoint_path)\n",
        "\n",
        "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "dhAtXdG843lr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, device, test_only=False, prediction_path='/content/drive/MyDrive/Predictions/test_predictions1.csv'):\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_image_ids = []\n",
        "\n",
        "    with tqdm(total=len(test_loader), desc=f'Evaluating', unit=' batch', file=sys.stdout) as pbar:\n",
        "        for i, data in enumerate(test_loader):\n",
        "\n",
        "            if test_only:\n",
        "                images = data\n",
        "            else:\n",
        "                images, labels = data\n",
        "\n",
        "            if not isinstance(images, list):\n",
        "                images = images.to(device)  # single image case\n",
        "            else:\n",
        "                images = [x.to(device) for x in images]  # dual images case\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(images)\n",
        "                preds = torch.argmax(outputs, 1)\n",
        "\n",
        "            if not isinstance(images, list):\n",
        "                # single image case\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                image_ids = [\n",
        "                    os.path.basename(test_loader.dataset.data[idx]['img_path']) for idx in\n",
        "                    range(i * test_loader.batch_size, i * test_loader.batch_size + len(images))\n",
        "                ]\n",
        "                all_image_ids.extend(image_ids)\n",
        "                if not test_only:\n",
        "                    all_labels.extend(labels.numpy())\n",
        "            else:\n",
        "                # dual images case\n",
        "                for k in range(2):\n",
        "                    all_preds.extend(preds.cpu().numpy())\n",
        "                    image_ids = [\n",
        "                        os.path.basename(test_loader.dataset.data[idx][f'img_path{k + 1}']) for idx in\n",
        "                        range(i * test_loader.batch_size, i * test_loader.batch_size + len(images[k]))\n",
        "                    ]\n",
        "                    all_image_ids.extend(image_ids)\n",
        "                    if not test_only:\n",
        "                        all_labels.extend(labels.numpy())\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "    # Save predictions to csv file for Kaggle online evaluation\n",
        "    if test_only:\n",
        "        df = pd.DataFrame({\n",
        "            'ID': all_image_ids,\n",
        "            'TARGET': all_preds\n",
        "        })\n",
        "        df.to_csv(prediction_path, index=False)\n",
        "        print(f'[Test] Save predictions to {os.path.abspath(prediction_path)}')\n",
        "    else:\n",
        "        metrics = compute_metrics(all_preds, all_labels)\n",
        "        return metrics\n"
      ],
      "metadata": {
        "id": "IIiyT07W46zD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(preds, labels, per_class=False):\n",
        "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
        "\n",
        "    # Calculate and print precision and recall for each class\n",
        "    if per_class:\n",
        "        precision_per_class = precision_score(labels, preds, average=None, zero_division=0)\n",
        "        recall_per_class = recall_score(labels, preds, average=None, zero_division=0)\n",
        "        return kappa, accuracy, precision, recall, precision_per_class, recall_per_class\n",
        "\n",
        "    return kappa, accuracy, precision, recall"
      ],
      "metadata": {
        "id": "Q2CwZht148Sq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):\n",
        "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = models.resnet18(pretrained=True)\n",
        "\n",
        "        # self.backbone = models.resnet34(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained/resnet34.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.vgg16(pretrained=True)\n",
        "        # self.backbone.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # state_dict = torch.load('pretrained/vgg16.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.efficientnet_b0(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained/efficientnet_b0.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.densenet121(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained/densenet121.pth', map_location='cpu')\n",
        "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "bX0hxd6g4-7q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Choose between 'single image' and 'dual images' pipeline\n",
        "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
        "\n",
        "    mode = 'single'  # forward single image to the model each time\n",
        "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
        "\n",
        "    assert mode in ('single', 'dual')\n",
        "\n",
        "    # Define the model\n",
        "    if mode == 'single':\n",
        "        model = MyModel()\n",
        "    else:\n",
        "        model = MyDualModel()\n",
        "\n",
        "    print(model, '\\n')\n",
        "    print('Pipeline Mode:', mode)\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = RetinopathyDataset('/content/DeepDRiD/train.csv', '/content/DeepDRiD/train', transform_train, mode)\n",
        "    val_dataset = RetinopathyDataset('/content/DeepDRiD/val.csv', '/content/DeepDRiD/val/', transform_test, mode)\n",
        "    test_dataset = RetinopathyDataset('/content/DeepDRiD/test.csv', '/content/DeepDRiD/test', transform_test, mode, test=True)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Define the weighted CrossEntropyLoss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Use GPU device is possible\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print('Device:', device)\n",
        "\n",
        "    # Move class weights to the device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Optimizer and Learning rate scheduler\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "    # Train and evaluate the model with the training and validation set\n",
        "    model = train_model(\n",
        "        model, train_loader, val_loader, device, criterion, optimizer,\n",
        "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
        "        checkpoint_path='/content/drive/MyDrive/models/model1.pth'\n",
        "    )\n",
        "\n",
        "    # Load the pretrained checkpoint\n",
        "    state_dict = torch.load('/content/drive/MyDrive/models/model1.pth', map_location='cpu')\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Make predictions on testing set and save the prediction results\n",
        "    evaluate_model(model, test_loader, device, test_only=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMiuw2-D5LAD",
        "outputId": "4b541354-5a84-4b15-dd96-efcadc9fa3dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyModel(\n",
            "  (backbone): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
            "  )\n",
            ") \n",
            "\n",
            "Pipeline Mode: single\n",
            "Device: cuda\n",
            "\n",
            "Epoch 1/10\n",
            "Training: 100%|| 50/50 [00:12<00:00,  4.05 batch/s, lr=1.0e-04, Loss=1.2992]\n",
            "[Train] Kappa: 0.3703 Accuracy: 0.3525 Precision: 0.3543 Recall: 0.3525 Loss: 1.4684\n",
            "[Train] Class 0: Precision: 0.6580, Recall: 0.6306\n",
            "[Train] Class 1: Precision: 0.2800, Recall: 0.1458\n",
            "[Train] Class 2: Precision: 0.2197, Recall: 0.1208\n",
            "[Train] Class 3: Precision: 0.2432, Recall: 0.5208\n",
            "[Train] Class 4: Precision: 0.0833, Recall: 0.0583\n",
            "Evaluating: 100%|| 17/17 [00:02<00:00,  7.04 batch/s]\n",
            "[Val] Kappa: 0.6441 Accuracy: 0.5700 Precision: 0.5023 Recall: 0.5700\n",
            "\n",
            "Epoch 2/10\n",
            "Training: 100%|| 50/50 [00:12<00:00,  4.02 batch/s, lr=1.0e-04, Loss=1.1926]\n",
            "[Train] Kappa: 0.6276 Accuracy: 0.5083 Precision: 0.4515 Recall: 0.5083 Loss: 1.2280\n",
            "[Train] Class 0: Precision: 0.7206, Recall: 0.9528\n",
            "[Train] Class 1: Precision: 0.3830, Recall: 0.3750\n",
            "[Train] Class 2: Precision: 0.3166, Recall: 0.2625\n",
            "[Train] Class 3: Precision: 0.4058, Recall: 0.4667\n",
            "[Train] Class 4: Precision: 0.1429, Recall: 0.0167\n",
            "Evaluating: 100%|| 17/17 [00:02<00:00,  7.17 batch/s]\n",
            "[Val] Kappa: 0.7350 Accuracy: 0.6200 Precision: 0.5708 Recall: 0.6200\n",
            "\n",
            "Epoch 3/10\n",
            "Training: 100%|| 50/50 [00:12<00:00,  4.06 batch/s, lr=1.0e-04, Loss=1.0932]\n",
            "[Train] Kappa: 0.7373 Accuracy: 0.5733 Precision: 0.5339 Recall: 0.5733 Loss: 1.0782\n",
            "[Train] Class 0: Precision: 0.8090, Recall: 0.9528\n",
            "[Train] Class 1: Precision: 0.5042, Recall: 0.4958\n",
            "[Train] Class 2: Precision: 0.4022, Recall: 0.3000\n",
            "[Train] Class 3: Precision: 0.4408, Recall: 0.6208\n",
            "[Train] Class 4: Precision: 0.2174, Recall: 0.0417\n",
            "Evaluating: 100%|| 17/17 [00:02<00:00,  7.18 batch/s]\n",
            "[Val] Kappa: 0.7396 Accuracy: 0.6275 Precision: 0.5535 Recall: 0.6275\n",
            "\n",
            "Epoch 4/10\n",
            "Training: 100%|| 50/50 [00:12<00:00,  4.05 batch/s, lr=1.0e-04, Loss=0.9721]\n",
            "[Train] Kappa: 0.7501 Accuracy: 0.5883 Precision: 0.5551 Recall: 0.5883 Loss: 1.0052\n",
            "[Train] Class 0: Precision: 0.8091, Recall: 0.9417\n",
            "[Train] Class 1: Precision: 0.5494, Recall: 0.5333\n",
            "[Train] Class 2: Precision: 0.4070, Recall: 0.3375\n",
            "[Train] Class 3: Precision: 0.4730, Recall: 0.6208\n",
            "[Train] Class 4: Precision: 0.2647, Recall: 0.0750\n",
            "Evaluating: 100%|| 17/17 [00:02<00:00,  7.14 batch/s]\n",
            "[Val] Kappa: 0.7722 Accuracy: 0.6250 Precision: 0.5563 Recall: 0.6250\n",
            "\n",
            "Epoch 5/10\n",
            "Training: 100%|| 50/50 [00:12<00:00,  4.05 batch/s, lr=1.0e-04, Loss=1.4016]\n",
            "[Train] Kappa: 0.7818 Accuracy: 0.6292 Precision: 0.6092 Recall: 0.6292 Loss: 0.9441\n",
            "[Train] Class 0: Precision: 0.8477, Recall: 0.9583\n",
            "[Train] Class 1: Precision: 0.5736, Recall: 0.6167\n",
            "[Train] Class 2: Precision: 0.4773, Recall: 0.3500\n",
            "[Train] Class 3: Precision: 0.5015, Recall: 0.6750\n",
            "[Train] Class 4: Precision: 0.4444, Recall: 0.1333\n",
            "Evaluating: 100%|| 17/17 [00:02<00:00,  7.18 batch/s]\n",
            "[Val] Kappa: 0.7408 Accuracy: 0.6000 Precision: 0.5217 Recall: 0.6000\n",
            "\n",
            "Epoch 6/10\n",
            "Training: 100%|| 50/50 [00:12<00:00,  4.11 batch/s, lr=1.0e-04, Loss=0.9523]\n",
            "[Train] Kappa: 0.7837 Accuracy: 0.6492 Precision: 0.6346 Recall: 0.6492 Loss: 0.9252\n",
            "[Train] Class 0: Precision: 0.8524, Recall: 0.9306\n",
            "[Train] Class 1: Precision: 0.6129, Recall: 0.6333\n",
            "[Train] Class 2: Precision: 0.5053, Recall: 0.3958\n",
            "[Train] Class 3: Precision: 0.5380, Recall: 0.7375\n",
            "[Train] Class 4: Precision: 0.4762, Recall: 0.1667\n",
            "Evaluating: 100%|| 17/17 [00:02<00:00,  7.12 batch/s]\n",
            "[Val] Kappa: 0.7732 Accuracy: 0.6275 Precision: 0.5916 Recall: 0.6275\n",
            "\n",
            "Epoch 7/10\n",
            "Training: 100%|| 50/50 [00:12<00:00,  4.06 batch/s, lr=1.0e-04, Loss=0.7351]\n",
            "[Train] Kappa: 0.8072 Accuracy: 0.6450 Precision: 0.6334 Recall: 0.6450 Loss: 0.8732\n",
            "[Train] Class 0: Precision: 0.8520, Recall: 0.9278\n",
            "[Train] Class 1: Precision: 0.5760, Recall: 0.6000\n",
            "[Train] Class 2: Precision: 0.5000, Recall: 0.4417\n",
            "[Train] Class 3: Precision: 0.5591, Recall: 0.6500\n",
            "[Train] Class 4: Precision: 0.5075, Recall: 0.2833\n",
            "Evaluating: 100%|| 17/17 [00:02<00:00,  5.94 batch/s]\n",
            "[Val] Kappa: 0.7013 Accuracy: 0.6050 Precision: 0.5971 Recall: 0.6050\n",
            "\n",
            "Epoch 8/10\n",
            "Training: 100%|| 50/50 [00:11<00:00,  4.21 batch/s, lr=1.0e-04, Loss=0.6204]\n",
            "[Train] Kappa: 0.8140 Accuracy: 0.6883 Precision: 0.6758 Recall: 0.6883 Loss: 0.8232\n",
            "[Train] Class 0: Precision: 0.8526, Recall: 0.9639\n",
            "[Train] Class 1: Precision: 0.6667, Recall: 0.6500\n",
            "[Train] Class 2: Precision: 0.5388, Recall: 0.4625\n",
            "[Train] Class 3: Precision: 0.6079, Recall: 0.7042\n",
            "[Train] Class 4: Precision: 0.5733, Recall: 0.3583\n",
            "Evaluating: 100%|| 17/17 [00:03<00:00,  5.40 batch/s]\n",
            "[Val] Kappa: 0.7583 Accuracy: 0.6200 Precision: 0.6013 Recall: 0.6200\n",
            "\n",
            "Epoch 9/10\n",
            "Training: 100%|| 50/50 [00:11<00:00,  4.30 batch/s, lr=1.0e-04, Loss=0.7656]\n",
            "[Train] Kappa: 0.8325 Accuracy: 0.7017 Precision: 0.6928 Recall: 0.7017 Loss: 0.8024\n",
            "[Train] Class 0: Precision: 0.8561, Recall: 0.9583\n",
            "[Train] Class 1: Precision: 0.7240, Recall: 0.6667\n",
            "[Train] Class 2: Precision: 0.5764, Recall: 0.4875\n",
            "[Train] Class 3: Precision: 0.6000, Recall: 0.7000\n",
            "[Train] Class 4: Precision: 0.5591, Recall: 0.4333\n",
            "Evaluating: 100%|| 17/17 [00:03<00:00,  5.01 batch/s]\n",
            "[Val] Kappa: 0.7589 Accuracy: 0.6325 Precision: 0.6101 Recall: 0.6325\n",
            "\n",
            "Epoch 10/10\n",
            "Training: 100%|| 50/50 [00:11<00:00,  4.31 batch/s, lr=1.0e-04, Loss=0.6963]\n",
            "[Train] Kappa: 0.8599 Accuracy: 0.7417 Precision: 0.7360 Recall: 0.7417 Loss: 0.6951\n",
            "[Train] Class 0: Precision: 0.8903, Recall: 0.9472\n",
            "[Train] Class 1: Precision: 0.7231, Recall: 0.7292\n",
            "[Train] Class 2: Precision: 0.6398, Recall: 0.5625\n",
            "[Train] Class 3: Precision: 0.6679, Recall: 0.7292\n",
            "[Train] Class 4: Precision: 0.6275, Recall: 0.5333\n",
            "Evaluating: 100%|| 17/17 [00:03<00:00,  5.22 batch/s]\n",
            "[Val] Kappa: 0.7554 Accuracy: 0.6250 Precision: 0.5982 Recall: 0.6250\n",
            "[Val] Best kappa: 0.7732, Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-3579f0252b28>:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('/content/drive/MyDrive/models/model1.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating: 100%|| 17/17 [00:02<00:00,  6.92 batch/s]\n",
            "[Test] Save predictions to /content/drive/MyDrive/Predictions/test_predictions1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Choose between 'single image' and 'dual images' pipeline\n",
        "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
        "\n",
        "    mode = 'single'  # forward single image to the model each time\n",
        "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
        "\n",
        "    assert mode in ('single', 'dual')\n",
        "\n",
        "    # Define the model\n",
        "    if mode == 'single':\n",
        "        model = MyModel()\n",
        "    else:\n",
        "        model = MyDualModel()\n",
        "\n",
        "    print(model, '\\n')\n",
        "    print('Pipeline Mode:', mode)\n",
        "\n",
        "    # tuned Hyper Parameters\n",
        "    batch_size = 16\n",
        "    num_classes = 5  # 5 DR levels\n",
        "    learning_rate = 0.0001\n",
        "    num_epochs = 15\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = RetinopathyDataset('/content/DeepDRiD/train.csv', '/content/DeepDRiD/train', transform_train, mode)\n",
        "    val_dataset = RetinopathyDataset('/content/DeepDRiD/val.csv', '/content/DeepDRiD/val/', transform_test, mode)\n",
        "    test_dataset = RetinopathyDataset('/content/DeepDRiD/test.csv', '/content/DeepDRiD/test', transform_test, mode, test=True)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Define the weighted CrossEntropyLoss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Use GPU device is possible\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print('Device:', device)\n",
        "\n",
        "    # Move class weights to the device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Optimizer and Learning rate scheduler\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "    # Train and evaluate the model with the training and validation set\n",
        "    model = train_model(\n",
        "        model, train_loader, val_loader, device, criterion, optimizer,\n",
        "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
        "        checkpoint_path='/content/drive/MyDrive/models/model2.pth'\n",
        "    )\n",
        "\n",
        "    # Load the pretrained checkpoint\n",
        "    state_dict = torch.load('/content/drive/MyDrive/models/model2.pth', map_location='cpu')\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Make predictions on testing set and save the prediction results\n",
        "    evaluate_model(model, test_loader, device, test_only=True, prediction_path='/content/drive/MyDrive/Predictions/test_predictions2.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-gZzeTRDK6_",
        "outputId": "7b926240-083b-4a13-f41a-e1e2eb78aba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyModel(\n",
            "  (backbone): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
            "  )\n",
            ") \n",
            "\n",
            "Pipeline Mode: single\n",
            "Device: cuda\n",
            "\n",
            "Epoch 1/15\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.10 batch/s, lr=1.0e-04, Loss=1.3668]\n",
            "[Train] Kappa: 0.3841 Accuracy: 0.4158 Precision: 0.3695 Recall: 0.4158 Loss: 1.4115\n",
            "[Train] Class 0: Precision: 0.5772, Recall: 0.8306\n",
            "[Train] Class 1: Precision: 0.2936, Recall: 0.2875\n",
            "[Train] Class 2: Precision: 0.2635, Recall: 0.1833\n",
            "[Train] Class 3: Precision: 0.3559, Recall: 0.3292\n",
            "[Train] Class 4: Precision: 0.1379, Recall: 0.0667\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.94 batch/s]\n",
            "[Val] Kappa: 0.6468 Accuracy: 0.5725 Precision: 0.4926 Recall: 0.5725\n",
            "\n",
            "Epoch 2/15\n",
            "Training: 100%|| 75/75 [00:11<00:00,  6.28 batch/s, lr=1.0e-04, Loss=1.0394]\n",
            "[Train] Kappa: 0.6423 Accuracy: 0.5042 Precision: 0.4624 Recall: 0.5042 Loss: 1.1921\n",
            "[Train] Class 0: Precision: 0.7620, Recall: 0.9250\n",
            "[Train] Class 1: Precision: 0.3734, Recall: 0.3625\n",
            "[Train] Class 2: Precision: 0.3105, Recall: 0.2833\n",
            "[Train] Class 3: Precision: 0.3897, Recall: 0.4708\n",
            "[Train] Class 4: Precision: 0.1905, Recall: 0.0333\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  8.07 batch/s]\n",
            "[Val] Kappa: 0.6643 Accuracy: 0.5900 Precision: 0.5069 Recall: 0.5900\n",
            "\n",
            "Epoch 3/15\n",
            "Training: 100%|| 75/75 [00:11<00:00,  6.44 batch/s, lr=1.0e-04, Loss=1.2372]\n",
            "[Train] Kappa: 0.7198 Accuracy: 0.5658 Precision: 0.5407 Recall: 0.5658 Loss: 1.0875\n",
            "[Train] Class 0: Precision: 0.8029, Recall: 0.9389\n",
            "[Train] Class 1: Precision: 0.4622, Recall: 0.4833\n",
            "[Train] Class 2: Precision: 0.3295, Recall: 0.2417\n",
            "[Train] Class 3: Precision: 0.4753, Recall: 0.6417\n",
            "[Train] Class 4: Precision: 0.4643, Recall: 0.1083\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.59 batch/s]\n",
            "[Val] Kappa: 0.7309 Accuracy: 0.6100 Precision: 0.5258 Recall: 0.6100\n",
            "\n",
            "Epoch 4/15\n",
            "Training: 100%|| 75/75 [00:11<00:00,  6.50 batch/s, lr=1.0e-04, Loss=0.9740]\n",
            "[Train] Kappa: 0.7277 Accuracy: 0.5950 Precision: 0.5616 Recall: 0.5950 Loss: 1.0274\n",
            "[Train] Class 0: Precision: 0.8094, Recall: 0.9556\n",
            "[Train] Class 1: Precision: 0.5441, Recall: 0.5917\n",
            "[Train] Class 2: Precision: 0.4069, Recall: 0.2458\n",
            "[Train] Class 3: Precision: 0.4795, Recall: 0.6333\n",
            "[Train] Class 4: Precision: 0.3269, Recall: 0.1417\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  8.00 batch/s]\n",
            "[Val] Kappa: 0.7734 Accuracy: 0.6075 Precision: 0.6100 Recall: 0.6075\n",
            "\n",
            "Epoch 5/15\n",
            "Training: 100%|| 75/75 [00:11<00:00,  6.31 batch/s, lr=1.0e-04, Loss=1.1075]\n",
            "[Train] Kappa: 0.7794 Accuracy: 0.6158 Precision: 0.5928 Recall: 0.6158 Loss: 0.9580\n",
            "[Train] Class 0: Precision: 0.8329, Recall: 0.9556\n",
            "[Train] Class 1: Precision: 0.5344, Recall: 0.5500\n",
            "[Train] Class 2: Precision: 0.4337, Recall: 0.3000\n",
            "[Train] Class 3: Precision: 0.5202, Recall: 0.6958\n",
            "[Train] Class 4: Precision: 0.4528, Recall: 0.2000\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.78 batch/s]\n",
            "[Val] Kappa: 0.7717 Accuracy: 0.6075 Precision: 0.5437 Recall: 0.6075\n",
            "\n",
            "Epoch 6/15\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.22 batch/s, lr=1.0e-04, Loss=1.1456]\n",
            "[Train] Kappa: 0.8009 Accuracy: 0.6233 Precision: 0.6080 Recall: 0.6233 Loss: 0.9392\n",
            "[Train] Class 0: Precision: 0.8390, Recall: 0.9556\n",
            "[Train] Class 1: Precision: 0.5714, Recall: 0.5500\n",
            "[Train] Class 2: Precision: 0.4317, Recall: 0.3292\n",
            "[Train] Class 3: Precision: 0.5093, Recall: 0.6875\n",
            "[Train] Class 4: Precision: 0.5385, Recall: 0.2333\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.21 batch/s]\n",
            "[Val] Kappa: 0.7900 Accuracy: 0.6375 Precision: 0.6333 Recall: 0.6375\n",
            "\n",
            "Epoch 7/15\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.05 batch/s, lr=1.0e-04, Loss=0.7864]\n",
            "[Train] Kappa: 0.7754 Accuracy: 0.6375 Precision: 0.6215 Recall: 0.6375 Loss: 0.9121\n",
            "[Train] Class 0: Precision: 0.8383, Recall: 0.9361\n",
            "[Train] Class 1: Precision: 0.6025, Recall: 0.6000\n",
            "[Train] Class 2: Precision: 0.5000, Recall: 0.3792\n",
            "[Train] Class 3: Precision: 0.5314, Recall: 0.6708\n",
            "[Train] Class 4: Precision: 0.4324, Recall: 0.2667\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.52 batch/s]\n",
            "[Val] Kappa: 0.8009 Accuracy: 0.6250 Precision: 0.5954 Recall: 0.6250\n",
            "\n",
            "Epoch 8/15\n",
            "Training: 100%|| 75/75 [00:12<00:00,  5.96 batch/s, lr=1.0e-04, Loss=1.0861]\n",
            "[Train] Kappa: 0.8254 Accuracy: 0.6750 Precision: 0.6608 Recall: 0.6750 Loss: 0.8322\n",
            "[Train] Class 0: Precision: 0.8543, Recall: 0.9611\n",
            "[Train] Class 1: Precision: 0.6303, Recall: 0.6250\n",
            "[Train] Class 2: Precision: 0.5436, Recall: 0.4417\n",
            "[Train] Class 3: Precision: 0.5922, Recall: 0.6958\n",
            "[Train] Class 4: Precision: 0.5125, Recall: 0.3417\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.94 batch/s]\n",
            "[Val] Kappa: 0.7947 Accuracy: 0.6250 Precision: 0.5871 Recall: 0.6250\n",
            "\n",
            "Epoch 9/15\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.10 batch/s, lr=1.0e-04, Loss=1.4873]\n",
            "[Train] Kappa: 0.8354 Accuracy: 0.6808 Precision: 0.6668 Recall: 0.6808 Loss: 0.7938\n",
            "[Train] Class 0: Precision: 0.8665, Recall: 0.9556\n",
            "[Train] Class 1: Precision: 0.6680, Recall: 0.6875\n",
            "[Train] Class 2: Precision: 0.5198, Recall: 0.3833\n",
            "[Train] Class 3: Precision: 0.5854, Recall: 0.7000\n",
            "[Train] Class 4: Precision: 0.5217, Recall: 0.4000\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.84 batch/s]\n",
            "[Val] Kappa: 0.7474 Accuracy: 0.5975 Precision: 0.6241 Recall: 0.5975\n",
            "\n",
            "Epoch 10/15\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.04 batch/s, lr=1.0e-04, Loss=0.4824]\n",
            "[Train] Kappa: 0.8226 Accuracy: 0.6975 Precision: 0.6873 Recall: 0.6975 Loss: 0.7978\n",
            "[Train] Class 0: Precision: 0.8687, Recall: 0.9556\n",
            "[Train] Class 1: Precision: 0.6695, Recall: 0.6667\n",
            "[Train] Class 2: Precision: 0.5258, Recall: 0.4667\n",
            "[Train] Class 3: Precision: 0.6371, Recall: 0.6875\n",
            "[Train] Class 4: Precision: 0.6022, Recall: 0.4667\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.78 batch/s]\n",
            "[Val] Kappa: 0.7997 Accuracy: 0.6350 Precision: 0.6267 Recall: 0.6350\n",
            "\n",
            "Epoch 11/15\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.13 batch/s, lr=1.0e-05, Loss=0.7776]\n",
            "[Train] Kappa: 0.8383 Accuracy: 0.7208 Precision: 0.7139 Recall: 0.7208 Loss: 0.7459\n",
            "[Train] Class 0: Precision: 0.8837, Recall: 0.9500\n",
            "[Train] Class 1: Precision: 0.7345, Recall: 0.6917\n",
            "[Train] Class 2: Precision: 0.5664, Recall: 0.5333\n",
            "[Train] Class 3: Precision: 0.6444, Recall: 0.7625\n",
            "[Train] Class 4: Precision: 0.5974, Recall: 0.3833\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.76 batch/s]\n",
            "[Val] Kappa: 0.8022 Accuracy: 0.6425 Precision: 0.6209 Recall: 0.6425\n",
            "\n",
            "Epoch 12/15\n",
            "Training: 100%|| 75/75 [00:12<00:00,  5.90 batch/s, lr=1.0e-05, Loss=0.8053]\n",
            "[Train] Kappa: 0.8608 Accuracy: 0.7342 Precision: 0.7280 Recall: 0.7342 Loss: 0.6988\n",
            "[Train] Class 0: Precision: 0.8830, Recall: 0.9639\n",
            "[Train] Class 1: Precision: 0.7409, Recall: 0.6792\n",
            "[Train] Class 2: Precision: 0.6099, Recall: 0.5667\n",
            "[Train] Class 3: Precision: 0.6511, Recall: 0.7542\n",
            "[Train] Class 4: Precision: 0.6279, Recall: 0.4500\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 11.12 batch/s]\n",
            "[Val] Kappa: 0.7989 Accuracy: 0.6625 Precision: 0.6364 Recall: 0.6625\n",
            "\n",
            "Epoch 13/15\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.03 batch/s, lr=1.0e-05, Loss=0.6787]\n",
            "[Train] Kappa: 0.8566 Accuracy: 0.7467 Precision: 0.7388 Recall: 0.7467 Loss: 0.6733\n",
            "[Train] Class 0: Precision: 0.8841, Recall: 0.9750\n",
            "[Train] Class 1: Precision: 0.7197, Recall: 0.7167\n",
            "[Train] Class 2: Precision: 0.6268, Recall: 0.5458\n",
            "[Train] Class 3: Precision: 0.6840, Recall: 0.7667\n",
            "[Train] Class 4: Precision: 0.6744, Recall: 0.4833\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 11.18 batch/s]\n",
            "[Val] Kappa: 0.7841 Accuracy: 0.6375 Precision: 0.6118 Recall: 0.6375\n",
            "\n",
            "Epoch 14/15\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.06 batch/s, lr=1.0e-05, Loss=0.6047]\n",
            "[Train] Kappa: 0.8824 Accuracy: 0.7817 Precision: 0.7756 Recall: 0.7817 Loss: 0.6356\n",
            "[Train] Class 0: Precision: 0.9051, Recall: 0.9806\n",
            "[Train] Class 1: Precision: 0.7860, Recall: 0.7958\n",
            "[Train] Class 2: Precision: 0.6759, Recall: 0.6083\n",
            "[Train] Class 3: Precision: 0.7109, Recall: 0.7583\n",
            "[Train] Class 4: Precision: 0.6947, Recall: 0.5500\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 11.05 batch/s]\n",
            "[Val] Kappa: 0.7861 Accuracy: 0.6325 Precision: 0.6138 Recall: 0.6325\n",
            "\n",
            "Epoch 15/15\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.08 batch/s, lr=1.0e-05, Loss=0.5055]\n",
            "[Train] Kappa: 0.8825 Accuracy: 0.7658 Precision: 0.7593 Recall: 0.7658 Loss: 0.6356\n",
            "[Train] Class 0: Precision: 0.8931, Recall: 0.9750\n",
            "[Train] Class 1: Precision: 0.7564, Recall: 0.7375\n",
            "[Train] Class 2: Precision: 0.6473, Recall: 0.5583\n",
            "[Train] Class 3: Precision: 0.7029, Recall: 0.8083\n",
            "[Train] Class 4: Precision: 0.7000, Recall: 0.5250\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 11.00 batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-3afbd131cb23>:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('/content/drive/MyDrive/models/model2.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Kappa: 0.7839 Accuracy: 0.6375 Precision: 0.6119 Recall: 0.6375\n",
            "[Val] Best kappa: 0.8022, Epoch 11\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.50 batch/s]\n",
            "[Test] Save predictions to /content/drive/MyDrive/Predictions/test_predictions2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel_resnet18(nn.Module):\n",
        "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = models.resnet18(pretrained=True)\n",
        "        state_dict = torch.load('pretrained_DR_resize/pretrained/resnet18.pth', map_location='cpu')\n",
        "        info = self.backbone.load_state_dict(state_dict, strict=False)\n",
        "        print('missing keys:', info[0])  # The missing fc or classifier layer is normal here\n",
        "        print('unexpected keys:', info[1])\n",
        "\n",
        "        # self.backbone = models.resnet34(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained/resnet34.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.vgg16(pretrained=True)\n",
        "        # self.backbone.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # state_dict = torch.load('pretrained/vgg16.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.efficientnet_b0(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained/efficientnet_b0.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.densenet121(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained/densenet121.pth', map_location='cpu')\n",
        "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "iuRllCFmIcaO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Choose between 'single image' and 'dual images' pipeline\n",
        "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
        "\n",
        "    mode = 'single'  # forward single image to the model each time\n",
        "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
        "\n",
        "    assert mode in ('single', 'dual')\n",
        "\n",
        "    # Define the model\n",
        "    if mode == 'single':\n",
        "        model = MyModel()\n",
        "    else:\n",
        "        model = MyDualModel()\n",
        "\n",
        "    print(model, '\\n')\n",
        "    print('Pipeline Mode:', mode)\n",
        "\n",
        "    # tuned Hyper Parameters\n",
        "    batch_size = 16\n",
        "    num_classes = 5  # 5 DR levels\n",
        "    learning_rate = 0.0001\n",
        "    num_epochs = 20\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = RetinopathyDataset('/content/DeepDRiD/train.csv', '/content/DeepDRiD/train', transform_train, mode)\n",
        "    val_dataset = RetinopathyDataset('/content/DeepDRiD/val.csv', '/content/DeepDRiD/val/', transform_test, mode)\n",
        "    test_dataset = RetinopathyDataset('/content/DeepDRiD/test.csv', '/content/DeepDRiD/test', transform_test, mode, test=True)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop((224, 224)),\n",
        "    SLORandomPad((224, 224)),\n",
        "    FundRandomRotate(prob=0.5, degree=30),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Define the weighted CrossEntropyLoss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Use GPU device is possible\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print('Device:', device)\n",
        "\n",
        "    # Move class weights to the device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Optimizer and Learning rate scheduler\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "     # Train and evaluate the model with the training and validation set\n",
        "    model = train_model(\n",
        "        model, train_loader, val_loader, device, criterion, optimizer,\n",
        "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
        "        checkpoint_path='/content/drive/MyDrive/models/model3.pth'\n",
        "    )\n",
        "\n",
        "    # Load the pretrained checkpoint\n",
        "    state_dict = torch.load('/content/drive/MyDrive/models/model3.pth', map_location='cpu')\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Make predictions on testing set and save the prediction results\n",
        "    evaluate_model(model, test_loader, device, test_only=True, prediction_path='/content/drive/MyDrive/Predictions/test_predictions3.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQODD8agJCcf",
        "outputId": "e8eb9861-606e-4a11-e485-49e88199f746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-22-2dee11ae0e4e>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('pretrained_DR_resize/pretrained/resnet18.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing keys: ['fc.weight', 'fc.bias']\n",
            "unexpected keys: []\n",
            "MyModel(\n",
            "  (backbone): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
            "  )\n",
            ") \n",
            "\n",
            "Pipeline Mode: single\n",
            "Device: cuda\n",
            "\n",
            "Epoch 1/20\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.04 batch/s, lr=1.0e-04, Loss=1.1349]\n",
            "[Train] Kappa: 0.3173 Accuracy: 0.3875 Precision: 0.3297 Recall: 0.3875 Loss: 1.3805\n",
            "[Train] Class 0: Precision: 0.3742, Recall: 0.8556\n",
            "[Train] Class 1: Precision: 0.2661, Recall: 0.1208\n",
            "[Train] Class 2: Precision: 0.2653, Recall: 0.0542\n",
            "[Train] Class 3: Precision: 0.5556, Recall: 0.4792\n",
            "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 11.13 batch/s]\n",
            "[Val] Kappa: 0.7338 Accuracy: 0.5550 Precision: 0.5537 Recall: 0.5550\n",
            "\n",
            "Epoch 2/20\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.11 batch/s, lr=1.0e-04, Loss=1.0137]\n",
            "[Train] Kappa: 0.7475 Accuracy: 0.5608 Precision: 0.4901 Recall: 0.5608 Loss: 1.1163\n",
            "[Train] Class 0: Precision: 0.7095, Recall: 0.8750\n",
            "[Train] Class 1: Precision: 0.4847, Recall: 0.4625\n",
            "[Train] Class 2: Precision: 0.4056, Recall: 0.2417\n",
            "[Train] Class 3: Precision: 0.4961, Recall: 0.7875\n",
            "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 11.01 batch/s]\n",
            "[Val] Kappa: 0.8240 Accuracy: 0.6575 Precision: 0.5835 Recall: 0.6575\n",
            "\n",
            "Epoch 3/20\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.18 batch/s, lr=1.0e-04, Loss=1.0455]\n",
            "[Train] Kappa: 0.7849 Accuracy: 0.6142 Precision: 0.5971 Recall: 0.6142 Loss: 0.9832\n",
            "[Train] Class 0: Precision: 0.8116, Recall: 0.9333\n",
            "[Train] Class 1: Precision: 0.5727, Recall: 0.5417\n",
            "[Train] Class 2: Precision: 0.4330, Recall: 0.3500\n",
            "[Train] Class 3: Precision: 0.5125, Recall: 0.7667\n",
            "[Train] Class 4: Precision: 0.5000, Recall: 0.0250\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 11.32 batch/s]\n",
            "[Val] Kappa: 0.8438 Accuracy: 0.6775 Precision: 0.6032 Recall: 0.6775\n",
            "\n",
            "Epoch 4/20\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.12 batch/s, lr=1.0e-04, Loss=0.8036]\n",
            "[Train] Kappa: 0.8252 Accuracy: 0.6508 Precision: 0.6118 Recall: 0.6508 Loss: 0.8935\n",
            "[Train] Class 0: Precision: 0.8407, Recall: 0.9528\n",
            "[Train] Class 1: Precision: 0.6607, Recall: 0.6167\n",
            "[Train] Class 2: Precision: 0.5047, Recall: 0.4458\n",
            "[Train] Class 3: Precision: 0.5327, Recall: 0.7458\n",
            "[Train] Class 4: Precision: 0.2000, Recall: 0.0333\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 11.13 batch/s]\n",
            "[Val] Kappa: 0.8339 Accuracy: 0.6725 Precision: 0.5985 Recall: 0.6725\n",
            "\n",
            "Epoch 5/20\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.14 batch/s, lr=1.0e-04, Loss=0.9569]\n",
            "[Train] Kappa: 0.8020 Accuracy: 0.6433 Precision: 0.6209 Recall: 0.6433 Loss: 0.8980\n",
            "[Train] Class 0: Precision: 0.8442, Recall: 0.9028\n",
            "[Train] Class 1: Precision: 0.6057, Recall: 0.6208\n",
            "[Train] Class 2: Precision: 0.4936, Recall: 0.4792\n",
            "[Train] Class 3: Precision: 0.5573, Recall: 0.7292\n",
            "[Train] Class 4: Precision: 0.3636, Recall: 0.0667\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.81 batch/s]\n",
            "[Val] Kappa: 0.8443 Accuracy: 0.6875 Precision: 0.6154 Recall: 0.6875\n",
            "\n",
            "Epoch 6/20\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.12 batch/s, lr=1.0e-04, Loss=0.9071]\n",
            "[Train] Kappa: 0.8184 Accuracy: 0.6633 Precision: 0.6473 Recall: 0.6633 Loss: 0.8943\n",
            "[Train] Class 0: Precision: 0.8345, Recall: 0.9528\n",
            "[Train] Class 1: Precision: 0.6710, Recall: 0.6458\n",
            "[Train] Class 2: Precision: 0.5111, Recall: 0.4792\n",
            "[Train] Class 3: Precision: 0.5527, Recall: 0.7208\n",
            "[Train] Class 4: Precision: 0.5000, Recall: 0.0833\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.57 batch/s]\n",
            "[Val] Kappa: 0.8211 Accuracy: 0.6825 Precision: 0.6068 Recall: 0.6825\n",
            "\n",
            "Epoch 7/20\n",
            "Training: 100%|| 75/75 [00:11<00:00,  6.44 batch/s, lr=1.0e-04, Loss=0.8677]\n",
            "[Train] Kappa: 0.7971 Accuracy: 0.6500 Precision: 0.6280 Recall: 0.6500 Loss: 0.8759\n",
            "[Train] Class 0: Precision: 0.8523, Recall: 0.9139\n",
            "[Train] Class 1: Precision: 0.6486, Recall: 0.7000\n",
            "[Train] Class 2: Precision: 0.4920, Recall: 0.3833\n",
            "[Train] Class 3: Precision: 0.5310, Recall: 0.7500\n",
            "[Train] Class 4: Precision: 0.3793, Recall: 0.0917\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.39 batch/s]\n",
            "[Val] Kappa: 0.8499 Accuracy: 0.6725 Precision: 0.5979 Recall: 0.6725\n",
            "\n",
            "Epoch 8/20\n",
            "Training: 100%|| 75/75 [00:11<00:00,  6.44 batch/s, lr=1.0e-04, Loss=0.3428]\n",
            "[Train] Kappa: 0.8206 Accuracy: 0.6900 Precision: 0.6743 Recall: 0.6900 Loss: 0.8034\n",
            "[Train] Class 0: Precision: 0.8557, Recall: 0.9389\n",
            "[Train] Class 1: Precision: 0.7285, Recall: 0.6708\n",
            "[Train] Class 2: Precision: 0.5570, Recall: 0.5500\n",
            "[Train] Class 3: Precision: 0.5844, Recall: 0.7500\n",
            "[Train] Class 4: Precision: 0.4359, Recall: 0.1417\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.43 batch/s]\n",
            "[Val] Kappa: 0.8366 Accuracy: 0.6850 Precision: 0.6114 Recall: 0.6850\n",
            "\n",
            "Epoch 9/20\n",
            "Training: 100%|| 75/75 [00:11<00:00,  6.57 batch/s, lr=1.0e-04, Loss=0.7789]\n",
            "[Train] Kappa: 0.8190 Accuracy: 0.6708 Precision: 0.6495 Recall: 0.6708 Loss: 0.8242\n",
            "[Train] Class 0: Precision: 0.8629, Recall: 0.9444\n",
            "[Train] Class 1: Precision: 0.6802, Recall: 0.7000\n",
            "[Train] Class 2: Precision: 0.5116, Recall: 0.4583\n",
            "[Train] Class 3: Precision: 0.5531, Recall: 0.7375\n",
            "[Train] Class 4: Precision: 0.4167, Recall: 0.0833\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.80 batch/s]\n",
            "[Val] Kappa: 0.8466 Accuracy: 0.6725 Precision: 0.6320 Recall: 0.6725\n",
            "\n",
            "Epoch 10/20\n",
            "Training: 100%|| 75/75 [00:11<00:00,  6.50 batch/s, lr=1.0e-04, Loss=0.7698]\n",
            "[Train] Kappa: 0.8255 Accuracy: 0.6800 Precision: 0.6623 Recall: 0.6800 Loss: 0.8018\n",
            "[Train] Class 0: Precision: 0.8480, Recall: 0.9611\n",
            "[Train] Class 1: Precision: 0.6842, Recall: 0.6500\n",
            "[Train] Class 2: Precision: 0.5333, Recall: 0.5333\n",
            "[Train] Class 3: Precision: 0.5935, Recall: 0.6875\n",
            "[Train] Class 4: Precision: 0.4565, Recall: 0.1750\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.34 batch/s]\n",
            "[Val] Kappa: 0.8126 Accuracy: 0.6825 Precision: 0.7121 Recall: 0.6825\n",
            "\n",
            "Epoch 11/20\n",
            "Training: 100%|| 75/75 [00:11<00:00,  6.39 batch/s, lr=1.0e-05, Loss=0.8807]\n",
            "[Train] Kappa: 0.8407 Accuracy: 0.6833 Precision: 0.6675 Recall: 0.6833 Loss: 0.7964\n",
            "[Train] Class 0: Precision: 0.8782, Recall: 0.9417\n",
            "[Train] Class 1: Precision: 0.6789, Recall: 0.6958\n",
            "[Train] Class 2: Precision: 0.5498, Recall: 0.4833\n",
            "[Train] Class 3: Precision: 0.5728, Recall: 0.7375\n",
            "[Train] Class 4: Precision: 0.4375, Recall: 0.1750\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.07 batch/s]\n",
            "[Val] Kappa: 0.8339 Accuracy: 0.6825 Precision: 0.7115 Recall: 0.6825\n",
            "\n",
            "Epoch 12/20\n",
            "Training: 100%|| 75/75 [00:11<00:00,  6.31 batch/s, lr=1.0e-05, Loss=1.5194]\n",
            "[Train] Kappa: 0.8238 Accuracy: 0.6983 Precision: 0.6842 Recall: 0.6983 Loss: 0.7832\n",
            "[Train] Class 0: Precision: 0.8546, Recall: 0.9472\n",
            "[Train] Class 1: Precision: 0.7083, Recall: 0.7083\n",
            "[Train] Class 2: Precision: 0.5819, Recall: 0.5625\n",
            "[Train] Class 3: Precision: 0.5918, Recall: 0.7250\n",
            "[Train] Class 4: Precision: 0.5143, Recall: 0.1500\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.06 batch/s]\n",
            "[Val] Kappa: 0.8242 Accuracy: 0.6825 Precision: 0.7072 Recall: 0.6825\n",
            "\n",
            "Epoch 13/20\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.21 batch/s, lr=1.0e-05, Loss=0.6415]\n",
            "[Train] Kappa: 0.8407 Accuracy: 0.6900 Precision: 0.6727 Recall: 0.6900 Loss: 0.7808\n",
            "[Train] Class 0: Precision: 0.8603, Recall: 0.9583\n",
            "[Train] Class 1: Precision: 0.7212, Recall: 0.6792\n",
            "[Train] Class 2: Precision: 0.5590, Recall: 0.5333\n",
            "[Train] Class 3: Precision: 0.5767, Recall: 0.7208\n",
            "[Train] Class 4: Precision: 0.4318, Recall: 0.1583\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.79 batch/s]\n",
            "[Val] Kappa: 0.8512 Accuracy: 0.6875 Precision: 0.7192 Recall: 0.6875\n",
            "\n",
            "Epoch 14/20\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.07 batch/s, lr=1.0e-05, Loss=0.9354]\n",
            "[Train] Kappa: 0.8215 Accuracy: 0.6725 Precision: 0.6517 Recall: 0.6725 Loss: 0.8033\n",
            "[Train] Class 0: Precision: 0.8522, Recall: 0.9611\n",
            "[Train] Class 1: Precision: 0.7034, Recall: 0.6917\n",
            "[Train] Class 2: Precision: 0.5273, Recall: 0.4833\n",
            "[Train] Class 3: Precision: 0.5517, Recall: 0.6667\n",
            "[Train] Class 4: Precision: 0.3958, Recall: 0.1583\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.95 batch/s]\n",
            "[Val] Kappa: 0.8563 Accuracy: 0.6900 Precision: 0.7218 Recall: 0.6900\n",
            "\n",
            "Epoch 15/20\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.06 batch/s, lr=1.0e-05, Loss=0.7959]\n",
            "[Train] Kappa: 0.8418 Accuracy: 0.6958 Precision: 0.6774 Recall: 0.6958 Loss: 0.7764\n",
            "[Train] Class 0: Precision: 0.8741, Recall: 0.9639\n",
            "[Train] Class 1: Precision: 0.7253, Recall: 0.7042\n",
            "[Train] Class 2: Precision: 0.5561, Recall: 0.5167\n",
            "[Train] Class 3: Precision: 0.5803, Recall: 0.7375\n",
            "[Train] Class 4: Precision: 0.4286, Recall: 0.1500\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.95 batch/s]\n",
            "[Val] Kappa: 0.8180 Accuracy: 0.6925 Precision: 0.7183 Recall: 0.6925\n",
            "\n",
            "Epoch 16/20\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.05 batch/s, lr=1.0e-05, Loss=0.8179]\n",
            "[Train] Kappa: 0.8402 Accuracy: 0.6783 Precision: 0.6594 Recall: 0.6783 Loss: 0.7683\n",
            "[Train] Class 0: Precision: 0.8718, Recall: 0.9444\n",
            "[Train] Class 1: Precision: 0.7025, Recall: 0.7083\n",
            "[Train] Class 2: Precision: 0.5357, Recall: 0.5000\n",
            "[Train] Class 3: Precision: 0.5612, Recall: 0.6875\n",
            "[Train] Class 4: Precision: 0.3800, Recall: 0.1583\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.74 batch/s]\n",
            "[Val] Kappa: 0.8211 Accuracy: 0.6700 Precision: 0.6983 Recall: 0.6700\n",
            "\n",
            "Epoch 17/20\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.13 batch/s, lr=1.0e-05, Loss=0.4698]\n",
            "[Train] Kappa: 0.8255 Accuracy: 0.6908 Precision: 0.6646 Recall: 0.6908 Loss: 0.7658\n",
            "[Train] Class 0: Precision: 0.8713, Recall: 0.9778\n",
            "[Train] Class 1: Precision: 0.7253, Recall: 0.7042\n",
            "[Train] Class 2: Precision: 0.5247, Recall: 0.4875\n",
            "[Train] Class 3: Precision: 0.5855, Recall: 0.7417\n",
            "[Train] Class 4: Precision: 0.3611, Recall: 0.1083\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.95 batch/s]\n",
            "[Val] Kappa: 0.8308 Accuracy: 0.6850 Precision: 0.7144 Recall: 0.6850\n",
            "\n",
            "Epoch 18/20\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.07 batch/s, lr=1.0e-05, Loss=0.6154]\n",
            "[Train] Kappa: 0.8352 Accuracy: 0.6958 Precision: 0.6746 Recall: 0.6958 Loss: 0.7649\n",
            "[Train] Class 0: Precision: 0.8680, Recall: 0.9500\n",
            "[Train] Class 1: Precision: 0.7143, Recall: 0.7083\n",
            "[Train] Class 2: Precision: 0.5701, Recall: 0.5250\n",
            "[Train] Class 3: Precision: 0.5915, Recall: 0.7542\n",
            "[Train] Class 4: Precision: 0.3902, Recall: 0.1333\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.90 batch/s]\n",
            "[Val] Kappa: 0.8385 Accuracy: 0.6875 Precision: 0.7191 Recall: 0.6875\n",
            "\n",
            "Epoch 19/20\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.04 batch/s, lr=1.0e-05, Loss=0.8132]\n",
            "[Train] Kappa: 0.8391 Accuracy: 0.7100 Precision: 0.6918 Recall: 0.7100 Loss: 0.7233\n",
            "[Train] Class 0: Precision: 0.8728, Recall: 0.9722\n",
            "[Train] Class 1: Precision: 0.7404, Recall: 0.7250\n",
            "[Train] Class 2: Precision: 0.5890, Recall: 0.5375\n",
            "[Train] Class 3: Precision: 0.5941, Recall: 0.7500\n",
            "[Train] Class 4: Precision: 0.4524, Recall: 0.1583\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.86 batch/s]\n",
            "[Val] Kappa: 0.8260 Accuracy: 0.6800 Precision: 0.7087 Recall: 0.6800\n",
            "\n",
            "Epoch 20/20\n",
            "Training: 100%|| 75/75 [00:12<00:00,  6.10 batch/s, lr=1.0e-05, Loss=0.8326]\n",
            "[Train] Kappa: 0.8479 Accuracy: 0.6808 Precision: 0.6675 Recall: 0.6808 Loss: 0.7783\n",
            "[Train] Class 0: Precision: 0.8759, Recall: 0.9611\n",
            "[Train] Class 1: Precision: 0.7284, Recall: 0.7042\n",
            "[Train] Class 2: Precision: 0.5231, Recall: 0.4708\n",
            "[Train] Class 3: Precision: 0.5385, Recall: 0.7000\n",
            "[Train] Class 4: Precision: 0.4667, Recall: 0.1750\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.92 batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-8a16ceb53830>:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('/content/drive/MyDrive/models/model3.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Kappa: 0.8274 Accuracy: 0.6800 Precision: 0.6598 Recall: 0.6800\n",
            "[Val] Best kappa: 0.8563, Epoch 14\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.28 batch/s]\n",
            "[Test] Save predictions to /content/drive/MyDrive/Predictions/test_predictions3.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel_resnet34(nn.Module):\n",
        "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        # self.backbone = models.resnet18(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained_DR_resize/pretrained/resnet18.pth', map_location='cpu')\n",
        "\n",
        "\n",
        "        self.backbone = models.resnet34(pretrained=True)\n",
        "        state_dict = torch.load('pretrained_DR_resize/pretrained/resnet34.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.vgg16(pretrained=True)\n",
        "        # self.backbone.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # state_dict = torch.load('pretrained/vgg16.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.efficientnet_b0(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained/efficientnet_b0.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.densenet121(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained/densenet121.pth', map_location='cpu')\n",
        "\n",
        "        info = self.backbone.load_state_dict(state_dict, strict=False)\n",
        "        print('missing keys:', info[0])  # The missing fc or classifier layer is normal here\n",
        "        print('unexpected keys:', info[1])\n",
        "\n",
        "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "pztMKrRQLRym"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Choose between 'single image' and 'dual images' pipeline\n",
        "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
        "\n",
        "    mode = 'single'  # forward single image to the model each time\n",
        "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
        "\n",
        "    assert mode in ('single', 'dual')\n",
        "\n",
        "    # Define the model\n",
        "    if mode == 'single':\n",
        "        model = MyModel()\n",
        "    else:\n",
        "        model = MyDualModel()\n",
        "\n",
        "    print(model, '\\n')\n",
        "    print('Pipeline Mode:', mode)\n",
        "\n",
        "    # tuned Hyper Parameters\n",
        "    batch_size = 16\n",
        "    num_classes = 5  # 5 DR levels\n",
        "    learning_rate = 0.0001\n",
        "    num_epochs = 20\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = RetinopathyDataset('/content/DeepDRiD/train.csv', '/content/DeepDRiD/train', transform_train, mode)\n",
        "    val_dataset = RetinopathyDataset('/content/DeepDRiD/val.csv', '/content/DeepDRiD/val/', transform_test, mode)\n",
        "    test_dataset = RetinopathyDataset('/content/DeepDRiD/test.csv', '/content/DeepDRiD/test', transform_test, mode, test=True)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop((224, 224)),\n",
        "    SLORandomPad((224, 224)),\n",
        "    FundRandomRotate(prob=0.5, degree=30),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Define the weighted CrossEntropyLoss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Use GPU device is possible\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print('Device:', device)\n",
        "\n",
        "    # Move class weights to the device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Optimizer and Learning rate scheduler\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "     # Train and evaluate the model with the training and validation set\n",
        "    model = train_model(\n",
        "        model, train_loader, val_loader, device, criterion, optimizer,\n",
        "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
        "        checkpoint_path='/content/drive/MyDrive/models/model4.pth'\n",
        "    )\n",
        "\n",
        "    # Load the pretrained checkpoint\n",
        "    state_dict = torch.load('/content/drive/MyDrive/models/model4.pth', map_location='cpu')\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Make predictions on testing set and save the prediction results\n",
        "    evaluate_model(model, test_loader, device, test_only=True, prediction_path='/content/drive/MyDrive/Predictions/test_predictions4.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zWaBp1MLTiu",
        "outputId": "481c5075-e94f-41b6-9201-c6f169e2e59f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|| 83.3M/83.3M [00:00<00:00, 113MB/s]\n",
            "<ipython-input-24-b6c7b0790233>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('pretrained_DR_resize/pretrained/resnet34.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing keys: ['fc.weight', 'fc.bias']\n",
            "unexpected keys: []\n",
            "MyModel(\n",
            "  (backbone): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (3): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (4): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (5): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (2): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
            "  )\n",
            ") \n",
            "\n",
            "Pipeline Mode: single\n",
            "Device: cuda\n",
            "\n",
            "Epoch 1/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.26 batch/s, lr=1.0e-04, Loss=1.0612]\n",
            "[Train] Kappa: 0.3995 Accuracy: 0.4050 Precision: 0.3031 Recall: 0.4050 Loss: 1.3919\n",
            "[Train] Class 0: Precision: 0.4269, Recall: 0.9167\n",
            "[Train] Class 1: Precision: 0.2000, Recall: 0.0208\n",
            "[Train] Class 2: Precision: 0.1905, Recall: 0.0333\n",
            "[Train] Class 3: Precision: 0.4011, Recall: 0.5917\n",
            "[Train] Class 4: Precision: 0.1667, Recall: 0.0083\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.58 batch/s]\n",
            "[Val] Kappa: 0.6676 Accuracy: 0.5450 Precision: 0.4986 Recall: 0.5450\n",
            "\n",
            "Epoch 2/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.17 batch/s, lr=1.0e-04, Loss=0.9811]\n",
            "[Train] Kappa: 0.7765 Accuracy: 0.5900 Precision: 0.5197 Recall: 0.5900 Loss: 1.1090\n",
            "[Train] Class 0: Precision: 0.7850, Recall: 0.9333\n",
            "[Train] Class 1: Precision: 0.5463, Recall: 0.4917\n",
            "[Train] Class 2: Precision: 0.3986, Recall: 0.2292\n",
            "[Train] Class 3: Precision: 0.4761, Recall: 0.8292\n",
            "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.82 batch/s]\n",
            "[Val] Kappa: 0.7744 Accuracy: 0.6600 Precision: 0.5992 Recall: 0.6600\n",
            "\n",
            "Epoch 3/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.08 batch/s, lr=1.0e-04, Loss=0.8296]\n",
            "[Train] Kappa: 0.8038 Accuracy: 0.6275 Precision: 0.5911 Recall: 0.6275 Loss: 0.9606\n",
            "[Train] Class 0: Precision: 0.8350, Recall: 0.9556\n",
            "[Train] Class 1: Precision: 0.5991, Recall: 0.5792\n",
            "[Train] Class 2: Precision: 0.4201, Recall: 0.2958\n",
            "[Train] Class 3: Precision: 0.5171, Recall: 0.8208\n",
            "[Train] Class 4: Precision: 0.3333, Recall: 0.0167\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.19 batch/s]\n",
            "[Val] Kappa: 0.7999 Accuracy: 0.6625 Precision: 0.5917 Recall: 0.6625\n",
            "\n",
            "Epoch 4/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.26 batch/s, lr=1.0e-04, Loss=0.9030]\n",
            "[Train] Kappa: 0.7788 Accuracy: 0.6192 Precision: 0.5811 Recall: 0.6192 Loss: 0.9292\n",
            "[Train] Class 0: Precision: 0.8268, Recall: 0.9417\n",
            "[Train] Class 1: Precision: 0.5756, Recall: 0.5708\n",
            "[Train] Class 2: Precision: 0.4091, Recall: 0.3375\n",
            "[Train] Class 3: Precision: 0.5457, Recall: 0.7458\n",
            "[Train] Class 4: Precision: 0.2692, Recall: 0.0583\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  8.32 batch/s]\n",
            "[Val] Kappa: 0.7810 Accuracy: 0.6550 Precision: 0.5822 Recall: 0.6550\n",
            "\n",
            "Epoch 5/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.26 batch/s, lr=1.0e-04, Loss=0.5673]\n",
            "[Train] Kappa: 0.7942 Accuracy: 0.6492 Precision: 0.6323 Recall: 0.6492 Loss: 0.8948\n",
            "[Train] Class 0: Precision: 0.8313, Recall: 0.9444\n",
            "[Train] Class 1: Precision: 0.6270, Recall: 0.6583\n",
            "[Train] Class 2: Precision: 0.4563, Recall: 0.3917\n",
            "[Train] Class 3: Precision: 0.5644, Recall: 0.7125\n",
            "[Train] Class 4: Precision: 0.5333, Recall: 0.1333\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.96 batch/s]\n",
            "[Val] Kappa: 0.8190 Accuracy: 0.6600 Precision: 0.6017 Recall: 0.6600\n",
            "\n",
            "Epoch 6/20\n",
            "Training: 100%|| 75/75 [00:15<00:00,  4.83 batch/s, lr=1.0e-04, Loss=1.1590]\n",
            "[Train] Kappa: 0.7986 Accuracy: 0.6525 Precision: 0.6376 Recall: 0.6525 Loss: 0.8887\n",
            "[Train] Class 0: Precision: 0.8428, Recall: 0.9083\n",
            "[Train] Class 1: Precision: 0.6089, Recall: 0.6292\n",
            "[Train] Class 2: Precision: 0.4976, Recall: 0.4375\n",
            "[Train] Class 3: Precision: 0.5884, Recall: 0.7208\n",
            "[Train] Class 4: Precision: 0.4576, Recall: 0.2250\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.17 batch/s]\n",
            "[Val] Kappa: 0.8384 Accuracy: 0.6575 Precision: 0.6070 Recall: 0.6575\n",
            "\n",
            "Epoch 7/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.10 batch/s, lr=1.0e-04, Loss=0.9400]\n",
            "[Train] Kappa: 0.8253 Accuracy: 0.6767 Precision: 0.6572 Recall: 0.6767 Loss: 0.8499\n",
            "[Train] Class 0: Precision: 0.8550, Recall: 0.9667\n",
            "[Train] Class 1: Precision: 0.6897, Recall: 0.6667\n",
            "[Train] Class 2: Precision: 0.5213, Recall: 0.4583\n",
            "[Train] Class 3: Precision: 0.5880, Recall: 0.6958\n",
            "[Train] Class 4: Precision: 0.4091, Recall: 0.2250\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.76 batch/s]\n",
            "[Val] Kappa: 0.8434 Accuracy: 0.6725 Precision: 0.6451 Recall: 0.6725\n",
            "\n",
            "Epoch 8/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.06 batch/s, lr=1.0e-04, Loss=1.0423]\n",
            "[Train] Kappa: 0.8204 Accuracy: 0.6775 Precision: 0.6612 Recall: 0.6775 Loss: 0.8350\n",
            "[Train] Class 0: Precision: 0.8636, Recall: 0.9500\n",
            "[Train] Class 1: Precision: 0.6534, Recall: 0.6833\n",
            "[Train] Class 2: Precision: 0.5377, Recall: 0.4458\n",
            "[Train] Class 3: Precision: 0.5825, Recall: 0.7208\n",
            "[Train] Class 4: Precision: 0.4737, Recall: 0.2250\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  6.93 batch/s]\n",
            "[Val] Kappa: 0.8063 Accuracy: 0.6675 Precision: 0.6288 Recall: 0.6675\n",
            "\n",
            "Epoch 9/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.15 batch/s, lr=1.0e-04, Loss=0.7370]\n",
            "[Train] Kappa: 0.8254 Accuracy: 0.6783 Precision: 0.6680 Recall: 0.6783 Loss: 0.8155\n",
            "[Train] Class 0: Precision: 0.8603, Recall: 0.9583\n",
            "[Train] Class 1: Precision: 0.6828, Recall: 0.6458\n",
            "[Train] Class 2: Precision: 0.4871, Recall: 0.4708\n",
            "[Train] Class 3: Precision: 0.5971, Recall: 0.6917\n",
            "[Train] Class 4: Precision: 0.5645, Recall: 0.2917\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.88 batch/s]\n",
            "[Val] Kappa: 0.7896 Accuracy: 0.6625 Precision: 0.6119 Recall: 0.6625\n",
            "\n",
            "Epoch 10/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.26 batch/s, lr=1.0e-04, Loss=0.8096]\n",
            "[Train] Kappa: 0.8086 Accuracy: 0.6683 Precision: 0.6528 Recall: 0.6683 Loss: 0.8186\n",
            "[Train] Class 0: Precision: 0.8662, Recall: 0.9528\n",
            "[Train] Class 1: Precision: 0.6298, Recall: 0.6875\n",
            "[Train] Class 2: Precision: 0.5393, Recall: 0.4292\n",
            "[Train] Class 3: Precision: 0.5714, Recall: 0.6500\n",
            "[Train] Class 4: Precision: 0.4487, Recall: 0.2917\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.22 batch/s]\n",
            "[Val] Kappa: 0.7715 Accuracy: 0.6575 Precision: 0.6306 Recall: 0.6575\n",
            "\n",
            "Epoch 11/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.25 batch/s, lr=1.0e-05, Loss=0.9694]\n",
            "[Train] Kappa: 0.8403 Accuracy: 0.6958 Precision: 0.6842 Recall: 0.6958 Loss: 0.7749\n",
            "[Train] Class 0: Precision: 0.8804, Recall: 0.9611\n",
            "[Train] Class 1: Precision: 0.7124, Recall: 0.6708\n",
            "[Train] Class 2: Precision: 0.5270, Recall: 0.5292\n",
            "[Train] Class 3: Precision: 0.6063, Recall: 0.7250\n",
            "[Train] Class 4: Precision: 0.5094, Recall: 0.2250\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.12 batch/s]\n",
            "[Val] Kappa: 0.8310 Accuracy: 0.6825 Precision: 0.6424 Recall: 0.6825\n",
            "\n",
            "Epoch 12/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.25 batch/s, lr=1.0e-05, Loss=1.1085]\n",
            "[Train] Kappa: 0.8578 Accuracy: 0.7100 Precision: 0.6935 Recall: 0.7100 Loss: 0.7450\n",
            "[Train] Class 0: Precision: 0.8787, Recall: 0.9861\n",
            "[Train] Class 1: Precision: 0.7004, Recall: 0.6917\n",
            "[Train] Class 2: Precision: 0.5581, Recall: 0.5000\n",
            "[Train] Class 3: Precision: 0.6370, Recall: 0.7458\n",
            "[Train] Class 4: Precision: 0.5079, Recall: 0.2667\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.44 batch/s]\n",
            "[Val] Kappa: 0.8207 Accuracy: 0.6825 Precision: 0.6526 Recall: 0.6825\n",
            "\n",
            "Epoch 13/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.17 batch/s, lr=1.0e-05, Loss=1.2931]\n",
            "[Train] Kappa: 0.8423 Accuracy: 0.7142 Precision: 0.7028 Recall: 0.7142 Loss: 0.7463\n",
            "[Train] Class 0: Precision: 0.8728, Recall: 0.9722\n",
            "[Train] Class 1: Precision: 0.7229, Recall: 0.6958\n",
            "[Train] Class 2: Precision: 0.5628, Recall: 0.5417\n",
            "[Train] Class 3: Precision: 0.6344, Recall: 0.7375\n",
            "[Train] Class 4: Precision: 0.5690, Recall: 0.2750\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.98 batch/s]\n",
            "[Val] Kappa: 0.8194 Accuracy: 0.6825 Precision: 0.6538 Recall: 0.6825\n",
            "\n",
            "Epoch 14/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.23 batch/s, lr=1.0e-05, Loss=0.5125]\n",
            "[Train] Kappa: 0.8492 Accuracy: 0.6942 Precision: 0.6841 Recall: 0.6942 Loss: 0.7664\n",
            "[Train] Class 0: Precision: 0.8789, Recall: 0.9472\n",
            "[Train] Class 1: Precision: 0.6737, Recall: 0.6625\n",
            "[Train] Class 2: Precision: 0.5455, Recall: 0.5000\n",
            "[Train] Class 3: Precision: 0.6103, Recall: 0.7375\n",
            "[Train] Class 4: Precision: 0.5455, Recall: 0.3000\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.79 batch/s]\n",
            "[Val] Kappa: 0.8334 Accuracy: 0.6800 Precision: 0.6554 Recall: 0.6800\n",
            "\n",
            "Epoch 15/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.20 batch/s, lr=1.0e-05, Loss=0.6440]\n",
            "[Train] Kappa: 0.8503 Accuracy: 0.7117 Precision: 0.6939 Recall: 0.7117 Loss: 0.7490\n",
            "[Train] Class 0: Precision: 0.8889, Recall: 0.9778\n",
            "[Train] Class 1: Precision: 0.7040, Recall: 0.7333\n",
            "[Train] Class 2: Precision: 0.5631, Recall: 0.4833\n",
            "[Train] Class 3: Precision: 0.6276, Recall: 0.7583\n",
            "[Train] Class 4: Precision: 0.4828, Recall: 0.2333\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.70 batch/s]\n",
            "[Val] Kappa: 0.8343 Accuracy: 0.6950 Precision: 0.6672 Recall: 0.6950\n",
            "\n",
            "Epoch 16/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.21 batch/s, lr=1.0e-05, Loss=0.6493]\n",
            "[Train] Kappa: 0.8421 Accuracy: 0.6967 Precision: 0.6785 Recall: 0.6967 Loss: 0.7716\n",
            "[Train] Class 0: Precision: 0.8785, Recall: 0.9639\n",
            "[Train] Class 1: Precision: 0.6984, Recall: 0.7333\n",
            "[Train] Class 2: Precision: 0.5524, Recall: 0.4833\n",
            "[Train] Class 3: Precision: 0.6000, Recall: 0.7125\n",
            "[Train] Class 4: Precision: 0.4483, Recall: 0.2167\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.44 batch/s]\n",
            "[Val] Kappa: 0.8317 Accuracy: 0.6675 Precision: 0.6358 Recall: 0.6675\n",
            "\n",
            "Epoch 17/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.13 batch/s, lr=1.0e-05, Loss=0.5919]\n",
            "[Train] Kappa: 0.8502 Accuracy: 0.7000 Precision: 0.6839 Recall: 0.7000 Loss: 0.7553\n",
            "[Train] Class 0: Precision: 0.8858, Recall: 0.9694\n",
            "[Train] Class 1: Precision: 0.7080, Recall: 0.7375\n",
            "[Train] Class 2: Precision: 0.5493, Recall: 0.4875\n",
            "[Train] Class 3: Precision: 0.5923, Recall: 0.7083\n",
            "[Train] Class 4: Precision: 0.4821, Recall: 0.2250\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.30 batch/s]\n",
            "[Val] Kappa: 0.8263 Accuracy: 0.6775 Precision: 0.6504 Recall: 0.6775\n",
            "\n",
            "Epoch 18/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.14 batch/s, lr=1.0e-05, Loss=0.7201]\n",
            "[Train] Kappa: 0.8420 Accuracy: 0.7000 Precision: 0.6849 Recall: 0.7000 Loss: 0.7465\n",
            "[Train] Class 0: Precision: 0.8897, Recall: 0.9639\n",
            "[Train] Class 1: Precision: 0.6885, Recall: 0.7458\n",
            "[Train] Class 2: Precision: 0.5505, Recall: 0.4542\n",
            "[Train] Class 3: Precision: 0.6007, Recall: 0.7208\n",
            "[Train] Class 4: Precision: 0.5000, Recall: 0.2667\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.72 batch/s]\n",
            "[Val] Kappa: 0.8246 Accuracy: 0.6700 Precision: 0.6400 Recall: 0.6700\n",
            "\n",
            "Epoch 19/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.21 batch/s, lr=1.0e-05, Loss=0.8674]\n",
            "[Train] Kappa: 0.8447 Accuracy: 0.7058 Precision: 0.6927 Recall: 0.7058 Loss: 0.7651\n",
            "[Train] Class 0: Precision: 0.8814, Recall: 0.9500\n",
            "[Train] Class 1: Precision: 0.6964, Recall: 0.7167\n",
            "[Train] Class 2: Precision: 0.5673, Recall: 0.4917\n",
            "[Train] Class 3: Precision: 0.6195, Recall: 0.7667\n",
            "[Train] Class 4: Precision: 0.5167, Recall: 0.2583\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.98 batch/s]\n",
            "[Val] Kappa: 0.8222 Accuracy: 0.6775 Precision: 0.6483 Recall: 0.6775\n",
            "\n",
            "Epoch 20/20\n",
            "Training: 100%|| 75/75 [00:14<00:00,  5.23 batch/s, lr=1.0e-05, Loss=0.7710]\n",
            "[Train] Kappa: 0.8394 Accuracy: 0.7025 Precision: 0.6858 Recall: 0.7025 Loss: 0.7659\n",
            "[Train] Class 0: Precision: 0.8682, Recall: 0.9694\n",
            "[Train] Class 1: Precision: 0.6929, Recall: 0.6958\n",
            "[Train] Class 2: Precision: 0.5640, Recall: 0.4958\n",
            "[Train] Class 3: Precision: 0.6277, Recall: 0.7375\n",
            "[Train] Class 4: Precision: 0.4844, Recall: 0.2583\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.87 batch/s]\n",
            "[Val] Kappa: 0.8260 Accuracy: 0.6775 Precision: 0.6514 Recall: 0.6775\n",
            "[Val] Best kappa: 0.8434, Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-6ebebff37fa4>:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('/content/drive/MyDrive/models/model4.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating: 100%|| 25/25 [00:03<00:00,  6.88 batch/s]\n",
            "[Test] Save predictions to /content/drive/MyDrive/Predictions/test_predictions4.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "def train_model_EfficientNet(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs,\n",
        "                checkpoint_path):\n",
        "    \"\"\"\n",
        "    Train the model using EfficientNet-B0 as the backbone.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The PyTorch model to train.\n",
        "        train_loader (DataLoader): DataLoader for training data.\n",
        "        val_loader (DataLoader): DataLoader for validation data.\n",
        "        device (torch.device): Device to run the training on (CPU or GPU).\n",
        "        criterion: Loss function.\n",
        "        optimizer: Optimizer for model training.\n",
        "        lr_scheduler: Learning rate scheduler.\n",
        "        num_epochs (int): Number of epochs to train for.\n",
        "        checkpoint_path (str): Path to save the best model checkpoint.\n",
        "\n",
        "    Returns:\n",
        "        nn.Module: The trained model.\n",
        "    \"\"\"\n",
        "    best_model = model.state_dict()\n",
        "    best_epoch = None\n",
        "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
        "        running_loss = []\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
        "            for images, labels in train_loader:\n",
        "                # Resize images to match EfficientNet-B0 input size\n",
        "                images = F.interpolate(images, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "\n",
        "                images = images.to(device)  # Send images to device\n",
        "                labels = labels.to(device)  # Send labels to device\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = model(images)  # Forward pass\n",
        "                loss = criterion(outputs, labels.long())\n",
        "\n",
        "                loss.backward()  # Backpropagation\n",
        "                optimizer.step()  # Optimizer step\n",
        "\n",
        "                preds = torch.argmax(outputs, 1)  # Get predicted labels\n",
        "                all_preds.extend(preds.cpu().numpy())  # Collect predictions\n",
        "                all_labels.extend(labels.cpu().numpy())  # Collect true labels\n",
        "\n",
        "                running_loss.append(loss.item())  # Track loss\n",
        "\n",
        "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
        "                pbar.update(1)\n",
        "\n",
        "        lr_scheduler.step()  # Update learning rate\n",
        "\n",
        "        epoch_loss = sum(running_loss) / len(running_loss)\n",
        "\n",
        "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)  # Compute metrics\n",
        "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
        "\n",
        "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
        "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
        "\n",
        "        if len(train_metrics) > 4:\n",
        "            precision_per_class, recall_per_class = train_metrics[4:]\n",
        "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
        "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
        "\n",
        "        # Evaluation on the validation set\n",
        "        val_metrics = evaluate_model(model, val_loader, device)\n",
        "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
        "\n",
        "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
        "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
        "\n",
        "        # Save the best model based on validation kappa\n",
        "        if val_kappa > best_val_kappa:\n",
        "            best_val_kappa = val_kappa\n",
        "            best_epoch = epoch\n",
        "            best_model = model.state_dict()\n",
        "            torch.save(best_model, checkpoint_path)\n",
        "\n",
        "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
        "\n",
        "    # Load the best model before returning\n",
        "    model.load_state_dict(best_model)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "qiyJIaBcQMlM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel_efficientnet(nn.Module):\n",
        "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        # self.backbone = models.resnet18(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained_DR_resize/pretrained/resnet18.pth', map_location='cpu')\n",
        "\n",
        "\n",
        "        # self.backbone = models.resnet34(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained_DR_resize/pretrained/resnet34.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.vgg16(pretrained=True)\n",
        "        # self.backbone.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # state_dict = torch.load('pretrained/vgg16.pth', map_location='cpu')\n",
        "\n",
        "        self.backbone = models.efficientnet_b0(pretrained=True)\n",
        "        state_dict = torch.load('pretrained_DR_resize/pretrained/efficientnet_b0.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.densenet121(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained/densenet121.pth', map_location='cpu')\n",
        "\n",
        "        info = self.backbone.load_state_dict(state_dict, strict=False)\n",
        "        print('missing keys:', info[0])  # The missing fc or classifier layer is normal here\n",
        "        print('unexpected keys:', info[1])\n",
        "\n",
        "        self.backbone.classifier = nn.Sequential()  # Ensure no residual classifier\n",
        "\n",
        "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(1280, 256),  # EfficientNet-B0 outputs 1280 features\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Fy7QhnOVOFGk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Choose between 'single image' and 'dual images' pipeline\n",
        "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
        "\n",
        "    mode = 'single'  # forward single image to the model each time\n",
        "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
        "\n",
        "    assert mode in ('single', 'dual')\n",
        "\n",
        "    # Define the model\n",
        "    if mode == 'single':\n",
        "        model = MyModel()\n",
        "    else:\n",
        "        model = MyDualModel()\n",
        "\n",
        "    print(model, '\\n')\n",
        "    print('Pipeline Mode:', mode)\n",
        "\n",
        "    # tuned Hyper Parameters\n",
        "    batch_size = 16\n",
        "    num_classes = 5  # 5 DR levels\n",
        "    learning_rate = 0.0001\n",
        "    num_epochs = 20\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = RetinopathyDataset('/content/DeepDRiD/train.csv', '/content/DeepDRiD/train', transform_train, mode)\n",
        "    val_dataset = RetinopathyDataset('/content/DeepDRiD/val.csv', '/content/DeepDRiD/val/', transform_test, mode)\n",
        "    test_dataset = RetinopathyDataset('/content/DeepDRiD/test.csv', '/content/DeepDRiD/test', transform_test, mode, test=True)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop((224, 224)),\n",
        "    SLORandomPad((224, 224)),\n",
        "    FundRandomRotate(prob=0.5, degree=30),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Define the weighted CrossEntropyLoss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Use GPU device is possible\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print('Device:', device)\n",
        "\n",
        "    # Move class weights to the device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Optimizer and Learning rate scheduler\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "     # Train and evaluate the model with the training and validation set\n",
        "    model = train_model_EfficientNet(\n",
        "        model, train_loader, val_loader, device, criterion, optimizer,\n",
        "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
        "        checkpoint_path='/content/drive/MyDrive/models/model5.pth'\n",
        "    )\n",
        "\n",
        "    # Load the pretrained checkpoint\n",
        "    state_dict = torch.load('/content/drive/MyDrive/models/model5.pth', map_location='cpu')\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Make predictions on testing set and save the prediction results\n",
        "    evaluate_model(model, test_loader, device, test_only=True, prediction_path='/content/drive/MyDrive/Predictions/test_predictions5.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-fHFzJqOHf0",
        "outputId": "006c94eb-7fe2-4f67-acff-830b3a6c94e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-45-25bf9b928b30>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('pretrained_DR_resize/pretrained/efficientnet_b0.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing keys: ['classifier.1.weight', 'classifier.1.bias']\n",
            "unexpected keys: []\n",
            "MyModel(\n",
            "  (backbone): EfficientNet(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2dNormActivation(\n",
            "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (2): Conv2dNormActivation(\n",
            "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
            "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
            "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (4): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
            "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
            "        )\n",
            "        (2): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (5): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
            "        )\n",
            "        (2): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (6): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
            "        )\n",
            "        (2): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
            "        )\n",
            "        (3): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (7): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (8): Conv2dNormActivation(\n",
            "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "    (classifier): Sequential()\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=1280, out_features=256, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
            "  )\n",
            ") \n",
            "\n",
            "Pipeline Mode: single\n",
            "Device: cuda\n",
            "\n",
            "Epoch 1/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.48 batch/s, lr=1.0e-04, Loss=0.9461]\n",
            "[Train] Kappa: 0.5447 Accuracy: 0.4625 Precision: 0.4117 Recall: 0.4625 Loss: 1.3680\n",
            "[Train] Class 0: Precision: 0.4777, Recall: 0.9500\n",
            "[Train] Class 1: Precision: 0.2143, Recall: 0.0125\n",
            "[Train] Class 2: Precision: 0.3756, Recall: 0.3208\n",
            "[Train] Class 3: Precision: 0.5020, Recall: 0.5333\n",
            "[Train] Class 4: Precision: 0.5000, Recall: 0.0417\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.58 batch/s]\n",
            "[Val] Kappa: 0.8129 Accuracy: 0.5450 Precision: 0.5209 Recall: 0.5450\n",
            "\n",
            "Epoch 2/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.35 batch/s, lr=1.0e-04, Loss=0.9834]\n",
            "[Train] Kappa: 0.8285 Accuracy: 0.6058 Precision: 0.6511 Recall: 0.6058 Loss: 1.0213\n",
            "[Train] Class 0: Precision: 0.7211, Recall: 0.9694\n",
            "[Train] Class 1: Precision: 0.6340, Recall: 0.4042\n",
            "[Train] Class 2: Precision: 0.5556, Recall: 0.2500\n",
            "[Train] Class 3: Precision: 0.4846, Recall: 0.9167\n",
            "[Train] Class 4: Precision: 1.0000, Recall: 0.0083\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.28 batch/s]\n",
            "[Val] Kappa: 0.8269 Accuracy: 0.6925 Precision: 0.6233 Recall: 0.6925\n",
            "\n",
            "Epoch 3/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.43 batch/s, lr=1.0e-04, Loss=0.6918]\n",
            "[Train] Kappa: 0.8239 Accuracy: 0.6600 Precision: 0.6224 Recall: 0.6600 Loss: 0.8681\n",
            "[Train] Class 0: Precision: 0.8513, Recall: 0.9222\n",
            "[Train] Class 1: Precision: 0.6289, Recall: 0.6708\n",
            "[Train] Class 2: Precision: 0.5204, Recall: 0.4250\n",
            "[Train] Class 3: Precision: 0.5607, Recall: 0.8083\n",
            "[Train] Class 4: Precision: 0.2500, Recall: 0.0250\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.68 batch/s]\n",
            "[Val] Kappa: 0.8453 Accuracy: 0.7175 Precision: 0.6516 Recall: 0.7175\n",
            "\n",
            "Epoch 4/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.31 batch/s, lr=1.0e-04, Loss=0.5715]\n",
            "[Train] Kappa: 0.8562 Accuracy: 0.6758 Precision: 0.6469 Recall: 0.6758 Loss: 0.7969\n",
            "[Train] Class 0: Precision: 0.8912, Recall: 0.9333\n",
            "[Train] Class 1: Precision: 0.6693, Recall: 0.7000\n",
            "[Train] Class 2: Precision: 0.5223, Recall: 0.4875\n",
            "[Train] Class 3: Precision: 0.5589, Recall: 0.7708\n",
            "[Train] Class 4: Precision: 0.2941, Recall: 0.0417\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  6.29 batch/s]\n",
            "[Val] Kappa: 0.8418 Accuracy: 0.7200 Precision: 0.6540 Recall: 0.7200\n",
            "\n",
            "Epoch 5/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.49 batch/s, lr=1.0e-04, Loss=0.9306]\n",
            "[Train] Kappa: 0.8603 Accuracy: 0.7075 Precision: 0.6804 Recall: 0.7075 Loss: 0.7482\n",
            "[Train] Class 0: Precision: 0.8918, Recall: 0.9611\n",
            "[Train] Class 1: Precision: 0.7316, Recall: 0.7042\n",
            "[Train] Class 2: Precision: 0.5991, Recall: 0.5542\n",
            "[Train] Class 3: Precision: 0.5836, Recall: 0.8000\n",
            "[Train] Class 4: Precision: 0.3000, Recall: 0.0750\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.42 batch/s]\n",
            "[Val] Kappa: 0.8204 Accuracy: 0.6975 Precision: 0.6323 Recall: 0.6975\n",
            "\n",
            "Epoch 6/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.38 batch/s, lr=1.0e-04, Loss=0.7690]\n",
            "[Train] Kappa: 0.8501 Accuracy: 0.7067 Precision: 0.6891 Recall: 0.7067 Loss: 0.7285\n",
            "[Train] Class 0: Precision: 0.8825, Recall: 0.9389\n",
            "[Train] Class 1: Precision: 0.6892, Recall: 0.7208\n",
            "[Train] Class 2: Precision: 0.5938, Recall: 0.5542\n",
            "[Train] Class 3: Precision: 0.6117, Recall: 0.7875\n",
            "[Train] Class 4: Precision: 0.4545, Recall: 0.1250\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.50 batch/s]\n",
            "[Val] Kappa: 0.8314 Accuracy: 0.7150 Precision: 0.6513 Recall: 0.7150\n",
            "\n",
            "Epoch 7/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.45 batch/s, lr=1.0e-04, Loss=0.5272]\n",
            "[Train] Kappa: 0.8732 Accuracy: 0.7392 Precision: 0.7273 Recall: 0.7392 Loss: 0.6854\n",
            "[Train] Class 0: Precision: 0.8987, Recall: 0.9611\n",
            "[Train] Class 1: Precision: 0.7291, Recall: 0.7625\n",
            "[Train] Class 2: Precision: 0.6486, Recall: 0.6000\n",
            "[Train] Class 3: Precision: 0.6358, Recall: 0.8000\n",
            "[Train] Class 4: Precision: 0.5500, Recall: 0.1833\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.25 batch/s]\n",
            "[Val] Kappa: 0.8424 Accuracy: 0.6950 Precision: 0.6595 Recall: 0.6950\n",
            "\n",
            "Epoch 8/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.49 batch/s, lr=1.0e-04, Loss=0.4467]\n",
            "[Train] Kappa: 0.8875 Accuracy: 0.7425 Precision: 0.7363 Recall: 0.7425 Loss: 0.6404\n",
            "[Train] Class 0: Precision: 0.9023, Recall: 0.9750\n",
            "[Train] Class 1: Precision: 0.7832, Recall: 0.7375\n",
            "[Train] Class 2: Precision: 0.6276, Recall: 0.6250\n",
            "[Train] Class 3: Precision: 0.6174, Recall: 0.8000\n",
            "[Train] Class 4: Precision: 0.6000, Recall: 0.1750\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.55 batch/s]\n",
            "[Val] Kappa: 0.8376 Accuracy: 0.6975 Precision: 0.6555 Recall: 0.6975\n",
            "\n",
            "Epoch 9/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.41 batch/s, lr=1.0e-04, Loss=0.4559]\n",
            "[Train] Kappa: 0.9001 Accuracy: 0.7842 Precision: 0.7793 Recall: 0.7842 Loss: 0.5710\n",
            "[Train] Class 0: Precision: 0.9328, Recall: 0.9639\n",
            "[Train] Class 1: Precision: 0.7912, Recall: 0.8208\n",
            "[Train] Class 2: Precision: 0.7149, Recall: 0.6583\n",
            "[Train] Class 3: Precision: 0.6745, Recall: 0.8375\n",
            "[Train] Class 4: Precision: 0.6333, Recall: 0.3167\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.13 batch/s]\n",
            "[Val] Kappa: 0.8148 Accuracy: 0.6775 Precision: 0.6485 Recall: 0.6775\n",
            "\n",
            "Epoch 10/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.47 batch/s, lr=1.0e-04, Loss=0.3554]\n",
            "[Train] Kappa: 0.8974 Accuracy: 0.7750 Precision: 0.7689 Recall: 0.7750 Loss: 0.5834\n",
            "[Train] Class 0: Precision: 0.9134, Recall: 0.9667\n",
            "[Train] Class 1: Precision: 0.8263, Recall: 0.8125\n",
            "[Train] Class 2: Precision: 0.6930, Recall: 0.6583\n",
            "[Train] Class 3: Precision: 0.6532, Recall: 0.8083\n",
            "[Train] Class 4: Precision: 0.6034, Recall: 0.2917\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.41 batch/s]\n",
            "[Val] Kappa: 0.7834 Accuracy: 0.6850 Precision: 0.6619 Recall: 0.6850\n",
            "\n",
            "Epoch 11/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.31 batch/s, lr=1.0e-05, Loss=0.5376]\n",
            "[Train] Kappa: 0.9113 Accuracy: 0.7950 Precision: 0.7872 Recall: 0.7950 Loss: 0.5120\n",
            "[Train] Class 0: Precision: 0.9380, Recall: 0.9667\n",
            "[Train] Class 1: Precision: 0.7899, Recall: 0.8458\n",
            "[Train] Class 2: Precision: 0.7203, Recall: 0.7083\n",
            "[Train] Class 3: Precision: 0.7214, Recall: 0.7875\n",
            "[Train] Class 4: Precision: 0.5946, Recall: 0.3667\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.64 batch/s]\n",
            "[Val] Kappa: 0.7943 Accuracy: 0.6775 Precision: 0.6574 Recall: 0.6775\n",
            "\n",
            "Epoch 12/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.51 batch/s, lr=1.0e-05, Loss=0.8448]\n",
            "[Train] Kappa: 0.9042 Accuracy: 0.8158 Precision: 0.8084 Recall: 0.8158 Loss: 0.5133\n",
            "[Train] Class 0: Precision: 0.9215, Recall: 0.9778\n",
            "[Train] Class 1: Precision: 0.8435, Recall: 0.8083\n",
            "[Train] Class 2: Precision: 0.7702, Recall: 0.7958\n",
            "[Train] Class 3: Precision: 0.7326, Recall: 0.8333\n",
            "[Train] Class 4: Precision: 0.6269, Recall: 0.3500\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.51 batch/s]\n",
            "[Val] Kappa: 0.7953 Accuracy: 0.6725 Precision: 0.6465 Recall: 0.6725\n",
            "\n",
            "Epoch 13/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.50 batch/s, lr=1.0e-05, Loss=0.4770]\n",
            "[Train] Kappa: 0.9235 Accuracy: 0.8242 Precision: 0.8245 Recall: 0.8242 Loss: 0.4843\n",
            "[Train] Class 0: Precision: 0.9564, Recall: 0.9750\n",
            "[Train] Class 1: Precision: 0.8382, Recall: 0.8417\n",
            "[Train] Class 2: Precision: 0.7261, Recall: 0.7292\n",
            "[Train] Class 3: Precision: 0.7348, Recall: 0.8542\n",
            "[Train] Class 4: Precision: 0.7778, Recall: 0.4667\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.58 batch/s]\n",
            "[Val] Kappa: 0.8075 Accuracy: 0.6875 Precision: 0.6685 Recall: 0.6875\n",
            "\n",
            "Epoch 14/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.40 batch/s, lr=1.0e-05, Loss=0.8514]\n",
            "[Train] Kappa: 0.9151 Accuracy: 0.8142 Precision: 0.8092 Recall: 0.8142 Loss: 0.5047\n",
            "[Train] Class 0: Precision: 0.9434, Recall: 0.9722\n",
            "[Train] Class 1: Precision: 0.8305, Recall: 0.8167\n",
            "[Train] Class 2: Precision: 0.7645, Recall: 0.7708\n",
            "[Train] Class 3: Precision: 0.7232, Recall: 0.8167\n",
            "[Train] Class 4: Precision: 0.6250, Recall: 0.4167\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.26 batch/s]\n",
            "[Val] Kappa: 0.7989 Accuracy: 0.6850 Precision: 0.6642 Recall: 0.6850\n",
            "\n",
            "Epoch 15/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.48 batch/s, lr=1.0e-05, Loss=0.4606]\n",
            "[Train] Kappa: 0.9366 Accuracy: 0.8417 Precision: 0.8397 Recall: 0.8417 Loss: 0.4505\n",
            "[Train] Class 0: Precision: 0.9544, Recall: 0.9889\n",
            "[Train] Class 1: Precision: 0.8793, Recall: 0.8500\n",
            "[Train] Class 2: Precision: 0.7975, Recall: 0.8042\n",
            "[Train] Class 3: Precision: 0.7302, Recall: 0.8458\n",
            "[Train] Class 4: Precision: 0.7200, Recall: 0.4500\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.47 batch/s]\n",
            "[Val] Kappa: 0.8102 Accuracy: 0.6900 Precision: 0.6774 Recall: 0.6900\n",
            "\n",
            "Epoch 16/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.20 batch/s, lr=1.0e-05, Loss=0.2966]\n",
            "[Train] Kappa: 0.9134 Accuracy: 0.8150 Precision: 0.8103 Recall: 0.8150 Loss: 0.4864\n",
            "[Train] Class 0: Precision: 0.9435, Recall: 0.9750\n",
            "[Train] Class 1: Precision: 0.8279, Recall: 0.8417\n",
            "[Train] Class 2: Precision: 0.7386, Recall: 0.7417\n",
            "[Train] Class 3: Precision: 0.7385, Recall: 0.8000\n",
            "[Train] Class 4: Precision: 0.6627, Recall: 0.4583\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.77 batch/s]\n",
            "[Val] Kappa: 0.8057 Accuracy: 0.6725 Precision: 0.6606 Recall: 0.6725\n",
            "\n",
            "Epoch 17/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.50 batch/s, lr=1.0e-05, Loss=0.5655]\n",
            "[Train] Kappa: 0.9100 Accuracy: 0.8142 Precision: 0.8087 Recall: 0.8142 Loss: 0.5044\n",
            "[Train] Class 0: Precision: 0.9404, Recall: 0.9639\n",
            "[Train] Class 1: Precision: 0.8506, Recall: 0.8542\n",
            "[Train] Class 2: Precision: 0.7593, Recall: 0.7625\n",
            "[Train] Class 3: Precision: 0.7262, Recall: 0.7958\n",
            "[Train] Class 4: Precision: 0.5930, Recall: 0.4250\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.37 batch/s]\n",
            "[Val] Kappa: 0.7884 Accuracy: 0.6650 Precision: 0.6470 Recall: 0.6650\n",
            "\n",
            "Epoch 18/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.41 batch/s, lr=1.0e-05, Loss=0.9257]\n",
            "[Train] Kappa: 0.9111 Accuracy: 0.8142 Precision: 0.8111 Recall: 0.8142 Loss: 0.4829\n",
            "[Train] Class 0: Precision: 0.9409, Recall: 0.9722\n",
            "[Train] Class 1: Precision: 0.8201, Recall: 0.8167\n",
            "[Train] Class 2: Precision: 0.7183, Recall: 0.7542\n",
            "[Train] Class 3: Precision: 0.7741, Recall: 0.7708\n",
            "[Train] Class 4: Precision: 0.6633, Recall: 0.5417\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.27 batch/s]\n",
            "[Val] Kappa: 0.7999 Accuracy: 0.6800 Precision: 0.6663 Recall: 0.6800\n",
            "\n",
            "Epoch 19/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.45 batch/s, lr=1.0e-05, Loss=0.5502]\n",
            "[Train] Kappa: 0.9220 Accuracy: 0.8125 Precision: 0.8086 Recall: 0.8125 Loss: 0.4886\n",
            "[Train] Class 0: Precision: 0.9284, Recall: 0.9722\n",
            "[Train] Class 1: Precision: 0.8292, Recall: 0.8292\n",
            "[Train] Class 2: Precision: 0.7783, Recall: 0.7167\n",
            "[Train] Class 3: Precision: 0.7239, Recall: 0.8083\n",
            "[Train] Class 4: Precision: 0.6383, Recall: 0.5000\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.27 batch/s]\n",
            "[Val] Kappa: 0.8072 Accuracy: 0.6800 Precision: 0.6741 Recall: 0.6800\n",
            "\n",
            "Epoch 20/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.48 batch/s, lr=1.0e-05, Loss=0.4552]\n",
            "[Train] Kappa: 0.9143 Accuracy: 0.8092 Precision: 0.8067 Recall: 0.8092 Loss: 0.5034\n",
            "[Train] Class 0: Precision: 0.9375, Recall: 0.9583\n",
            "[Train] Class 1: Precision: 0.8270, Recall: 0.8167\n",
            "[Train] Class 2: Precision: 0.7205, Recall: 0.7625\n",
            "[Train] Class 3: Precision: 0.7430, Recall: 0.7708\n",
            "[Train] Class 4: Precision: 0.6739, Recall: 0.5167\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.46 batch/s]\n",
            "[Val] Kappa: 0.7989 Accuracy: 0.6725 Precision: 0.6612 Recall: 0.6725\n",
            "[Val] Best kappa: 0.8453, Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-46-8578a8f61049>:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('/content/drive/MyDrive/models/model5.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.38 batch/s]\n",
            "[Test] Save predictions to /content/drive/MyDrive/Predictions/test_predictions5.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Implement only one attention mechanisms (e.g., self-attention, channel attention, or spatial attention) in this model archtecture.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        self.fc1   = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2   = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
        "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        self.backbone = models.efficientnet_b0(pretrained=True)\n",
        "        state_dict = torch.load('pretrained_DR_resize/pretrained/efficientnet_b0.pth', map_location='cpu')\n",
        "        info = self.backbone.load_state_dict(state_dict, strict=False)\n",
        "        print('missing keys:', info[0])\n",
        "        print('unexpected keys:', info[1])\n",
        "        self.backbone.classifier = nn.Sequential()\n",
        "        self.backbone.fc = nn.Identity()\n",
        "\n",
        "        self.ca = ChannelAttention(1280) #Apply channel attention to the output of EfficientNet\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(1280, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.backbone(x)\n",
        "        # x = self.ca(x) * x # Apply channel attention\n",
        "        # x = x.view(x.size(0),-1) # Flatten for the fully connected layers.\n",
        "        # x = self.fc(x)\n",
        "        x = self.backbone(x)  # EfficientNet feature extractor output\n",
        "        x = x.unsqueeze(-1).unsqueeze(-1)  # Reshape to [batch_size, 1280, 1, 1] for ChannelAttention\n",
        "        x = self.ca(x) * x  # Apply channel attention\n",
        "        x = x.view(x.size(0), -1)  # Flatten for the fully connected layers\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "zy5xj6fRW5El"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Choose between 'single image' and 'dual images' pipeline\n",
        "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
        "\n",
        "    mode = 'single'  # forward single image to the model each time\n",
        "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
        "\n",
        "    assert mode in ('single', 'dual')\n",
        "\n",
        "    # Define the model\n",
        "    if mode == 'single':\n",
        "        model = MyModel()\n",
        "    else:\n",
        "        model = MyDualModel()\n",
        "\n",
        "    print(model, '\\n')\n",
        "    print('Pipeline Mode:', mode)\n",
        "\n",
        "    # tuned Hyper Parameters\n",
        "    batch_size = 16\n",
        "    num_classes = 5  # 5 DR levels\n",
        "    learning_rate = 0.0001\n",
        "    num_epochs = 20\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = RetinopathyDataset('/content/DeepDRiD/train.csv', '/content/DeepDRiD/train', transform_train, mode)\n",
        "    val_dataset = RetinopathyDataset('/content/DeepDRiD/val.csv', '/content/DeepDRiD/val/', transform_test, mode)\n",
        "    test_dataset = RetinopathyDataset('/content/DeepDRiD/test.csv', '/content/DeepDRiD/test', transform_test, mode, test=True)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop((224, 224)),\n",
        "    SLORandomPad((224, 224)),\n",
        "    FundRandomRotate(prob=0.5, degree=30),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Define the weighted CrossEntropyLoss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Use GPU device is possible\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print('Device:', device)\n",
        "\n",
        "    # Move class weights to the device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Optimizer and Learning rate scheduler\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "     # Train and evaluate the model with the training and validation set\n",
        "    model = train_model_EfficientNet(\n",
        "        model, train_loader, val_loader, device, criterion, optimizer,\n",
        "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
        "        checkpoint_path='/content/drive/MyDrive/models/model6.pth'\n",
        "    )\n",
        "\n",
        "    # Load the pretrained checkpoint\n",
        "    state_dict = torch.load('/content/drive/MyDrive/models/model6.pth', map_location='cpu')\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Make predictions on testing set and save the prediction results\n",
        "    evaluate_model(model, test_loader, device, test_only=True, prediction_path='/content/drive/MyDrive/Predictions/test_predictions6.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2ZiaTwrX511",
        "outputId": "20dadde3-a8f0-4b60-9129-568193147b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-49-0847e2570fe0>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('pretrained_DR_resize/pretrained/efficientnet_b0.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing keys: ['classifier.1.weight', 'classifier.1.bias']\n",
            "unexpected keys: []\n",
            "MyModel(\n",
            "  (backbone): EfficientNet(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2dNormActivation(\n",
            "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (2): Conv2dNormActivation(\n",
            "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
            "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
            "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (4): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
            "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
            "        )\n",
            "        (2): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (5): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
            "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
            "        )\n",
            "        (2): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (6): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
            "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
            "        )\n",
            "        (1): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
            "        )\n",
            "        (2): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
            "        )\n",
            "        (3): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (7): Sequential(\n",
            "        (0): MBConv(\n",
            "          (block): Sequential(\n",
            "            (0): Conv2dNormActivation(\n",
            "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (1): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): SiLU(inplace=True)\n",
            "            )\n",
            "            (2): SqueezeExcitation(\n",
            "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
            "              (activation): SiLU(inplace=True)\n",
            "              (scale_activation): Sigmoid()\n",
            "            )\n",
            "            (3): Conv2dNormActivation(\n",
            "              (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
            "        )\n",
            "      )\n",
            "      (8): Conv2dNormActivation(\n",
            "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "    (classifier): Sequential()\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (ca): ChannelAttention(\n",
            "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "    (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
            "    (fc1): Conv2d(1280, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (relu1): ReLU()\n",
            "    (fc2): Conv2d(80, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=1280, out_features=256, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
            "  )\n",
            ") \n",
            "\n",
            "Pipeline Mode: single\n",
            "Device: cuda\n",
            "\n",
            "Epoch 1/20\n",
            "Training: 100%|| 75/75 [00:18<00:00,  4.03 batch/s, lr=1.0e-04, Loss=1.3119]\n",
            "[Train] Kappa: 0.6352 Accuracy: 0.4725 Precision: 0.5431 Recall: 0.4725 Loss: 1.4283\n",
            "[Train] Class 0: Precision: 0.6110, Recall: 0.8639\n",
            "[Train] Class 1: Precision: 0.4324, Recall: 0.1333\n",
            "[Train] Class 2: Precision: 1.0000, Recall: 0.0042\n",
            "[Train] Class 3: Precision: 0.3668, Recall: 0.9292\n",
            "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.87 batch/s]\n",
            "[Val] Kappa: 0.7936 Accuracy: 0.5625 Precision: 0.4605 Recall: 0.5625\n",
            "\n",
            "Epoch 2/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.29 batch/s, lr=1.0e-04, Loss=1.3430]\n",
            "[Train] Kappa: 0.7941 Accuracy: 0.5983 Precision: 0.5579 Recall: 0.5983 Loss: 1.0981\n",
            "[Train] Class 0: Precision: 0.7636, Recall: 0.9778\n",
            "[Train] Class 1: Precision: 0.6554, Recall: 0.4833\n",
            "[Train] Class 2: Precision: 0.5532, Recall: 0.1083\n",
            "[Train] Class 3: Precision: 0.4358, Recall: 0.9333\n",
            "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.34 batch/s]\n",
            "[Val] Kappa: 0.8227 Accuracy: 0.6675 Precision: 0.6403 Recall: 0.6675\n",
            "\n",
            "Epoch 3/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.37 batch/s, lr=1.0e-04, Loss=0.9469]\n",
            "[Train] Kappa: 0.8152 Accuracy: 0.6583 Precision: 0.6155 Recall: 0.6583 Loss: 0.9113\n",
            "[Train] Class 0: Precision: 0.8535, Recall: 0.9389\n",
            "[Train] Class 1: Precision: 0.6089, Recall: 0.6875\n",
            "[Train] Class 2: Precision: 0.5058, Recall: 0.3625\n",
            "[Train] Class 3: Precision: 0.5574, Recall: 0.8292\n",
            "[Train] Class 4: Precision: 0.2500, Recall: 0.0083\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.10 batch/s]\n",
            "[Val] Kappa: 0.8422 Accuracy: 0.7100 Precision: 0.6456 Recall: 0.7100\n",
            "\n",
            "Epoch 4/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.17 batch/s, lr=1.0e-04, Loss=0.8796]\n",
            "[Train] Kappa: 0.8404 Accuracy: 0.6783 Precision: 0.6403 Recall: 0.6783 Loss: 0.8485\n",
            "[Train] Class 0: Precision: 0.8740, Recall: 0.9444\n",
            "[Train] Class 1: Precision: 0.6522, Recall: 0.6875\n",
            "[Train] Class 2: Precision: 0.5493, Recall: 0.4875\n",
            "[Train] Class 3: Precision: 0.5638, Recall: 0.7917\n",
            "[Train] Class 4: Precision: 0.2500, Recall: 0.0167\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.30 batch/s]\n",
            "[Val] Kappa: 0.8238 Accuracy: 0.7125 Precision: 0.6404 Recall: 0.7125\n",
            "\n",
            "Epoch 5/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.41 batch/s, lr=1.0e-04, Loss=0.8129]\n",
            "[Train] Kappa: 0.8529 Accuracy: 0.6992 Precision: 0.6817 Recall: 0.6992 Loss: 0.7773\n",
            "[Train] Class 0: Precision: 0.8883, Recall: 0.9500\n",
            "[Train] Class 1: Precision: 0.7097, Recall: 0.7333\n",
            "[Train] Class 2: Precision: 0.5714, Recall: 0.5167\n",
            "[Train] Class 3: Precision: 0.5697, Recall: 0.7833\n",
            "[Train] Class 4: Precision: 0.4500, Recall: 0.0750\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.18 batch/s]\n",
            "[Val] Kappa: 0.8172 Accuracy: 0.6875 Precision: 0.6225 Recall: 0.6875\n",
            "\n",
            "Epoch 6/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.30 batch/s, lr=1.0e-04, Loss=1.0499]\n",
            "[Train] Kappa: 0.8479 Accuracy: 0.7042 Precision: 0.6910 Recall: 0.7042 Loss: 0.7547\n",
            "[Train] Class 0: Precision: 0.8763, Recall: 0.9444\n",
            "[Train] Class 1: Precision: 0.6855, Recall: 0.7083\n",
            "[Train] Class 2: Precision: 0.5804, Recall: 0.5417\n",
            "[Train] Class 3: Precision: 0.6055, Recall: 0.8250\n",
            "[Train] Class 4: Precision: 0.5385, Recall: 0.0583\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.62 batch/s]\n",
            "[Val] Kappa: 0.8313 Accuracy: 0.7050 Precision: 0.6385 Recall: 0.7050\n",
            "\n",
            "Epoch 7/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.42 batch/s, lr=1.0e-04, Loss=0.6223]\n",
            "[Train] Kappa: 0.8796 Accuracy: 0.7317 Precision: 0.7207 Recall: 0.7317 Loss: 0.6916\n",
            "[Train] Class 0: Precision: 0.9158, Recall: 0.9361\n",
            "[Train] Class 1: Precision: 0.7198, Recall: 0.7708\n",
            "[Train] Class 2: Precision: 0.6820, Recall: 0.6167\n",
            "[Train] Class 3: Precision: 0.5962, Recall: 0.7875\n",
            "[Train] Class 4: Precision: 0.4634, Recall: 0.1583\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.10 batch/s]\n",
            "[Val] Kappa: 0.8313 Accuracy: 0.7050 Precision: 0.6383 Recall: 0.7050\n",
            "\n",
            "Epoch 8/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.38 batch/s, lr=1.0e-04, Loss=0.4708]\n",
            "[Train] Kappa: 0.8748 Accuracy: 0.7508 Precision: 0.7331 Recall: 0.7508 Loss: 0.6275\n",
            "[Train] Class 0: Precision: 0.9021, Recall: 0.9722\n",
            "[Train] Class 1: Precision: 0.7705, Recall: 0.7833\n",
            "[Train] Class 2: Precision: 0.6596, Recall: 0.6458\n",
            "[Train] Class 3: Precision: 0.6400, Recall: 0.8000\n",
            "[Train] Class 4: Precision: 0.4848, Recall: 0.1333\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.26 batch/s]\n",
            "[Val] Kappa: 0.8410 Accuracy: 0.7000 Precision: 0.6357 Recall: 0.7000\n",
            "\n",
            "Epoch 9/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.34 batch/s, lr=1.0e-04, Loss=0.6524]\n",
            "[Train] Kappa: 0.8807 Accuracy: 0.7533 Precision: 0.7426 Recall: 0.7533 Loss: 0.6042\n",
            "[Train] Class 0: Precision: 0.9229, Recall: 0.9639\n",
            "[Train] Class 1: Precision: 0.7650, Recall: 0.7458\n",
            "[Train] Class 2: Precision: 0.6587, Recall: 0.6917\n",
            "[Train] Class 3: Precision: 0.6448, Recall: 0.7792\n",
            "[Train] Class 4: Precision: 0.5208, Recall: 0.2083\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.81 batch/s]\n",
            "[Val] Kappa: 0.8405 Accuracy: 0.7050 Precision: 0.6729 Recall: 0.7050\n",
            "\n",
            "Epoch 10/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.40 batch/s, lr=1.0e-04, Loss=0.6224]\n",
            "[Train] Kappa: 0.9030 Accuracy: 0.7900 Precision: 0.7847 Recall: 0.7900 Loss: 0.5332\n",
            "[Train] Class 0: Precision: 0.9259, Recall: 0.9722\n",
            "[Train] Class 1: Precision: 0.8220, Recall: 0.8083\n",
            "[Train] Class 2: Precision: 0.7154, Recall: 0.7333\n",
            "[Train] Class 3: Precision: 0.6803, Recall: 0.7625\n",
            "[Train] Class 4: Precision: 0.6338, Recall: 0.3750\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.77 batch/s]\n",
            "[Val] Kappa: 0.7986 Accuracy: 0.6800 Precision: 0.6524 Recall: 0.6800\n",
            "\n",
            "Epoch 11/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.23 batch/s, lr=1.0e-05, Loss=0.4836]\n",
            "[Train] Kappa: 0.9156 Accuracy: 0.8142 Precision: 0.8127 Recall: 0.8142 Loss: 0.5070\n",
            "[Train] Class 0: Precision: 0.9363, Recall: 0.9806\n",
            "[Train] Class 1: Precision: 0.8048, Recall: 0.8417\n",
            "[Train] Class 2: Precision: 0.6971, Recall: 0.7000\n",
            "[Train] Class 3: Precision: 0.7597, Recall: 0.8167\n",
            "[Train] Class 4: Precision: 0.7945, Recall: 0.4833\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.88 batch/s]\n",
            "[Val] Kappa: 0.8267 Accuracy: 0.6775 Precision: 0.6575 Recall: 0.6775\n",
            "\n",
            "Epoch 12/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.39 batch/s, lr=1.0e-05, Loss=0.3929]\n",
            "[Train] Kappa: 0.9125 Accuracy: 0.8100 Precision: 0.8060 Recall: 0.8100 Loss: 0.5112\n",
            "[Train] Class 0: Precision: 0.9312, Recall: 0.9778\n",
            "[Train] Class 1: Precision: 0.8253, Recall: 0.7875\n",
            "[Train] Class 2: Precision: 0.7287, Recall: 0.7500\n",
            "[Train] Class 3: Precision: 0.7370, Recall: 0.8292\n",
            "[Train] Class 4: Precision: 0.6842, Recall: 0.4333\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.08 batch/s]\n",
            "[Val] Kappa: 0.8202 Accuracy: 0.6825 Precision: 0.6651 Recall: 0.6825\n",
            "\n",
            "Epoch 13/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.24 batch/s, lr=1.0e-05, Loss=0.3209]\n",
            "[Train] Kappa: 0.9068 Accuracy: 0.7975 Precision: 0.7935 Recall: 0.7975 Loss: 0.5230\n",
            "[Train] Class 0: Precision: 0.9428, Recall: 0.9611\n",
            "[Train] Class 1: Precision: 0.7846, Recall: 0.8042\n",
            "[Train] Class 2: Precision: 0.7238, Recall: 0.7208\n",
            "[Train] Class 3: Precision: 0.7315, Recall: 0.7833\n",
            "[Train] Class 4: Precision: 0.6264, Recall: 0.4750\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.72 batch/s]\n",
            "[Val] Kappa: 0.8228 Accuracy: 0.6775 Precision: 0.6664 Recall: 0.6775\n",
            "\n",
            "Epoch 14/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.40 batch/s, lr=1.0e-05, Loss=0.8328]\n",
            "[Train] Kappa: 0.9172 Accuracy: 0.8200 Precision: 0.8169 Recall: 0.8200 Loss: 0.4926\n",
            "[Train] Class 0: Precision: 0.9351, Recall: 0.9611\n",
            "[Train] Class 1: Precision: 0.8148, Recall: 0.8250\n",
            "[Train] Class 2: Precision: 0.7552, Recall: 0.7583\n",
            "[Train] Class 3: Precision: 0.7638, Recall: 0.8083\n",
            "[Train] Class 4: Precision: 0.6957, Recall: 0.5333\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.51 batch/s]\n",
            "[Val] Kappa: 0.8258 Accuracy: 0.6875 Precision: 0.6690 Recall: 0.6875\n",
            "\n",
            "Epoch 15/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.37 batch/s, lr=1.0e-05, Loss=0.4127]\n",
            "[Train] Kappa: 0.9227 Accuracy: 0.8242 Precision: 0.8196 Recall: 0.8242 Loss: 0.4749\n",
            "[Train] Class 0: Precision: 0.9595, Recall: 0.9861\n",
            "[Train] Class 1: Precision: 0.8361, Recall: 0.8500\n",
            "[Train] Class 2: Precision: 0.7469, Recall: 0.7500\n",
            "[Train] Class 3: Precision: 0.7500, Recall: 0.8000\n",
            "[Train] Class 4: Precision: 0.6517, Recall: 0.4833\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.12 batch/s]\n",
            "[Val] Kappa: 0.8380 Accuracy: 0.6975 Precision: 0.6785 Recall: 0.6975\n",
            "\n",
            "Epoch 16/20\n",
            "Training: 100%|| 75/75 [00:16<00:00,  4.44 batch/s, lr=1.0e-05, Loss=0.3336]\n",
            "[Train] Kappa: 0.9191 Accuracy: 0.8242 Precision: 0.8218 Recall: 0.8242 Loss: 0.4905\n",
            "[Train] Class 0: Precision: 0.9465, Recall: 0.9833\n",
            "[Train] Class 1: Precision: 0.8522, Recall: 0.8167\n",
            "[Train] Class 2: Precision: 0.7143, Recall: 0.7708\n",
            "[Train] Class 3: Precision: 0.7842, Recall: 0.7875\n",
            "[Train] Class 4: Precision: 0.6771, Recall: 0.5417\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.23 batch/s]\n",
            "[Val] Kappa: 0.8292 Accuracy: 0.6850 Precision: 0.6731 Recall: 0.6850\n",
            "\n",
            "Epoch 17/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.38 batch/s, lr=1.0e-05, Loss=1.4219]\n",
            "[Train] Kappa: 0.9053 Accuracy: 0.8117 Precision: 0.8080 Recall: 0.8117 Loss: 0.4998\n",
            "[Train] Class 0: Precision: 0.9387, Recall: 0.9778\n",
            "[Train] Class 1: Precision: 0.8426, Recall: 0.8250\n",
            "[Train] Class 2: Precision: 0.7108, Recall: 0.7375\n",
            "[Train] Class 3: Precision: 0.7412, Recall: 0.7875\n",
            "[Train] Class 4: Precision: 0.6744, Recall: 0.4833\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.40 batch/s]\n",
            "[Val] Kappa: 0.8384 Accuracy: 0.6975 Precision: 0.6788 Recall: 0.6975\n",
            "\n",
            "Epoch 18/20\n",
            "Training: 100%|| 75/75 [00:18<00:00,  4.16 batch/s, lr=1.0e-05, Loss=1.3008]\n",
            "[Train] Kappa: 0.9141 Accuracy: 0.8233 Precision: 0.8196 Recall: 0.8233 Loss: 0.4766\n",
            "[Train] Class 0: Precision: 0.9491, Recall: 0.9833\n",
            "[Train] Class 1: Precision: 0.8458, Recall: 0.8458\n",
            "[Train] Class 2: Precision: 0.7227, Recall: 0.7167\n",
            "[Train] Class 3: Precision: 0.7689, Recall: 0.8042\n",
            "[Train] Class 4: Precision: 0.6735, Recall: 0.5500\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.42 batch/s]\n",
            "[Val] Kappa: 0.8409 Accuracy: 0.7050 Precision: 0.6900 Recall: 0.7050\n",
            "\n",
            "Epoch 19/20\n",
            "Training: 100%|| 75/75 [00:17<00:00,  4.36 batch/s, lr=1.0e-05, Loss=0.4633]\n",
            "[Train] Kappa: 0.9120 Accuracy: 0.8183 Precision: 0.8153 Recall: 0.8183 Loss: 0.4824\n",
            "[Train] Class 0: Precision: 0.9439, Recall: 0.9806\n",
            "[Train] Class 1: Precision: 0.8109, Recall: 0.8042\n",
            "[Train] Class 2: Precision: 0.7202, Recall: 0.7292\n",
            "[Train] Class 3: Precision: 0.7686, Recall: 0.8167\n",
            "[Train] Class 4: Precision: 0.7222, Recall: 0.5417\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.34 batch/s]\n",
            "[Val] Kappa: 0.8355 Accuracy: 0.6925 Precision: 0.6821 Recall: 0.6925\n",
            "\n",
            "Epoch 20/20\n",
            "Training: 100%|| 75/75 [00:18<00:00,  4.13 batch/s, lr=1.0e-05, Loss=0.6206]\n",
            "[Train] Kappa: 0.9301 Accuracy: 0.8342 Precision: 0.8310 Recall: 0.8342 Loss: 0.4690\n",
            "[Train] Class 0: Precision: 0.9593, Recall: 0.9833\n",
            "[Train] Class 1: Precision: 0.8245, Recall: 0.8417\n",
            "[Train] Class 2: Precision: 0.7722, Recall: 0.7625\n",
            "[Train] Class 3: Precision: 0.7674, Recall: 0.8250\n",
            "[Train] Class 4: Precision: 0.7033, Recall: 0.5333\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.17 batch/s]\n",
            "[Val] Kappa: 0.8378 Accuracy: 0.7050 Precision: 0.6911 Recall: 0.7050\n",
            "[Val] Best kappa: 0.8422, Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-b101744f87fd>:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('/content/drive/MyDrive/models/model6.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.77 batch/s]\n",
            "[Test] Save predictions to /content/drive/MyDrive/Predictions/test_predictions6.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs,\n",
        "                checkpoint_path):\n",
        "    best_model = model.state_dict()\n",
        "    best_epoch = None\n",
        "    best_val_kappa = -1.0  # Initialize the best kappa score\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f'\\nEpoch {epoch}/{num_epochs}')\n",
        "        running_loss = []\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        with tqdm(total=len(train_loader), desc=f'Training', unit=' batch', file=sys.stdout) as pbar:\n",
        "            for images, labels in train_loader:\n",
        "                if not isinstance(images, list):\n",
        "                    images = images.to(device)  # single image case\n",
        "                else:\n",
        "                    images = [x.to(device) for x in images]  # dual images case\n",
        "\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels.long())\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                preds = torch.argmax(outputs, 1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                running_loss.append(loss.item())\n",
        "\n",
        "                pbar.set_postfix({'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}', 'Loss': f'{loss.item():.4f}'})\n",
        "                pbar.update(1)\n",
        "\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        epoch_loss = sum(running_loss) / len(running_loss)\n",
        "\n",
        "        train_metrics = compute_metrics(all_preds, all_labels, per_class=True)\n",
        "        kappa, accuracy, precision, recall = train_metrics[:4]\n",
        "\n",
        "        print(f'[Train] Kappa: {kappa:.4f} Accuracy: {accuracy:.4f} '\n",
        "              f'Precision: {precision:.4f} Recall: {recall:.4f} Loss: {epoch_loss:.4f}')\n",
        "\n",
        "        if len(train_metrics) > 4:\n",
        "            precision_per_class, recall_per_class = train_metrics[4:]\n",
        "            for i, (precision, recall) in enumerate(zip(precision_per_class, recall_per_class)):\n",
        "                print(f'[Train] Class {i}: Precision: {precision:.4f}, Recall: {recall:.4f}')\n",
        "\n",
        "        # Evaluation on the validation set at the end of each epoch\n",
        "        val_metrics = evaluate_model(model, val_loader, device)\n",
        "        val_kappa, val_accuracy, val_precision, val_recall = val_metrics[:4]\n",
        "        print(f'[Val] Kappa: {val_kappa:.4f} Accuracy: {val_accuracy:.4f} '\n",
        "              f'Precision: {val_precision:.4f} Recall: {val_recall:.4f}')\n",
        "\n",
        "        if val_kappa > best_val_kappa:\n",
        "            best_val_kappa = val_kappa\n",
        "            best_epoch = epoch\n",
        "            best_model = model.state_dict()\n",
        "            torch.save(best_model, checkpoint_path)\n",
        "\n",
        "    print(f'[Val] Best kappa: {best_val_kappa:.4f}, Epoch {best_epoch}')\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "43_IzvThcUWk"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: replace and Implement  channel attention mechanism in the above pretrained  resnet18 model architecture\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "\n",
        "        self.fc1   = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2   = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
        "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        self.backbone = models.resnet18(pretrained=True)\n",
        "        state_dict = torch.load('pretrained_DR_resize/pretrained/resnet18.pth', map_location='cpu')\n",
        "        info = self.backbone.load_state_dict(state_dict, strict=False)\n",
        "        print('missing keys:', info[0])  # The missing fc or classifier layer is normal here\n",
        "        print('unexpected keys:', info[1])\n",
        "\n",
        "        self.backbone.fc = nn.Identity() # Remove original FC layer\n",
        "\n",
        "        self.ca = ChannelAttention(512) #Apply channel attention to the output of ResNet18\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = x.unsqueeze(-1).unsqueeze(-1)\n",
        "        x = self.ca(x) * x  # Apply channel attention\n",
        "        x = torch.mean(x, dim=(2, 3)) # Global Average Pooling\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2l3Ly1YAdkCD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Choose between 'single image' and 'dual images' pipeline\n",
        "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
        "\n",
        "    mode = 'single'  # forward single image to the model each time\n",
        "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
        "\n",
        "    assert mode in ('single', 'dual')\n",
        "\n",
        "    # Define the model\n",
        "    if mode == 'single':\n",
        "        model = MyModel()\n",
        "    else:\n",
        "        model = MyDualModel()\n",
        "\n",
        "    print(model, '\\n')\n",
        "    print('Pipeline Mode:', mode)\n",
        "\n",
        "    # tuned Hyper Parameters\n",
        "    batch_size = 20\n",
        "    num_classes = 5  # 5 DR levels\n",
        "    learning_rate = 0.0001\n",
        "    num_epochs = 15\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = RetinopathyDataset('/content/DeepDRiD/train.csv', '/content/DeepDRiD/train', transform_train, mode)\n",
        "    val_dataset = RetinopathyDataset('/content/DeepDRiD/val.csv', '/content/DeepDRiD/val/', transform_test, mode)\n",
        "    test_dataset = RetinopathyDataset('/content/DeepDRiD/test.csv', '/content/DeepDRiD/test', transform_test, mode, test=True)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop((224, 224)),\n",
        "    SLORandomPad((224, 224)),\n",
        "    FundRandomRotate(prob=0.5, degree=30),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Define the weighted CrossEntropyLoss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Use GPU device is possible\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print('Device:', device)\n",
        "\n",
        "    # Move class weights to the device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Optimizer and Learning rate scheduler\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "     # Train and evaluate the model with the training and validation set\n",
        "    model = train_model(\n",
        "        model, train_loader, val_loader, device, criterion, optimizer,\n",
        "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
        "        checkpoint_path='/content/drive/MyDrive/models/model7.pth'\n",
        "    )\n",
        "\n",
        "    # Load the pretrained checkpoint\n",
        "    state_dict = torch.load('/content/drive/MyDrive/models/model7.pth', map_location='cpu')\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Make predictions on testing set and save the prediction results\n",
        "    evaluate_model(model, test_loader, device, test_only=True, prediction_path='/content/drive/MyDrive/Predictions/test_predictions7.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cyhGjRKcH3l",
        "outputId": "da3e4062-bb83-4465-c2a1-990523d83ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-64-a69c3e767b96>:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('pretrained_DR_resize/pretrained/resnet18.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing keys: ['fc.weight', 'fc.bias']\n",
            "unexpected keys: []\n",
            "MyModel(\n",
            "  (backbone): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (ca): ChannelAttention(\n",
            "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "    (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
            "    (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (relu1): ReLU()\n",
            "    (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
            "  )\n",
            ") \n",
            "\n",
            "Pipeline Mode: single\n",
            "Device: cuda\n",
            "\n",
            "Epoch 1/15\n",
            "Training: 100%|| 60/60 [00:13<00:00,  4.49 batch/s, lr=1.0e-04, Loss=1.2367]\n",
            "[Train] Kappa: 0.5254 Accuracy: 0.4250 Precision: 0.4987 Recall: 0.4250 Loss: 1.3880\n",
            "[Train] Class 0: Precision: 0.5484, Recall: 0.8806\n",
            "[Train] Class 1: Precision: 0.6333, Recall: 0.0792\n",
            "[Train] Class 2: Precision: 0.2584, Recall: 0.5750\n",
            "[Train] Class 3: Precision: 0.7292, Recall: 0.1458\n",
            "[Train] Class 4: Precision: 0.1000, Recall: 0.0083\n",
            "Evaluating: 100%|| 20/20 [00:02<00:00,  6.74 batch/s]\n",
            "[Val] Kappa: 0.3362 Accuracy: 0.3525 Precision: 0.2827 Recall: 0.3525\n",
            "\n",
            "Epoch 2/15\n",
            "Training: 100%|| 60/60 [00:13<00:00,  4.61 batch/s, lr=1.0e-04, Loss=1.1187]\n",
            "[Train] Kappa: 0.7373 Accuracy: 0.5900 Precision: 0.5224 Recall: 0.5900 Loss: 1.1208\n",
            "[Train] Class 0: Precision: 0.7248, Recall: 0.9583\n",
            "[Train] Class 1: Precision: 0.5886, Recall: 0.4292\n",
            "[Train] Class 2: Precision: 0.3922, Recall: 0.4167\n",
            "[Train] Class 3: Precision: 0.5442, Recall: 0.6667\n",
            "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
            "Evaluating: 100%|| 20/20 [00:03<00:00,  5.79 batch/s]\n",
            "[Val] Kappa: 0.8395 Accuracy: 0.6575 Precision: 0.5965 Recall: 0.6575\n",
            "\n",
            "Epoch 3/15\n",
            "Training: 100%|| 60/60 [00:13<00:00,  4.60 batch/s, lr=1.0e-04, Loss=0.7146]\n",
            "[Train] Kappa: 0.7939 Accuracy: 0.6433 Precision: 0.6241 Recall: 0.6433 Loss: 0.9640\n",
            "[Train] Class 0: Precision: 0.8375, Recall: 0.9306\n",
            "[Train] Class 1: Precision: 0.6192, Recall: 0.6708\n",
            "[Train] Class 2: Precision: 0.4650, Recall: 0.3042\n",
            "[Train] Class 3: Precision: 0.5302, Recall: 0.8417\n",
            "[Train] Class 4: Precision: 0.5000, Recall: 0.0083\n",
            "Evaluating: 100%|| 20/20 [00:02<00:00,  7.42 batch/s]\n",
            "[Val] Kappa: 0.8112 Accuracy: 0.6475 Precision: 0.5777 Recall: 0.6475\n",
            "\n",
            "Epoch 4/15\n",
            "Training: 100%|| 60/60 [00:13<00:00,  4.54 batch/s, lr=1.0e-04, Loss=0.7770]\n",
            "[Train] Kappa: 0.8093 Accuracy: 0.6467 Precision: 0.6279 Recall: 0.6467 Loss: 0.9209\n",
            "[Train] Class 0: Precision: 0.8329, Recall: 0.9417\n",
            "[Train] Class 1: Precision: 0.6307, Recall: 0.6333\n",
            "[Train] Class 2: Precision: 0.4660, Recall: 0.3708\n",
            "[Train] Class 3: Precision: 0.5434, Recall: 0.8083\n",
            "[Train] Class 4: Precision: 0.5000, Recall: 0.0167\n",
            "Evaluating: 100%|| 20/20 [00:02<00:00,  7.96 batch/s]\n",
            "[Val] Kappa: 0.8089 Accuracy: 0.6650 Precision: 0.5878 Recall: 0.6650\n",
            "\n",
            "Epoch 5/15\n",
            "Training: 100%|| 60/60 [00:13<00:00,  4.57 batch/s, lr=1.0e-04, Loss=0.7062]\n",
            "[Train] Kappa: 0.8172 Accuracy: 0.6492 Precision: 0.6190 Recall: 0.6492 Loss: 0.8902\n",
            "[Train] Class 0: Precision: 0.8276, Recall: 0.9333\n",
            "[Train] Class 1: Precision: 0.6426, Recall: 0.6292\n",
            "[Train] Class 2: Precision: 0.4734, Recall: 0.4083\n",
            "[Train] Class 3: Precision: 0.5592, Recall: 0.7875\n",
            "[Train] Class 4: Precision: 0.3571, Recall: 0.0417\n",
            "Evaluating: 100%|| 20/20 [00:02<00:00,  8.09 batch/s]\n",
            "[Val] Kappa: 0.7941 Accuracy: 0.6525 Precision: 0.5882 Recall: 0.6525\n",
            "\n",
            "Epoch 6/15\n",
            "Training: 100%|| 60/60 [00:13<00:00,  4.60 batch/s, lr=1.0e-04, Loss=0.8674]\n",
            "[Train] Kappa: 0.8136 Accuracy: 0.6775 Precision: 0.6472 Recall: 0.6775 Loss: 0.8290\n",
            "[Train] Class 0: Precision: 0.8547, Recall: 0.9639\n",
            "[Train] Class 1: Precision: 0.6820, Recall: 0.6792\n",
            "[Train] Class 2: Precision: 0.5377, Recall: 0.4750\n",
            "[Train] Class 3: Precision: 0.5674, Recall: 0.7542\n",
            "[Train] Class 4: Precision: 0.3333, Recall: 0.0667\n",
            "Evaluating: 100%|| 20/20 [00:02<00:00,  7.95 batch/s]\n",
            "[Val] Kappa: 0.7901 Accuracy: 0.6700 Precision: 0.6924 Recall: 0.6700\n",
            "\n",
            "Epoch 7/15\n",
            "Training: 100%|| 60/60 [00:12<00:00,  4.67 batch/s, lr=1.0e-04, Loss=0.6756]\n",
            "[Train] Kappa: 0.8299 Accuracy: 0.6808 Precision: 0.6651 Recall: 0.6808 Loss: 0.8108\n",
            "[Train] Class 0: Precision: 0.8692, Recall: 0.9417\n",
            "[Train] Class 1: Precision: 0.7207, Recall: 0.6667\n",
            "[Train] Class 2: Precision: 0.5339, Recall: 0.5250\n",
            "[Train] Class 3: Precision: 0.5645, Recall: 0.7292\n",
            "[Train] Class 4: Precision: 0.4048, Recall: 0.1417\n",
            "Evaluating: 100%|| 20/20 [00:02<00:00,  8.09 batch/s]\n",
            "[Val] Kappa: 0.8147 Accuracy: 0.6750 Precision: 0.6555 Recall: 0.6750\n",
            "\n",
            "Epoch 8/15\n",
            "Training: 100%|| 60/60 [00:13<00:00,  4.55 batch/s, lr=1.0e-04, Loss=0.5681]\n",
            "[Train] Kappa: 0.8358 Accuracy: 0.6942 Precision: 0.6807 Recall: 0.6942 Loss: 0.7963\n",
            "[Train] Class 0: Precision: 0.8653, Recall: 0.9639\n",
            "[Train] Class 1: Precision: 0.7441, Recall: 0.6542\n",
            "[Train] Class 2: Precision: 0.5311, Recall: 0.5333\n",
            "[Train] Class 3: Precision: 0.5886, Recall: 0.7750\n",
            "[Train] Class 4: Precision: 0.4839, Recall: 0.1250\n",
            "Evaluating: 100%|| 20/20 [00:02<00:00,  7.92 batch/s]\n",
            "[Val] Kappa: 0.8389 Accuracy: 0.6950 Precision: 0.6621 Recall: 0.6950\n",
            "\n",
            "Epoch 9/15\n",
            "Training: 100%|| 60/60 [00:13<00:00,  4.55 batch/s, lr=1.0e-04, Loss=0.7583]\n",
            "[Train] Kappa: 0.8189 Accuracy: 0.6825 Precision: 0.6720 Recall: 0.6825 Loss: 0.8194\n",
            "[Train] Class 0: Precision: 0.8715, Recall: 0.9417\n",
            "[Train] Class 1: Precision: 0.6886, Recall: 0.6542\n",
            "[Train] Class 2: Precision: 0.4979, Recall: 0.4875\n",
            "[Train] Class 3: Precision: 0.6084, Recall: 0.7250\n",
            "[Train] Class 4: Precision: 0.5161, Recall: 0.2667\n",
            "Evaluating: 100%|| 20/20 [00:03<00:00,  6.28 batch/s]\n",
            "[Val] Kappa: 0.8377 Accuracy: 0.6750 Precision: 0.6406 Recall: 0.6750\n",
            "\n",
            "Epoch 10/15\n",
            "Training: 100%|| 60/60 [00:12<00:00,  4.75 batch/s, lr=1.0e-04, Loss=1.0998]\n",
            "[Train] Kappa: 0.8498 Accuracy: 0.7125 Precision: 0.7013 Recall: 0.7125 Loss: 0.7749\n",
            "[Train] Class 0: Precision: 0.8738, Recall: 0.9806\n",
            "[Train] Class 1: Precision: 0.7500, Recall: 0.6875\n",
            "[Train] Class 2: Precision: 0.5561, Recall: 0.5167\n",
            "[Train] Class 3: Precision: 0.6120, Recall: 0.7625\n",
            "[Train] Class 4: Precision: 0.5556, Recall: 0.2500\n",
            "Evaluating: 100%|| 20/20 [00:03<00:00,  5.92 batch/s]\n",
            "[Val] Kappa: 0.8143 Accuracy: 0.6725 Precision: 0.6483 Recall: 0.6725\n",
            "\n",
            "Epoch 11/15\n",
            "Training: 100%|| 60/60 [00:13<00:00,  4.56 batch/s, lr=1.0e-05, Loss=0.8109]\n",
            "[Train] Kappa: 0.8500 Accuracy: 0.6992 Precision: 0.6945 Recall: 0.6992 Loss: 0.7544\n",
            "[Train] Class 0: Precision: 0.8744, Recall: 0.9472\n",
            "[Train] Class 1: Precision: 0.7606, Recall: 0.6750\n",
            "[Train] Class 2: Precision: 0.5571, Recall: 0.5083\n",
            "[Train] Class 3: Precision: 0.5688, Recall: 0.7750\n",
            "[Train] Class 4: Precision: 0.5490, Recall: 0.2333\n",
            "Evaluating: 100%|| 20/20 [00:02<00:00,  7.57 batch/s]\n",
            "[Val] Kappa: 0.8488 Accuracy: 0.6975 Precision: 0.6674 Recall: 0.6975\n",
            "\n",
            "Epoch 12/15\n",
            "Training: 100%|| 60/60 [00:13<00:00,  4.51 batch/s, lr=1.0e-05, Loss=0.6727]\n",
            "[Train] Kappa: 0.8702 Accuracy: 0.7200 Precision: 0.7129 Recall: 0.7200 Loss: 0.7461\n",
            "[Train] Class 0: Precision: 0.8841, Recall: 0.9750\n",
            "[Train] Class 1: Precision: 0.7544, Recall: 0.7167\n",
            "[Train] Class 2: Precision: 0.5519, Recall: 0.4875\n",
            "[Train] Class 3: Precision: 0.6126, Recall: 0.7708\n",
            "[Train] Class 4: Precision: 0.6393, Recall: 0.3250\n",
            "Evaluating: 100%|| 20/20 [00:02<00:00,  8.18 batch/s]\n",
            "[Val] Kappa: 0.8369 Accuracy: 0.6975 Precision: 0.6724 Recall: 0.6975\n",
            "\n",
            "Epoch 13/15\n",
            "Training: 100%|| 60/60 [00:13<00:00,  4.53 batch/s, lr=1.0e-05, Loss=0.3964]\n",
            "[Train] Kappa: 0.8604 Accuracy: 0.6992 Precision: 0.6898 Recall: 0.6992 Loss: 0.7501\n",
            "[Train] Class 0: Precision: 0.8835, Recall: 0.9694\n",
            "[Train] Class 1: Precision: 0.7105, Recall: 0.6750\n",
            "[Train] Class 2: Precision: 0.5279, Recall: 0.5125\n",
            "[Train] Class 3: Precision: 0.6021, Recall: 0.7125\n",
            "[Train] Class 4: Precision: 0.5667, Recall: 0.2833\n",
            "Evaluating: 100%|| 20/20 [00:02<00:00,  8.21 batch/s]\n",
            "[Val] Kappa: 0.8265 Accuracy: 0.6775 Precision: 0.6464 Recall: 0.6775\n",
            "\n",
            "Epoch 14/15\n",
            "Training: 100%|| 60/60 [00:13<00:00,  4.55 batch/s, lr=1.0e-05, Loss=0.3978]\n",
            "[Train] Kappa: 0.8555 Accuracy: 0.7133 Precision: 0.7053 Recall: 0.7133 Loss: 0.7428\n",
            "[Train] Class 0: Precision: 0.8807, Recall: 0.9639\n",
            "[Train] Class 1: Precision: 0.7362, Recall: 0.7208\n",
            "[Train] Class 2: Precision: 0.5463, Recall: 0.4667\n",
            "[Train] Class 3: Precision: 0.6091, Recall: 0.7792\n",
            "[Train] Class 4: Precision: 0.6271, Recall: 0.3083\n",
            "Evaluating: 100%|| 20/20 [00:02<00:00,  8.13 batch/s]\n",
            "[Val] Kappa: 0.8269 Accuracy: 0.6875 Precision: 0.6585 Recall: 0.6875\n",
            "\n",
            "Epoch 15/15\n",
            "Training: 100%|| 60/60 [00:13<00:00,  4.58 batch/s, lr=1.0e-05, Loss=0.9894]\n",
            "[Train] Kappa: 0.8583 Accuracy: 0.7142 Precision: 0.7059 Recall: 0.7142 Loss: 0.7479\n",
            "[Train] Class 0: Precision: 0.8869, Recall: 0.9583\n",
            "[Train] Class 1: Precision: 0.7106, Recall: 0.6958\n",
            "[Train] Class 2: Precision: 0.5622, Recall: 0.5083\n",
            "[Train] Class 3: Precision: 0.6246, Recall: 0.7833\n",
            "[Train] Class 4: Precision: 0.6034, Recall: 0.2917\n",
            "Evaluating: 100%|| 20/20 [00:02<00:00,  7.92 batch/s]\n",
            "[Val] Kappa: 0.8442 Accuracy: 0.6950 Precision: 0.6712 Recall: 0.6950\n",
            "[Val] Best kappa: 0.8488, Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-a8ead97ef4a4>:75: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('/content/drive/MyDrive/models/model7.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating: 100%|| 20/20 [00:03<00:00,  6.39 batch/s]\n",
            "[Test] Save predictions to /content/drive/MyDrive/Predictions/test_predictions7.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task D"
      ],
      "metadata": {
        "id": "3F37IZDyn49z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: I have done model training with transfer learning with resnet18, resnet34 and EfficientNet. Which are now saved as model3.pth, model4.pth, model5.pth. Now perform ensemble learning. Try out the following ensemble techniques (Stacking, Boosting, Weighted Average, Max Voting, Bagging) and analyze whether the performance increases or not.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Load the trained models\n",
        "#with taskb's resnet18\n",
        "model3 = MyModel_resnet18().to(device)  # Assuming MyModel is defined as in your code\n",
        "model3.load_state_dict(torch.load('/content/drive/MyDrive/models/model3.pth', map_location=device))\n",
        "model3.eval()\n",
        "\n",
        "#with taskb's resnet34\n",
        "model4 = MyModel_resnet34().to(device)\n",
        "model4.load_state_dict(torch.load('/content/drive/MyDrive/models/model4.pth', map_location=device))\n",
        "model4.eval()\n",
        "\n",
        "#with taskb's EfficientNet\n",
        "model5 = MyModel_efficientnet().to(device)\n",
        "model5.load_state_dict(torch.load('/content/drive/MyDrive/models/model5.pth', map_location=device))\n",
        "model5.eval()\n",
        "\n",
        "def ensemble_predictions(models, images):\n",
        "    \"\"\"\n",
        "    Generate ensemble predictions from a list of models.\n",
        "\n",
        "    Args:\n",
        "        models (list): List of trained PyTorch models.\n",
        "        images (torch.Tensor): Batch of input images.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Array of ensemble predictions.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for model in models:\n",
        "            outputs = model(images)\n",
        "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "            predictions.append(preds)\n",
        "    return np.array(predictions)\n",
        "\n",
        "\n",
        "def evaluate_ensemble(ensemble_preds, true_labels):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of ensemble predictions.\n",
        "\n",
        "    Args:\n",
        "        ensemble_preds (list): List of lists, where each inner list contains predictions from different models.\n",
        "        true_labels (list): True labels for the validation set.\n",
        "\n",
        "    \"\"\"\n",
        "    # Concatenate all predictions and true labels into single arrays\n",
        "    all_ensemble_preds = np.concatenate(ensemble_preds, axis=1) # Concatenate the prediction\n",
        "    all_true_labels = np.concatenate(true_labels) # concatenate the true labels\n",
        "\n",
        "    # 1. Weighted Average\n",
        "    weighted_average_pred = np.round(np.mean(all_ensemble_preds, axis=0)).astype(int)\n",
        "    kappa_weighted_avg = cohen_kappa_score(all_true_labels, weighted_average_pred, weights='quadratic')\n",
        "    print(f\"Weighted Average Kappa: {kappa_weighted_avg:.4f}\")\n",
        "\n",
        "    # 2. Max Voting\n",
        "    max_voting_preds = np.apply_along_axis(lambda x: np.bincount(x, minlength=5).argmax(), axis=0, arr=all_ensemble_preds)\n",
        "    kappa_max_voting = cohen_kappa_score(all_true_labels, max_voting_preds, weights='quadratic')\n",
        "    print(f\"Max Voting Kappa: {kappa_max_voting:.4f}\")\n",
        "\n",
        "    # 3. Stacking (Simplified as averaging predictions)\n",
        "    stacked_preds = np.round(np.mean(all_ensemble_preds, axis=0)).astype(int)\n",
        "    kappa_stacking = cohen_kappa_score(all_true_labels, stacked_preds, weights='quadratic')\n",
        "    print(f\"Stacking Kappa: {kappa_stacking:.4f}\")\n",
        "\n",
        "    # 4. Bagging (Simplified as averaging predictions)\n",
        "    bagging_preds = np.round(np.mean(all_ensemble_preds, axis=0)).astype(int)\n",
        "    kappa_bagging = cohen_kappa_score(all_true_labels, bagging_preds, weights='quadratic')\n",
        "    print(f\"Bagging Kappa: {kappa_bagging:.4f}\")\n",
        "\n",
        "\n",
        "# Now let's evaluate on the validation set:\n",
        "if __name__ == \"__main__\":\n",
        "    # ... (Rest of your code, such as model and dataloader definitions)\n",
        "\n",
        "    mode = 'single'  # Ensure mode is defined\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = RetinopathyDataset('/content/DeepDRiD/train.csv', '/content/DeepDRiD/train', transform_train, mode)\n",
        "    val_dataset = RetinopathyDataset('/content/DeepDRiD/val.csv', '/content/DeepDRiD/val/', transform_test, mode)\n",
        "    test_dataset = RetinopathyDataset('/content/DeepDRiD/test.csv', '/content/DeepDRiD/test', transform_test, mode, test=True)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "    # Gather predictions and true labels from the validation set\n",
        "    all_true_labels = []\n",
        "    all_ensemble_preds = []\n",
        "\n",
        "    # Corrected evaluation loop using the validation loader\n",
        "    with torch.no_grad():\n",
        "      for images, labels in val_loader:  # Use the validation loader\n",
        "          images = images.to(device)\n",
        "          labels = labels.cpu().numpy()\n",
        "\n",
        "          # Perform ensemble prediction\n",
        "          ensemble_preds = ensemble_predictions([model3, model4, model5], images)\n",
        "          all_ensemble_preds.append(ensemble_preds)\n",
        "          all_true_labels.append(labels)\n",
        "\n",
        "    evaluate_ensemble(all_ensemble_preds, all_true_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDjXArIkn7oD",
        "outputId": "6ea95cb8-856a-41da-92ee-1c6413832c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-72-77729cf7f76f>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('pretrained_DR_resize/pretrained/resnet18.pth', map_location='cpu')\n",
            "<ipython-input-76-2effce168267>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model3.load_state_dict(torch.load('/content/drive/MyDrive/models/model3.pth', map_location=device))\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing keys: ['fc.weight', 'fc.bias']\n",
            "unexpected keys: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-71-937141b994ba>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('pretrained_DR_resize/pretrained/resnet34.pth', map_location='cpu')\n",
            "<ipython-input-76-2effce168267>:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model4.load_state_dict(torch.load('/content/drive/MyDrive/models/model4.pth', map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing keys: ['fc.weight', 'fc.bias']\n",
            "unexpected keys: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-73-16c542f796c9>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('pretrained_DR_resize/pretrained/efficientnet_b0.pth', map_location='cpu')\n",
            "<ipython-input-76-2effce168267>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model5.load_state_dict(torch.load('/content/drive/MyDrive/models/model5.pth', map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing keys: ['classifier.1.weight', 'classifier.1.bias']\n",
            "unexpected keys: []\n",
            "Weighted Average Kappa: 0.8638\n",
            "Max Voting Kappa: 0.8467\n",
            "Stacking Kappa: 0.8638\n",
            "Bagging Kappa: 0.8638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task D 2"
      ],
      "metadata": {
        "id": "wkfF2z3qQBjH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yT6SOmnq2ap9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Now Try out different image preprocessing techniques such as, Ben Graham, Circle Cropping, CLAHE, adding gaussian blur, sharpening up the images etc.  Then see again if that has any effect on the model.\n",
        "\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import torchvision.transforms.functional as TF\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# ... (Your existing code)\n",
        "\n",
        "def ben_graham_preprocessing(image):\n",
        "    # Convert to grayscale\n",
        "    gray = image.convert('L')\n",
        "\n",
        "    # Increase contrast (adjust factor as needed)\n",
        "    enhancer = ImageEnhance.Contrast(gray)\n",
        "    gray = enhancer.enhance(1.5)\n",
        "\n",
        "    return gray\n",
        "\n",
        "def circle_crop(image):\n",
        "    # Convert the image to a NumPy array\n",
        "    img_np = np.array(image)\n",
        "\n",
        "    # Get the dimensions of the image\n",
        "    height, width = img_np.shape[:2]\n",
        "\n",
        "    # Create a black mask of the same size as the image\n",
        "    mask = np.zeros((height, width), np.uint8)\n",
        "\n",
        "    # Draw a white circle in the center of the mask\n",
        "    center_x = width // 2\n",
        "    center_y = height // 2\n",
        "    radius = min(center_x, center_y)\n",
        "    cv2.circle(mask, (center_x, center_y), radius, (255, 255, 255), -1)\n",
        "\n",
        "    # Apply the mask to the image\n",
        "    masked_img = cv2.bitwise_and(img_np, img_np, mask=mask)\n",
        "\n",
        "    # Convert the masked image back to PIL format\n",
        "    masked_image = Image.fromarray(masked_img)\n",
        "\n",
        "    return masked_image\n",
        "\n",
        "def clahe_preprocessing(image):\n",
        "    # Convert PIL Image to OpenCV format\n",
        "    # img_np = np.array(image)\n",
        "    # lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)  # Convert to LAB color space\n",
        "\n",
        "    # # Apply CLAHE\n",
        "    # lab_planes = cv2.split(lab)\n",
        "    # clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    # lab_planes[0] = clahe.apply(lab_planes[0])\n",
        "    # lab = cv2.merge(lab_planes)\n",
        "\n",
        "    # # Convert back to RGB\n",
        "    # img_rgb = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
        "    # # Convert back to PIL Image\n",
        "    # img = Image.fromarray(img_rgb)\n",
        "    # return img\n",
        "    image_np = np.array(image)\n",
        "    lab = cv2.cvtColor(image_np, cv2.COLOR_RGB2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    l = clahe.apply(l)\n",
        "    lab = cv2.merge((l, a, b))\n",
        "    image_np = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "    return Image.fromarray(image_np)\n",
        "\n",
        "\n",
        "\n",
        "def gaussian_blur_preprocessing(image):\n",
        "  # Apply Gaussian Blur\n",
        "  blurred_image = image.filter(ImageFilter.GaussianBlur(radius=1))\n",
        "  return blurred_image\n",
        "\n",
        "\n",
        "def sharpen_image(image):\n",
        "    # Create a sharpening kernel\n",
        "    kernel = np.array([[-1, -1, -1],\n",
        "                       [-1,  9, -1],\n",
        "                       [-1, -1, -1]])\n",
        "    # Apply the kernel to the image\n",
        "    img_np = np.array(image)\n",
        "    sharpened_img = cv2.filter2D(img_np, -1, kernel)\n",
        "\n",
        "    sharpened_image = Image.fromarray(sharpened_img)\n",
        "    return sharpened_image\n",
        "\n",
        "\n",
        "    # Example usage within your transform\n",
        "transform_train = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.RandomCrop((224, 224)),\n",
        "        SLORandomPad((224, 224)),\n",
        "        FundRandomRotate(prob=0.5, degree=30),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
        "        #transforms.Lambda(lambda img: ben_graham_preprocessing(img)), # Ben Graham\n",
        "        #transforms.Lambda(lambda img: circle_crop(img)), # Circle Cropping\n",
        "        transforms.Lambda(lambda img: clahe_preprocessing(img)), # CLAHE\n",
        "        #transforms.Lambda(lambda img: gaussian_blur_preprocessing(img)), #Gaussian Blur\n",
        "        #transforms.Lambda(lambda img: sharpen_image(img)), #Sharpening\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        #transforms.Lambda(lambda img: ben_graham_preprocessing(img)), # Ben Graham\n",
        "        #transforms.Lambda(lambda img: circle_crop(img)), # Circle Cropping\n",
        "        transforms.Lambda(lambda img: clahe_preprocessing(img)), # CLAHE\n",
        "        #transforms.Lambda(lambda img: gaussian_blur_preprocessing(img)), #Gaussian Blur\n",
        "        #transforms.Lambda(lambda img: sharpen_image(img)), #Sharpening\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "# ... (rest of your code)"
      ],
      "metadata": {
        "id": "3J7emdD4pJV_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel_resnet18(nn.Module):\n",
        "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = models.resnet18(pretrained=True)\n",
        "        state_dict = torch.load('pretrained_DR_resize/pretrained/resnet18.pth', map_location='cpu')\n",
        "        info = self.backbone.load_state_dict(state_dict, strict=False)\n",
        "        print('missing keys:', info[0])  # The missing fc or classifier layer is normal here\n",
        "        print('unexpected keys:', info[1])\n",
        "\n",
        "        # self.backbone = models.resnet34(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained/resnet34.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.vgg16(pretrained=True)\n",
        "        # self.backbone.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # state_dict = torch.load('pretrained/vgg16.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.efficientnet_b0(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained/efficientnet_b0.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.densenet121(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained/densenet121.pth', map_location='cpu')\n",
        "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GiCDnIA5QF7f"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Choose between 'single image' and 'dual images' pipeline\n",
        "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
        "\n",
        "    mode = 'single'  # forward single image to the model each time\n",
        "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
        "\n",
        "    assert mode in ('single', 'dual')\n",
        "\n",
        "    # Define the model\n",
        "    if mode == 'single':\n",
        "        model = MyModel_resnet18()\n",
        "    else:\n",
        "        model = MyDualModel()\n",
        "\n",
        "    print(model, '\\n')\n",
        "    print('Pipeline Mode:', mode)\n",
        "\n",
        "    # tuned Hyper Parameters\n",
        "    batch_size = 16\n",
        "    num_classes = 5  # 5 DR levels\n",
        "    learning_rate = 0.0001\n",
        "    num_epochs = 20\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = RetinopathyDataset('/content/DeepDRiD/train.csv', '/content/DeepDRiD/train', transform_train, mode)\n",
        "    val_dataset = RetinopathyDataset('/content/DeepDRiD/val.csv', '/content/DeepDRiD/val/', transform_test, mode)\n",
        "    test_dataset = RetinopathyDataset('/content/DeepDRiD/test.csv', '/content/DeepDRiD/test', transform_test, mode, test=True)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "    # Define the weighted CrossEntropyLoss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Use GPU device is possible\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print('Device:', device)\n",
        "\n",
        "    # Move class weights to the device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Optimizer and Learning rate scheduler\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "     # Train and evaluate the model with the training and validation set\n",
        "    model = train_model(\n",
        "        model, train_loader, val_loader, device, criterion, optimizer,\n",
        "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
        "        checkpoint_path='/content/drive/MyDrive/models/model8.pth'\n",
        "    )\n",
        "\n",
        "    # Load the pretrained checkpoint\n",
        "    state_dict = torch.load('/content/drive/MyDrive/models/model8.pth', map_location='cpu')\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Make predictions on testing set and save the prediction results\n",
        "    evaluate_model(model, test_loader, device, test_only=True, prediction_path='/content/drive/MyDrive/Predictions/test_predictions8.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY3TQlDRQXrE",
        "outputId": "b5f62a01-0611-42c1-f050-73941e103938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-22-77729cf7f76f>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('pretrained_DR_resize/pretrained/resnet18.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing keys: ['fc.weight', 'fc.bias']\n",
            "unexpected keys: []\n",
            "MyModel_resnet18(\n",
            "  (backbone): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
            "  )\n",
            ") \n",
            "\n",
            "Pipeline Mode: single\n",
            "Device: cpu\n",
            "\n",
            "Epoch 1/20\n",
            "Training: 100%|| 75/75 [06:12<00:00,  4.97s/ batch, lr=1.0e-04, Loss=1.2585]\n",
            "[Train] Kappa: 0.2923 Accuracy: 0.3633 Precision: 0.3370 Recall: 0.3633 Loss: 1.4099\n",
            "[Train] Class 0: Precision: 0.4047, Recall: 0.8139\n",
            "[Train] Class 1: Precision: 0.3047, Recall: 0.1625\n",
            "[Train] Class 2: Precision: 0.2390, Recall: 0.2708\n",
            "[Train] Class 3: Precision: 0.5342, Recall: 0.1625\n",
            "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
            "Evaluating: 100%|| 25/25 [00:39<00:00,  1.59s/ batch]\n",
            "[Val] Kappa: 0.6416 Accuracy: 0.6025 Precision: 0.5346 Recall: 0.6025\n",
            "\n",
            "Epoch 2/20\n",
            "Training: 100%|| 75/75 [06:08<00:00,  4.92s/ batch, lr=1.0e-04, Loss=1.1069]\n",
            "[Train] Kappa: 0.6627 Accuracy: 0.5575 Precision: 0.4835 Recall: 0.5575 Loss: 1.1798\n",
            "[Train] Class 0: Precision: 0.6899, Recall: 0.9083\n",
            "[Train] Class 1: Precision: 0.5164, Recall: 0.5250\n",
            "[Train] Class 2: Precision: 0.3452, Recall: 0.2833\n",
            "[Train] Class 3: Precision: 0.5211, Recall: 0.6167\n",
            "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
            "Evaluating: 100%|| 25/25 [00:40<00:00,  1.61s/ batch]\n",
            "[Val] Kappa: 0.8404 Accuracy: 0.6625 Precision: 0.6128 Recall: 0.6625\n",
            "\n",
            "Epoch 3/20\n",
            "Training: 100%|| 75/75 [06:08<00:00,  4.91s/ batch, lr=1.0e-04, Loss=1.1963]\n",
            "[Train] Kappa: 0.7284 Accuracy: 0.6108 Precision: 0.5761 Recall: 0.6108 Loss: 1.0318\n",
            "[Train] Class 0: Precision: 0.7927, Recall: 0.9028\n",
            "[Train] Class 1: Precision: 0.5575, Recall: 0.6667\n",
            "[Train] Class 2: Precision: 0.4540, Recall: 0.3083\n",
            "[Train] Class 3: Precision: 0.5134, Recall: 0.7208\n",
            "[Train] Class 4: Precision: 0.3333, Recall: 0.0083\n",
            "Evaluating: 100%|| 25/25 [00:41<00:00,  1.68s/ batch]\n",
            "[Val] Kappa: 0.8275 Accuracy: 0.6675 Precision: 0.5929 Recall: 0.6675\n",
            "\n",
            "Epoch 4/20\n",
            "Training: 100%|| 75/75 [06:08<00:00,  4.92s/ batch, lr=1.0e-04, Loss=1.0004]\n",
            "[Train] Kappa: 0.7751 Accuracy: 0.6200 Precision: 0.5889 Recall: 0.6200 Loss: 0.9820\n",
            "[Train] Class 0: Precision: 0.8029, Recall: 0.9278\n",
            "[Train] Class 1: Precision: 0.6104, Recall: 0.5875\n",
            "[Train] Class 2: Precision: 0.4486, Recall: 0.3458\n",
            "[Train] Class 3: Precision: 0.5143, Recall: 0.7500\n",
            "[Train] Class 4: Precision: 0.3333, Recall: 0.0500\n",
            "Evaluating: 100%|| 25/25 [00:41<00:00,  1.67s/ batch]\n",
            "[Val] Kappa: 0.8434 Accuracy: 0.6700 Precision: 0.6144 Recall: 0.6700\n",
            "\n",
            "Epoch 5/20\n",
            "Training: 100%|| 75/75 [06:01<00:00,  4.81s/ batch, lr=1.0e-04, Loss=1.0519]\n",
            "[Train] Kappa: 0.7822 Accuracy: 0.6367 Precision: 0.6201 Recall: 0.6367 Loss: 0.9287\n",
            "[Train] Class 0: Precision: 0.8243, Recall: 0.9250\n",
            "[Train] Class 1: Precision: 0.5943, Recall: 0.6042\n",
            "[Train] Class 2: Precision: 0.4829, Recall: 0.4125\n",
            "[Train] Class 3: Precision: 0.5446, Recall: 0.7125\n",
            "[Train] Class 4: Precision: 0.4848, Recall: 0.1333\n",
            "Evaluating: 100%|| 25/25 [00:40<00:00,  1.60s/ batch]\n",
            "[Val] Kappa: 0.8444 Accuracy: 0.6650 Precision: 0.6007 Recall: 0.6650\n",
            "\n",
            "Epoch 6/20\n",
            "Training: 100%|| 75/75 [06:03<00:00,  4.85s/ batch, lr=1.0e-04, Loss=1.1041]\n",
            "[Train] Kappa: 0.7891 Accuracy: 0.6467 Precision: 0.6264 Recall: 0.6467 Loss: 0.9094\n",
            "[Train] Class 0: Precision: 0.8221, Recall: 0.9500\n",
            "[Train] Class 1: Precision: 0.6151, Recall: 0.6125\n",
            "[Train] Class 2: Precision: 0.5152, Recall: 0.4250\n",
            "[Train] Class 3: Precision: 0.5414, Recall: 0.7083\n",
            "[Train] Class 4: Precision: 0.4545, Recall: 0.1250\n",
            "Evaluating: 100%|| 25/25 [00:40<00:00,  1.60s/ batch]\n",
            "[Val] Kappa: 0.8314 Accuracy: 0.6650 Precision: 0.6270 Recall: 0.6650\n",
            "\n",
            "Epoch 7/20\n",
            "Training: 100%|| 75/75 [06:06<00:00,  4.88s/ batch, lr=1.0e-04, Loss=0.9371]\n",
            "[Train] Kappa: 0.8046 Accuracy: 0.6592 Precision: 0.6477 Recall: 0.6592 Loss: 0.8740\n",
            "[Train] Class 0: Precision: 0.8281, Recall: 0.9500\n",
            "[Train] Class 1: Precision: 0.6711, Recall: 0.6375\n",
            "[Train] Class 2: Precision: 0.4978, Recall: 0.4625\n",
            "[Train] Class 3: Precision: 0.5498, Recall: 0.6667\n",
            "[Train] Class 4: Precision: 0.5556, Recall: 0.2083\n",
            "Evaluating: 100%|| 25/25 [00:38<00:00,  1.53s/ batch]\n",
            "[Val] Kappa: 0.8261 Accuracy: 0.6900 Precision: 0.6950 Recall: 0.6900\n",
            "\n",
            "Epoch 8/20\n",
            "Training: 100%|| 75/75 [06:08<00:00,  4.92s/ batch, lr=1.0e-04, Loss=0.7964]\n",
            "[Train] Kappa: 0.7635 Accuracy: 0.6350 Precision: 0.6194 Recall: 0.6350 Loss: 0.9260\n",
            "[Train] Class 0: Precision: 0.8295, Recall: 0.8917\n",
            "[Train] Class 1: Precision: 0.6466, Recall: 0.6250\n",
            "[Train] Class 2: Precision: 0.4848, Recall: 0.4667\n",
            "[Train] Class 3: Precision: 0.5351, Recall: 0.6667\n",
            "[Train] Class 4: Precision: 0.3725, Recall: 0.1583\n",
            "Evaluating: 100%|| 25/25 [00:41<00:00,  1.65s/ batch]\n",
            "[Val] Kappa: 0.8542 Accuracy: 0.6900 Precision: 0.6797 Recall: 0.6900\n",
            "\n",
            "Epoch 9/20\n",
            "Training: 100%|| 75/75 [06:06<00:00,  4.88s/ batch, lr=1.0e-04, Loss=0.7335]\n",
            "[Train] Kappa: 0.7873 Accuracy: 0.6492 Precision: 0.6295 Recall: 0.6492 Loss: 0.8978\n",
            "[Train] Class 0: Precision: 0.8167, Recall: 0.9528\n",
            "[Train] Class 1: Precision: 0.6151, Recall: 0.6125\n",
            "[Train] Class 2: Precision: 0.4803, Recall: 0.4583\n",
            "[Train] Class 3: Precision: 0.6056, Recall: 0.6333\n",
            "[Train] Class 4: Precision: 0.4426, Recall: 0.2250\n",
            "Evaluating: 100%|| 25/25 [00:39<00:00,  1.57s/ batch]\n",
            "[Val] Kappa: 0.8504 Accuracy: 0.7100 Precision: 0.6961 Recall: 0.7100\n",
            "\n",
            "Epoch 10/20\n",
            "Training: 100%|| 75/75 [06:07<00:00,  4.91s/ batch, lr=1.0e-04, Loss=0.9977]\n",
            "[Train] Kappa: 0.8126 Accuracy: 0.6550 Precision: 0.6389 Recall: 0.6550 Loss: 0.8749\n",
            "[Train] Class 0: Precision: 0.8293, Recall: 0.9583\n",
            "[Train] Class 1: Precision: 0.6265, Recall: 0.6500\n",
            "[Train] Class 2: Precision: 0.5000, Recall: 0.3958\n",
            "[Train] Class 3: Precision: 0.5521, Recall: 0.6625\n",
            "[Train] Class 4: Precision: 0.5439, Recall: 0.2583\n",
            "Evaluating: 100%|| 25/25 [00:43<00:00,  1.76s/ batch]\n",
            "[Val] Kappa: 0.8283 Accuracy: 0.6850 Precision: 0.6587 Recall: 0.6850\n",
            "\n",
            "Epoch 11/20\n",
            "Training: 100%|| 75/75 [06:05<00:00,  4.87s/ batch, lr=1.0e-05, Loss=1.6623]\n",
            "[Train] Kappa: 0.7952 Accuracy: 0.6608 Precision: 0.6471 Recall: 0.6608 Loss: 0.8483\n",
            "[Train] Class 0: Precision: 0.8296, Recall: 0.9333\n",
            "[Train] Class 1: Precision: 0.6820, Recall: 0.6792\n",
            "[Train] Class 2: Precision: 0.4891, Recall: 0.4667\n",
            "[Train] Class 3: Precision: 0.5647, Recall: 0.6542\n",
            "[Train] Class 4: Precision: 0.5102, Recall: 0.2083\n",
            "Evaluating: 100%|| 25/25 [00:42<00:00,  1.70s/ batch]\n",
            "[Val] Kappa: 0.8304 Accuracy: 0.6825 Precision: 0.6613 Recall: 0.6825\n",
            "\n",
            "Epoch 12/20\n",
            "Training: 100%|| 75/75 [06:02<00:00,  4.84s/ batch, lr=1.0e-05, Loss=1.2440]\n",
            "[Train] Kappa: 0.7844 Accuracy: 0.6675 Precision: 0.6445 Recall: 0.6675 Loss: 0.8463\n",
            "[Train] Class 0: Precision: 0.8390, Recall: 0.9556\n",
            "[Train] Class 1: Precision: 0.6638, Recall: 0.6500\n",
            "[Train] Class 2: Precision: 0.5408, Recall: 0.5250\n",
            "[Train] Class 3: Precision: 0.5799, Recall: 0.6500\n",
            "[Train] Class 4: Precision: 0.3585, Recall: 0.1583\n",
            "Evaluating: 100%|| 25/25 [00:43<00:00,  1.73s/ batch]\n",
            "[Val] Kappa: 0.8251 Accuracy: 0.6850 Precision: 0.6656 Recall: 0.6850\n",
            "\n",
            "Epoch 13/20\n",
            "Training: 100%|| 75/75 [06:08<00:00,  4.91s/ batch, lr=1.0e-05, Loss=0.9595]\n",
            "[Train] Kappa: 0.8032 Accuracy: 0.6858 Precision: 0.6676 Recall: 0.6858 Loss: 0.8272\n",
            "[Train] Class 0: Precision: 0.8398, Recall: 0.9611\n",
            "[Train] Class 1: Precision: 0.6946, Recall: 0.6917\n",
            "[Train] Class 2: Precision: 0.5328, Recall: 0.5083\n",
            "[Train] Class 3: Precision: 0.6111, Recall: 0.6875\n",
            "[Train] Class 4: Precision: 0.4800, Recall: 0.2000\n",
            "Evaluating: 100%|| 25/25 [00:39<00:00,  1.59s/ batch]\n",
            "[Val] Kappa: 0.8337 Accuracy: 0.6825 Precision: 0.6594 Recall: 0.6825\n",
            "\n",
            "Epoch 14/20\n",
            "Training: 100%|| 75/75 [06:08<00:00,  4.92s/ batch, lr=1.0e-05, Loss=1.1778]\n",
            "[Train] Kappa: 0.7918 Accuracy: 0.6492 Precision: 0.6294 Recall: 0.6492 Loss: 0.8779\n",
            "[Train] Class 0: Precision: 0.8325, Recall: 0.9528\n",
            "[Train] Class 1: Precision: 0.6637, Recall: 0.6250\n",
            "[Train] Class 2: Precision: 0.5000, Recall: 0.4625\n",
            "[Train] Class 3: Precision: 0.5345, Recall: 0.6458\n",
            "[Train] Class 4: Precision: 0.4000, Recall: 0.1667\n",
            "Evaluating: 100%|| 25/25 [00:42<00:00,  1.69s/ batch]\n",
            "[Val] Kappa: 0.8510 Accuracy: 0.6975 Precision: 0.6746 Recall: 0.6975\n",
            "\n",
            "Epoch 15/20\n",
            "Training: 100%|| 75/75 [06:05<00:00,  4.88s/ batch, lr=1.0e-05, Loss=0.4717]\n",
            "[Train] Kappa: 0.8227 Accuracy: 0.6758 Precision: 0.6601 Recall: 0.6758 Loss: 0.8324\n",
            "[Train] Class 0: Precision: 0.8488, Recall: 0.9667\n",
            "[Train] Class 1: Precision: 0.6805, Recall: 0.6833\n",
            "[Train] Class 2: Precision: 0.4953, Recall: 0.4375\n",
            "[Train] Class 3: Precision: 0.5836, Recall: 0.6833\n",
            "[Train] Class 4: Precision: 0.5357, Recall: 0.2500\n",
            "Evaluating: 100%|| 25/25 [00:41<00:00,  1.68s/ batch]\n",
            "[Val] Kappa: 0.8424 Accuracy: 0.6925 Precision: 0.6748 Recall: 0.6925\n",
            "\n",
            "Epoch 16/20\n",
            "Training: 100%|| 75/75 [06:09<00:00,  4.92s/ batch, lr=1.0e-05, Loss=0.8985]\n",
            "[Train] Kappa: 0.7940 Accuracy: 0.6683 Precision: 0.6590 Recall: 0.6683 Loss: 0.8713\n",
            "[Train] Class 0: Precision: 0.8341, Recall: 0.9500\n",
            "[Train] Class 1: Precision: 0.6461, Recall: 0.6542\n",
            "[Train] Class 2: Precision: 0.4977, Recall: 0.4500\n",
            "[Train] Class 3: Precision: 0.5836, Recall: 0.6833\n",
            "[Train] Class 4: Precision: 0.6327, Recall: 0.2583\n",
            "Evaluating: 100%|| 25/25 [00:39<00:00,  1.59s/ batch]\n",
            "[Val] Kappa: 0.8484 Accuracy: 0.6925 Precision: 0.6695 Recall: 0.6925\n",
            "\n",
            "Epoch 17/20\n",
            "Training: 100%|| 75/75 [06:06<00:00,  4.89s/ batch, lr=1.0e-05, Loss=0.5249]\n",
            "[Train] Kappa: 0.8131 Accuracy: 0.6767 Precision: 0.6705 Recall: 0.6767 Loss: 0.8239\n",
            "[Train] Class 0: Precision: 0.8589, Recall: 0.9472\n",
            "[Train] Class 1: Precision: 0.6417, Recall: 0.6417\n",
            "[Train] Class 2: Precision: 0.4938, Recall: 0.4958\n",
            "[Train] Class 3: Precision: 0.6105, Recall: 0.6792\n",
            "[Train] Class 4: Precision: 0.6364, Recall: 0.2917\n",
            "Evaluating: 100%|| 25/25 [00:39<00:00,  1.58s/ batch]\n",
            "[Val] Kappa: 0.8437 Accuracy: 0.6850 Precision: 0.6640 Recall: 0.6850\n",
            "\n",
            "Epoch 18/20\n",
            "Training: 100%|| 75/75 [06:07<00:00,  4.90s/ batch, lr=1.0e-05, Loss=0.9624]\n",
            "[Train] Kappa: 0.8147 Accuracy: 0.6825 Precision: 0.6691 Recall: 0.6825 Loss: 0.8348\n",
            "[Train] Class 0: Precision: 0.8750, Recall: 0.9528\n",
            "[Train] Class 1: Precision: 0.6747, Recall: 0.7000\n",
            "[Train] Class 2: Precision: 0.5164, Recall: 0.4583\n",
            "[Train] Class 3: Precision: 0.5828, Recall: 0.7042\n",
            "[Train] Class 4: Precision: 0.5179, Recall: 0.2417\n",
            "Evaluating: 100%|| 25/25 [00:38<00:00,  1.54s/ batch]\n",
            "[Val] Kappa: 0.8427 Accuracy: 0.6875 Precision: 0.6680 Recall: 0.6875\n",
            "\n",
            "Epoch 19/20\n",
            "Training: 100%|| 75/75 [06:07<00:00,  4.90s/ batch, lr=1.0e-05, Loss=0.6343]\n",
            "[Train] Kappa: 0.7876 Accuracy: 0.6617 Precision: 0.6455 Recall: 0.6617 Loss: 0.8579\n",
            "[Train] Class 0: Precision: 0.8375, Recall: 0.9306\n",
            "[Train] Class 1: Precision: 0.6537, Recall: 0.6292\n",
            "[Train] Class 2: Precision: 0.5045, Recall: 0.4708\n",
            "[Train] Class 3: Precision: 0.5889, Recall: 0.7042\n",
            "[Train] Class 4: Precision: 0.4483, Recall: 0.2167\n",
            "Evaluating: 100%|| 25/25 [00:37<00:00,  1.50s/ batch]\n",
            "[Val] Kappa: 0.8459 Accuracy: 0.6875 Precision: 0.6680 Recall: 0.6875\n",
            "\n",
            "Epoch 20/20\n",
            "Training: 100%|| 75/75 [06:07<00:00,  4.90s/ batch, lr=1.0e-05, Loss=0.7704]\n",
            "[Train] Kappa: 0.8137 Accuracy: 0.6850 Precision: 0.6697 Recall: 0.6850 Loss: 0.8174\n",
            "[Train] Class 0: Precision: 0.8456, Recall: 0.9583\n",
            "[Train] Class 1: Precision: 0.6777, Recall: 0.6833\n",
            "[Train] Class 2: Precision: 0.5405, Recall: 0.5000\n",
            "[Train] Class 3: Precision: 0.6029, Recall: 0.6833\n",
            "[Train] Class 4: Precision: 0.5179, Recall: 0.2417\n",
            "Evaluating: 100%|| 25/25 [00:40<00:00,  1.60s/ batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-e95521dac2f2>:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('/content/drive/MyDrive/models/model8.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Kappa: 0.8426 Accuracy: 0.6850 Precision: 0.6650 Recall: 0.6850\n",
            "[Val] Best kappa: 0.8542, Epoch 8\n",
            "Evaluating: 100%|| 25/25 [00:41<00:00,  1.68s/ batch]\n",
            "[Test] Save predictions to /content/drive/MyDrive/Predictions/test_predictions8.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Now Try out different image preprocessing techniques such as, Ben Graham, Circle Cropping, CLAHE, adding gaussian blur, sharpening up the images etc.  Then see again if that has any effect on the model.\n",
        "\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "import torchvision.transforms.functional as TF\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# ... (Your existing code)\n",
        "\n",
        "def ben_graham_preprocessing(image):\n",
        "    # Convert to grayscale\n",
        "    gray = image.convert('L')\n",
        "\n",
        "    # Increase contrast (adjust factor as needed)\n",
        "    enhancer = ImageEnhance.Contrast(gray)\n",
        "    gray = enhancer.enhance(1.5)\n",
        "\n",
        "    return gray\n",
        "\n",
        "\n",
        "def circle_crop(image):\n",
        "    # Convert the image to a NumPy array\n",
        "    img_np = np.array(image)\n",
        "\n",
        "    # Get the dimensions of the image\n",
        "    height, width = img_np.shape[:2]\n",
        "\n",
        "    # Create a black mask of the same size as the image\n",
        "    mask = np.zeros((height, width), np.uint8)\n",
        "\n",
        "    # Draw a white circle in the center of the mask\n",
        "    center_x = width // 2\n",
        "    center_y = height // 2\n",
        "    radius = min(center_x, center_y)\n",
        "    cv2.circle(mask, (center_x, center_y), radius, (255, 255, 255), -1)\n",
        "\n",
        "    # Apply the mask to the image\n",
        "    masked_img = cv2.bitwise_and(img_np, img_np, mask=mask)\n",
        "\n",
        "    # Convert the masked image back to PIL format\n",
        "    masked_image = Image.fromarray(masked_img)\n",
        "\n",
        "    return masked_image\n",
        "\n",
        "def clahe_preprocessing(image):\n",
        "    # Convert PIL Image to OpenCV format\n",
        "    # img_np = np.array(image)\n",
        "    # lab = cv2.cvtColor(img_np, cv2.COLOR_RGB2LAB)  # Convert to LAB color space\n",
        "\n",
        "    # # Apply CLAHE\n",
        "    # lab_planes = cv2.split(lab)\n",
        "    # clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    # lab_planes[0] = clahe.apply(lab_planes[0])\n",
        "    # lab = cv2.merge(lab_planes)\n",
        "\n",
        "    # # Convert back to RGB\n",
        "    # img_rgb = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
        "    # # Convert back to PIL Image\n",
        "    # img = Image.fromarray(img_rgb)\n",
        "    # return img\n",
        "    image_np = np.array(image)\n",
        "    lab = cv2.cvtColor(image_np, cv2.COLOR_RGB2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    l = clahe.apply(l)\n",
        "    lab = cv2.merge((l, a, b))\n",
        "    image_np = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "    return Image.fromarray(image_np)\n",
        "\n",
        "\n",
        "\n",
        "def gaussian_blur_preprocessing(image):\n",
        "  # Apply Gaussian Blur\n",
        "  blurred_image = image.filter(ImageFilter.GaussianBlur(radius=1))\n",
        "  return blurred_image\n",
        "\n",
        "\n",
        "def sharpen_image(image):\n",
        "    # Create a sharpening kernel\n",
        "    kernel = np.array([[-1, -1, -1],\n",
        "                       [-1,  9, -1],\n",
        "                       [-1, -1, -1]])\n",
        "    # Apply the kernel to the image\n",
        "    img_np = np.array(image)\n",
        "    sharpened_img = cv2.filter2D(img_np, -1, kernel)\n",
        "\n",
        "    sharpened_image = Image.fromarray(sharpened_img)\n",
        "    return sharpened_image\n",
        "\n",
        "\n",
        "    # Example usage within your transform\n",
        "transform_train = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.RandomCrop((224, 224)),\n",
        "        SLORandomPad((224, 224)),\n",
        "        FundRandomRotate(prob=0.5, degree=30),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.ColorJitter(brightness=(0.1, 0.9)),\n",
        "        # transforms.Lambda(lambda img: ben_graham_preprocessing(img)), # Ben Graham\n",
        "        #transforms.Lambda(lambda img: circle_crop(img)), # Circle Cropping\n",
        "        # transforms.Lambda(lambda img: clahe_preprocessing(img)), # CLAHE\n",
        "        transforms.Lambda(lambda img: gaussian_blur_preprocessing(img)), #Gaussian Blur\n",
        "        #transforms.Lambda(lambda img: sharpen_image(img)), #Sharpening\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        #transforms.Lambda(lambda img: ben_graham_preprocessing(img)), # Ben Graham\n",
        "        #transforms.Lambda(lambda img: circle_crop(img)), # Circle Cropping\n",
        "        # transforms.Lambda(lambda img: clahe_preprocessing(img)), # CLAHE\n",
        "        transforms.Lambda(lambda img: gaussian_blur_preprocessing(img)), #Gaussian Blur\n",
        "        #transforms.Lambda(lambda img: sharpen_image(img)), #Sharpening\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "# ... (rest of your code)"
      ],
      "metadata": {
        "id": "brO5Ej6m2GR9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel_resnet18(nn.Module):\n",
        "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = models.resnet18(pretrained=True)\n",
        "        state_dict = torch.load('pretrained_DR_resize/pretrained/resnet18.pth', map_location='cpu')\n",
        "        info = self.backbone.load_state_dict(state_dict, strict=False)\n",
        "        print('missing keys:', info[0])  # The missing fc or classifier layer is normal here\n",
        "        print('unexpected keys:', info[1])\n",
        "\n",
        "        # self.backbone = models.resnet34(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained/resnet34.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.vgg16(pretrained=True)\n",
        "        # self.backbone.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # state_dict = torch.load('pretrained/vgg16.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.efficientnet_b0(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained/efficientnet_b0.pth', map_location='cpu')\n",
        "\n",
        "        # self.backbone = models.densenet121(pretrained=True)\n",
        "        # state_dict = torch.load('pretrained/densenet121.pth', map_location='cpu')\n",
        "        self.backbone.fc = nn.Identity()  # Remove the original classification layer\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=dropout_rate),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "xR1nvnEQ2Lm9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Choose between 'single image' and 'dual images' pipeline\n",
        "    # This will affect the model definition, dataset pipeline, training and evaluation\n",
        "\n",
        "    mode = 'single'  # forward single image to the model each time\n",
        "    # mode = 'dual'  # forward two images of the same eye to the model and fuse the features\n",
        "\n",
        "    assert mode in ('single', 'dual')\n",
        "\n",
        "    # Define the model\n",
        "    if mode == 'single':\n",
        "        model = MyModel_resnet18()\n",
        "    else:\n",
        "        model = MyDualModel()\n",
        "\n",
        "    print(model, '\\n')\n",
        "    print('Pipeline Mode:', mode)\n",
        "\n",
        "    # tuned Hyper Parameters\n",
        "    batch_size = 16\n",
        "    num_classes = 5  # 5 DR levels\n",
        "    learning_rate = 0.0001\n",
        "    num_epochs = 20\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = RetinopathyDataset('/content/DeepDRiD/train.csv', '/content/DeepDRiD/train', transform_train, mode)\n",
        "    val_dataset = RetinopathyDataset('/content/DeepDRiD/val.csv', '/content/DeepDRiD/val/', transform_test, mode)\n",
        "    test_dataset = RetinopathyDataset('/content/DeepDRiD/test.csv', '/content/DeepDRiD/test', transform_test, mode, test=True)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "    # Define the weighted CrossEntropyLoss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Use GPU device is possible\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print('Device:', device)\n",
        "\n",
        "    # Move class weights to the device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Optimizer and Learning rate scheduler\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "     # Train and evaluate the model with the training and validation set\n",
        "    model = train_model(\n",
        "        model, train_loader, val_loader, device, criterion, optimizer,\n",
        "        lr_scheduler=lr_scheduler, num_epochs=num_epochs,\n",
        "        checkpoint_path='/content/drive/MyDrive/models/model9.pth'\n",
        "    )\n",
        "\n",
        "    # Load the pretrained checkpoint\n",
        "    state_dict = torch.load('/content/drive/MyDrive/models/model9.pth', map_location='cpu')\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Make predictions on testing set and save the prediction results\n",
        "    evaluate_model(model, test_loader, device, test_only=True, prediction_path='/content/drive/MyDrive/Predictions/test_predictions9.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXTKZiAp2OKA",
        "outputId": "01b75578-ebef-43f0-8d94-2175081e746d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-34-77729cf7f76f>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('pretrained_DR_resize/pretrained/resnet18.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing keys: ['fc.weight', 'fc.bias']\n",
            "unexpected keys: []\n",
            "MyModel_resnet18(\n",
            "  (backbone): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
            "  )\n",
            ") \n",
            "\n",
            "Pipeline Mode: single\n",
            "Device: cpu\n",
            "\n",
            "Epoch 1/20\n",
            "Training: 100%|| 75/75 [06:03<00:00,  4.84s/ batch, lr=1.0e-04, Loss=1.0350]\n",
            "[Train] Kappa: 0.5414 Accuracy: 0.4617 Precision: 0.4028 Recall: 0.4617 Loss: 1.3554\n",
            "[Train] Class 0: Precision: 0.5577, Recall: 0.8861\n",
            "[Train] Class 1: Precision: 0.3827, Recall: 0.1292\n",
            "[Train] Class 2: Precision: 0.3143, Recall: 0.2750\n",
            "[Train] Class 3: Precision: 0.4277, Recall: 0.5667\n",
            "[Train] Class 4: Precision: 0.1053, Recall: 0.0167\n",
            "Evaluating: 100%|| 25/25 [00:39<00:00,  1.59s/ batch]\n",
            "[Val] Kappa: 0.7943 Accuracy: 0.6250 Precision: 0.5505 Recall: 0.6250\n",
            "\n",
            "Epoch 2/20\n",
            "Training: 100%|| 75/75 [06:04<00:00,  4.86s/ batch, lr=1.0e-04, Loss=0.9066]\n",
            "[Train] Kappa: 0.7538 Accuracy: 0.6175 Precision: 0.5480 Recall: 0.6175 Loss: 1.0692\n",
            "[Train] Class 0: Precision: 0.7825, Recall: 0.9194\n",
            "[Train] Class 1: Precision: 0.5560, Recall: 0.6000\n",
            "[Train] Class 2: Precision: 0.4788, Recall: 0.3292\n",
            "[Train] Class 3: Precision: 0.5312, Recall: 0.7792\n",
            "[Train] Class 4: Precision: 0.0000, Recall: 0.0000\n",
            "Evaluating: 100%|| 25/25 [00:38<00:00,  1.54s/ batch]\n",
            "[Val] Kappa: 0.7768 Accuracy: 0.6175 Precision: 0.5364 Recall: 0.6175\n",
            "\n",
            "Epoch 3/20\n",
            "Training: 100%|| 75/75 [06:03<00:00,  4.85s/ batch, lr=1.0e-04, Loss=0.7295]\n",
            "[Train] Kappa: 0.7941 Accuracy: 0.6433 Precision: 0.5982 Recall: 0.6433 Loss: 0.9368\n",
            "[Train] Class 0: Precision: 0.8203, Recall: 0.9639\n",
            "[Train] Class 1: Precision: 0.6524, Recall: 0.5708\n",
            "[Train] Class 2: Precision: 0.4422, Recall: 0.4625\n",
            "[Train] Class 3: Precision: 0.5659, Recall: 0.7333\n",
            "[Train] Class 4: Precision: 0.2000, Recall: 0.0083\n",
            "Evaluating: 100%|| 25/25 [00:43<00:00,  1.74s/ batch]\n",
            "[Val] Kappa: 0.7938 Accuracy: 0.6450 Precision: 0.5661 Recall: 0.6450\n",
            "\n",
            "Epoch 4/20\n",
            "Training: 100%|| 75/75 [06:01<00:00,  4.83s/ batch, lr=1.0e-04, Loss=1.5991]\n",
            "[Train] Kappa: 0.7912 Accuracy: 0.6533 Precision: 0.6218 Recall: 0.6533 Loss: 0.9196\n",
            "[Train] Class 0: Precision: 0.8305, Recall: 0.9389\n",
            "[Train] Class 1: Precision: 0.6562, Recall: 0.7000\n",
            "[Train] Class 2: Precision: 0.5233, Recall: 0.3750\n",
            "[Train] Class 3: Precision: 0.5260, Recall: 0.7583\n",
            "[Train] Class 4: Precision: 0.3158, Recall: 0.0500\n",
            "Evaluating: 100%|| 25/25 [00:41<00:00,  1.67s/ batch]\n",
            "[Val] Kappa: 0.7831 Accuracy: 0.6550 Precision: 0.6794 Recall: 0.6550\n",
            "\n",
            "Epoch 5/20\n",
            "Training: 100%|| 75/75 [06:02<00:00,  4.83s/ batch, lr=1.0e-04, Loss=0.9290]\n",
            "[Train] Kappa: 0.7885 Accuracy: 0.6358 Precision: 0.6014 Recall: 0.6358 Loss: 0.9101\n",
            "[Train] Class 0: Precision: 0.8431, Recall: 0.9556\n",
            "[Train] Class 1: Precision: 0.6234, Recall: 0.6000\n",
            "[Train] Class 2: Precision: 0.4237, Recall: 0.4167\n",
            "[Train] Class 3: Precision: 0.5700, Recall: 0.6958\n",
            "[Train] Class 4: Precision: 0.2500, Recall: 0.0667\n",
            "Evaluating: 100%|| 25/25 [00:38<00:00,  1.55s/ batch]\n",
            "[Val] Kappa: 0.8366 Accuracy: 0.6950 Precision: 0.6268 Recall: 0.6950\n",
            "\n",
            "Epoch 6/20\n",
            "Training: 100%|| 75/75 [06:12<00:00,  4.97s/ batch, lr=1.0e-04, Loss=0.8602]\n",
            "[Train] Kappa: 0.7970 Accuracy: 0.6458 Precision: 0.6274 Recall: 0.6458 Loss: 0.8679\n",
            "[Train] Class 0: Precision: 0.8384, Recall: 0.9222\n",
            "[Train] Class 1: Precision: 0.6550, Recall: 0.6250\n",
            "[Train] Class 2: Precision: 0.4706, Recall: 0.4333\n",
            "[Train] Class 3: Precision: 0.5578, Recall: 0.7042\n",
            "[Train] Class 4: Precision: 0.3922, Recall: 0.1667\n",
            "Evaluating: 100%|| 25/25 [00:39<00:00,  1.59s/ batch]\n",
            "[Val] Kappa: 0.8433 Accuracy: 0.6900 Precision: 0.7162 Recall: 0.6900\n",
            "\n",
            "Epoch 7/20\n",
            "Training: 100%|| 75/75 [06:04<00:00,  4.86s/ batch, lr=1.0e-04, Loss=0.6979]\n",
            "[Train] Kappa: 0.8127 Accuracy: 0.6550 Precision: 0.6390 Recall: 0.6550 Loss: 0.8629\n",
            "[Train] Class 0: Precision: 0.8582, Recall: 0.9417\n",
            "[Train] Class 1: Precision: 0.6754, Recall: 0.6417\n",
            "[Train] Class 2: Precision: 0.4928, Recall: 0.4292\n",
            "[Train] Class 3: Precision: 0.5529, Recall: 0.6750\n",
            "[Train] Class 4: Precision: 0.3733, Recall: 0.2333\n",
            "Evaluating: 100%|| 25/25 [00:42<00:00,  1.69s/ batch]\n",
            "[Val] Kappa: 0.8300 Accuracy: 0.6975 Precision: 0.6992 Recall: 0.6975\n",
            "\n",
            "Epoch 8/20\n",
            "Training: 100%|| 75/75 [06:02<00:00,  4.83s/ batch, lr=1.0e-04, Loss=0.7158]\n",
            "[Train] Kappa: 0.7989 Accuracy: 0.6600 Precision: 0.6401 Recall: 0.6600 Loss: 0.8622\n",
            "[Train] Class 0: Precision: 0.8358, Recall: 0.9472\n",
            "[Train] Class 1: Precision: 0.6375, Recall: 0.6667\n",
            "[Train] Class 2: Precision: 0.4975, Recall: 0.4167\n",
            "[Train] Class 3: Precision: 0.5773, Recall: 0.7000\n",
            "[Train] Class 4: Precision: 0.4694, Recall: 0.1917\n",
            "Evaluating: 100%|| 25/25 [00:38<00:00,  1.54s/ batch]\n",
            "[Val] Kappa: 0.7977 Accuracy: 0.6775 Precision: 0.6506 Recall: 0.6775\n",
            "\n",
            "Epoch 9/20\n",
            "Training: 100%|| 75/75 [06:04<00:00,  4.86s/ batch, lr=1.0e-04, Loss=0.5739]\n",
            "[Train] Kappa: 0.8189 Accuracy: 0.6692 Precision: 0.6458 Recall: 0.6692 Loss: 0.8357\n",
            "[Train] Class 0: Precision: 0.8386, Recall: 0.9528\n",
            "[Train] Class 1: Precision: 0.6747, Recall: 0.7000\n",
            "[Train] Class 2: Precision: 0.5385, Recall: 0.4667\n",
            "[Train] Class 3: Precision: 0.5601, Recall: 0.6792\n",
            "[Train] Class 4: Precision: 0.3953, Recall: 0.1417\n",
            "Evaluating: 100%|| 25/25 [00:41<00:00,  1.65s/ batch]\n",
            "[Val] Kappa: 0.8362 Accuracy: 0.6800 Precision: 0.6533 Recall: 0.6800\n",
            "\n",
            "Epoch 10/20\n",
            "Training: 100%|| 75/75 [05:59<00:00,  4.79s/ batch, lr=1.0e-04, Loss=0.9607]\n",
            "[Train] Kappa: 0.8341 Accuracy: 0.6992 Precision: 0.6858 Recall: 0.6992 Loss: 0.7890\n",
            "[Train] Class 0: Precision: 0.8625, Recall: 0.9583\n",
            "[Train] Class 1: Precision: 0.7244, Recall: 0.6792\n",
            "[Train] Class 2: Precision: 0.5625, Recall: 0.5250\n",
            "[Train] Class 3: Precision: 0.6063, Recall: 0.7250\n",
            "[Train] Class 4: Precision: 0.4844, Recall: 0.2583\n",
            "Evaluating: 100%|| 25/25 [00:39<00:00,  1.59s/ batch]\n",
            "[Val] Kappa: 0.7998 Accuracy: 0.6550 Precision: 0.6315 Recall: 0.6550\n",
            "\n",
            "Epoch 11/20\n",
            "Training: 100%|| 75/75 [05:59<00:00,  4.79s/ batch, lr=1.0e-05, Loss=0.7536]\n",
            "[Train] Kappa: 0.8414 Accuracy: 0.7083 Precision: 0.6971 Recall: 0.7083 Loss: 0.7826\n",
            "[Train] Class 0: Precision: 0.8561, Recall: 0.9583\n",
            "[Train] Class 1: Precision: 0.7261, Recall: 0.6958\n",
            "[Train] Class 2: Precision: 0.5766, Recall: 0.5333\n",
            "[Train] Class 3: Precision: 0.6336, Recall: 0.6917\n",
            "[Train] Class 4: Precision: 0.5301, Recall: 0.3667\n",
            "Evaluating: 100%|| 25/25 [00:41<00:00,  1.66s/ batch]\n",
            "[Val] Kappa: 0.8273 Accuracy: 0.6775 Precision: 0.6546 Recall: 0.6775\n",
            "\n",
            "Epoch 12/20\n",
            "Training: 100%|| 75/75 [06:15<00:00,  5.00s/ batch, lr=1.0e-05, Loss=1.0390]\n",
            "[Train] Kappa: 0.8359 Accuracy: 0.6975 Precision: 0.6850 Recall: 0.6975 Loss: 0.8089\n",
            "[Train] Class 0: Precision: 0.8737, Recall: 0.9611\n",
            "[Train] Class 1: Precision: 0.7387, Recall: 0.6833\n",
            "[Train] Class 2: Precision: 0.5429, Recall: 0.5542\n",
            "[Train] Class 3: Precision: 0.6136, Recall: 0.6750\n",
            "[Train] Class 4: Precision: 0.4384, Recall: 0.2667\n",
            "Evaluating: 100%|| 25/25 [00:43<00:00,  1.73s/ batch]\n",
            "[Val] Kappa: 0.8472 Accuracy: 0.6850 Precision: 0.6560 Recall: 0.6850\n",
            "\n",
            "Epoch 13/20\n",
            "Training: 100%|| 75/75 [06:22<00:00,  5.10s/ batch, lr=1.0e-05, Loss=1.0029]\n",
            "[Train] Kappa: 0.8519 Accuracy: 0.7033 Precision: 0.6919 Recall: 0.7033 Loss: 0.7795\n",
            "[Train] Class 0: Precision: 0.8673, Recall: 0.9806\n",
            "[Train] Class 1: Precision: 0.7342, Recall: 0.6792\n",
            "[Train] Class 2: Precision: 0.5517, Recall: 0.5333\n",
            "[Train] Class 3: Precision: 0.6053, Recall: 0.6708\n",
            "[Train] Class 4: Precision: 0.5342, Recall: 0.3250\n",
            "Evaluating: 100%|| 25/25 [00:42<00:00,  1.69s/ batch]\n",
            "[Val] Kappa: 0.8408 Accuracy: 0.6900 Precision: 0.6639 Recall: 0.6900\n",
            "\n",
            "Epoch 14/20\n",
            "Training: 100%|| 75/75 [06:06<00:00,  4.88s/ batch, lr=1.0e-05, Loss=0.7674]\n",
            "[Train] Kappa: 0.8224 Accuracy: 0.7000 Precision: 0.6845 Recall: 0.7000 Loss: 0.8122\n",
            "[Train] Class 0: Precision: 0.8869, Recall: 0.9583\n",
            "[Train] Class 1: Precision: 0.7202, Recall: 0.7292\n",
            "[Train] Class 2: Precision: 0.5545, Recall: 0.5083\n",
            "[Train] Class 3: Precision: 0.5986, Recall: 0.7083\n",
            "[Train] Class 4: Precision: 0.4375, Recall: 0.2333\n",
            "Evaluating: 100%|| 25/25 [00:39<00:00,  1.56s/ batch]\n",
            "[Val] Kappa: 0.8511 Accuracy: 0.6950 Precision: 0.6618 Recall: 0.6950\n",
            "\n",
            "Epoch 15/20\n",
            "Training: 100%|| 75/75 [06:02<00:00,  4.84s/ batch, lr=1.0e-05, Loss=0.8401]\n",
            "[Train] Kappa: 0.8429 Accuracy: 0.6975 Precision: 0.6854 Recall: 0.6975 Loss: 0.7610\n",
            "[Train] Class 0: Precision: 0.8878, Recall: 0.9667\n",
            "[Train] Class 1: Precision: 0.7155, Recall: 0.7125\n",
            "[Train] Class 2: Precision: 0.5254, Recall: 0.5167\n",
            "[Train] Class 3: Precision: 0.6109, Recall: 0.6542\n",
            "[Train] Class 4: Precision: 0.4868, Recall: 0.3083\n",
            "Evaluating: 100%|| 25/25 [00:40<00:00,  1.63s/ batch]\n",
            "[Val] Kappa: 0.8267 Accuracy: 0.6675 Precision: 0.6358 Recall: 0.6675\n",
            "\n",
            "Epoch 16/20\n",
            "Training: 100%|| 75/75 [06:02<00:00,  4.83s/ batch, lr=1.0e-05, Loss=0.3769]\n",
            "[Train] Kappa: 0.8413 Accuracy: 0.6967 Precision: 0.6841 Recall: 0.6967 Loss: 0.7770\n",
            "[Train] Class 0: Precision: 0.8728, Recall: 0.9528\n",
            "[Train] Class 1: Precision: 0.6883, Recall: 0.7083\n",
            "[Train] Class 2: Precision: 0.5367, Recall: 0.4875\n",
            "[Train] Class 3: Precision: 0.6332, Recall: 0.6833\n",
            "[Train] Class 4: Precision: 0.5060, Recall: 0.3500\n",
            "Evaluating: 100%|| 25/25 [00:42<00:00,  1.70s/ batch]\n",
            "[Val] Kappa: 0.8398 Accuracy: 0.6775 Precision: 0.6420 Recall: 0.6775\n",
            "\n",
            "Epoch 17/20\n",
            "Training: 100%|| 75/75 [06:01<00:00,  4.82s/ batch, lr=1.0e-05, Loss=0.6995]\n",
            "[Train] Kappa: 0.8402 Accuracy: 0.6983 Precision: 0.6860 Recall: 0.6983 Loss: 0.7718\n",
            "[Train] Class 0: Precision: 0.8504, Recall: 0.9472\n",
            "[Train] Class 1: Precision: 0.7212, Recall: 0.6792\n",
            "[Train] Class 2: Precision: 0.5739, Recall: 0.5500\n",
            "[Train] Class 3: Precision: 0.6049, Recall: 0.7208\n",
            "[Train] Class 4: Precision: 0.5088, Recall: 0.2417\n",
            "Evaluating: 100%|| 25/25 [00:38<00:00,  1.54s/ batch]\n",
            "[Val] Kappa: 0.8508 Accuracy: 0.7000 Precision: 0.6758 Recall: 0.7000\n",
            "\n",
            "Epoch 18/20\n",
            "Training: 100%|| 75/75 [06:00<00:00,  4.80s/ batch, lr=1.0e-05, Loss=0.9561]\n",
            "[Train] Kappa: 0.8426 Accuracy: 0.7108 Precision: 0.7033 Recall: 0.7108 Loss: 0.7457\n",
            "[Train] Class 0: Precision: 0.8636, Recall: 0.9500\n",
            "[Train] Class 1: Precision: 0.7241, Recall: 0.7000\n",
            "[Train] Class 2: Precision: 0.5316, Recall: 0.5250\n",
            "[Train] Class 3: Precision: 0.6553, Recall: 0.7208\n",
            "[Train] Class 4: Precision: 0.6197, Recall: 0.3667\n",
            "Evaluating: 100%|| 25/25 [00:40<00:00,  1.61s/ batch]\n",
            "[Val] Kappa: 0.8428 Accuracy: 0.6875 Precision: 0.6531 Recall: 0.6875\n",
            "\n",
            "Epoch 19/20\n",
            "Training: 100%|| 75/75 [06:02<00:00,  4.83s/ batch, lr=1.0e-05, Loss=0.8553]\n",
            "[Train] Kappa: 0.8468 Accuracy: 0.6967 Precision: 0.6838 Recall: 0.6967 Loss: 0.7439\n",
            "[Train] Class 0: Precision: 0.8763, Recall: 0.9639\n",
            "[Train] Class 1: Precision: 0.7500, Recall: 0.7125\n",
            "[Train] Class 2: Precision: 0.5642, Recall: 0.5125\n",
            "[Train] Class 3: Precision: 0.5739, Recall: 0.6792\n",
            "[Train] Class 4: Precision: 0.4324, Recall: 0.2667\n",
            "Evaluating: 100%|| 25/25 [00:38<00:00,  1.53s/ batch]\n",
            "[Val] Kappa: 0.8462 Accuracy: 0.6825 Precision: 0.6482 Recall: 0.6825\n",
            "\n",
            "Epoch 20/20\n",
            "Training: 100%|| 75/75 [06:03<00:00,  4.85s/ batch, lr=1.0e-05, Loss=0.8107]\n",
            "[Train] Kappa: 0.8361 Accuracy: 0.7200 Precision: 0.7080 Recall: 0.7200 Loss: 0.7367\n",
            "[Train] Class 0: Precision: 0.8737, Recall: 0.9611\n",
            "[Train] Class 1: Precision: 0.7061, Recall: 0.7208\n",
            "[Train] Class 2: Precision: 0.5901, Recall: 0.5458\n",
            "[Train] Class 3: Precision: 0.6498, Recall: 0.7500\n",
            "[Train] Class 4: Precision: 0.5667, Recall: 0.2833\n",
            "Evaluating: 100%|| 25/25 [00:40<00:00,  1.64s/ batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-88427ea331ec>:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('/content/drive/MyDrive/models/model9.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Val] Kappa: 0.8430 Accuracy: 0.6875 Precision: 0.6584 Recall: 0.6875\n",
            "[Val] Best kappa: 0.8511, Epoch 14\n",
            "Evaluating: 100%|| 25/25 [00:42<00:00,  1.70s/ batch]\n",
            "[Test] Save predictions to /content/drive/MyDrive/Predictions/test_predictions9.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs,\n",
        "                checkpoint_path):\n",
        "    train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []  # Add these lists\n",
        "\n",
        "    best_model = model.state_dict()\n",
        "    best_val_kappa = -1.0\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        model.train()\n",
        "        running_loss, all_preds, all_labels = [], [], []\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            running_loss.append(loss.item())\n",
        "\n",
        "        lr_scheduler.step()\n",
        "        epoch_loss = sum(running_loss) / len(running_loss)\n",
        "        train_losses.append(epoch_loss)\n",
        "\n",
        "        accuracy = sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
        "        train_accuracies.append(accuracy)\n",
        "\n",
        "        val_metrics = evaluate_model(model, val_loader, device)\n",
        "        val_losses.append(sum(val_metrics) / len(val_metrics))\n",
        "        val_accuracies.append(val_metrics[1])  # Assuming accuracy is at index 1\n",
        "\n",
        "        print(f'Epoch {epoch}/{num_epochs} - Train Loss: {epoch_loss:.4f}, Train Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    return model, train_losses, val_losses, train_accuracies, val_accuracies\n"
      ],
      "metadata": {
        "id": "rA9dcIMDnU2I"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label='Train Loss')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, label='Train Accuracy')\n",
        "    plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "YMW2Gv2Tndjs"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "mode = 'single'\n",
        "if mode == 'single':\n",
        "    model = MyModel_resnet18(num_classes=5)  # Ensure MyModel_resnet18 is defined as per your previous code\n",
        "else:\n",
        "    model = MyDualModel()\n",
        "\n",
        "print(model)\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 16\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 20\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = RetinopathyDataset('/content/DeepDRiD/train.csv', '/content/DeepDRiD/train', transform_train, mode)\n",
        "val_dataset = RetinopathyDataset('/content/DeepDRiD/val.csv', '/content/DeepDRiD/val', transform_test, mode)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define the loss function, optimizer, and scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "# Train the model\n",
        "model, train_losses, val_losses, train_accuracies, val_accuracies = train_model(\n",
        "    model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=num_epochs,\n",
        "    checkpoint_path='/content/drive/MyDrive/models/model9.pth'\n",
        ")\n",
        "\n",
        "# Plot the training and validation curves\n",
        "plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k_YuJ6OZnz1-",
        "outputId": "28211607-53e6-4116-9357-c0c646ade8f4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|| 44.7M/44.7M [00:00<00:00, 66.5MB/s]\n",
            "<ipython-input-33-77729cf7f76f>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('pretrained_DR_resize/pretrained/resnet18.pth', map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing keys: ['fc.weight', 'fc.bias']\n",
            "unexpected keys: []\n",
            "MyModel_resnet18(\n",
            "  (backbone): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Identity()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=128, out_features=5, bias=True)\n",
            "  )\n",
            ")\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.37 batch/s]\n",
            "Epoch 1/20 - Train Loss: 1.3852, Train Accuracy: 0.4217\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.42 batch/s]\n",
            "Epoch 2/20 - Train Loss: 1.0763, Train Accuracy: 0.5942\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.61 batch/s]\n",
            "Epoch 3/20 - Train Loss: 0.9842, Train Accuracy: 0.6233\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.33 batch/s]\n",
            "Epoch 4/20 - Train Loss: 0.9047, Train Accuracy: 0.6417\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.33 batch/s]\n",
            "Epoch 5/20 - Train Loss: 0.8600, Train Accuracy: 0.6600\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.32 batch/s]\n",
            "Epoch 6/20 - Train Loss: 0.8939, Train Accuracy: 0.6567\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.37 batch/s]\n",
            "Epoch 7/20 - Train Loss: 0.8644, Train Accuracy: 0.6792\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.51 batch/s]\n",
            "Epoch 8/20 - Train Loss: 0.8245, Train Accuracy: 0.6733\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.62 batch/s]\n",
            "Epoch 9/20 - Train Loss: 0.8244, Train Accuracy: 0.6783\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  8.05 batch/s]\n",
            "Epoch 10/20 - Train Loss: 0.8234, Train Accuracy: 0.6767\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.55 batch/s]\n",
            "Epoch 11/20 - Train Loss: 0.7719, Train Accuracy: 0.7008\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.47 batch/s]\n",
            "Epoch 12/20 - Train Loss: 0.7623, Train Accuracy: 0.7042\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.68 batch/s]\n",
            "Epoch 13/20 - Train Loss: 0.7262, Train Accuracy: 0.7233\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.07 batch/s]\n",
            "Epoch 14/20 - Train Loss: 0.7622, Train Accuracy: 0.7108\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.19 batch/s]\n",
            "Epoch 15/20 - Train Loss: 0.7634, Train Accuracy: 0.6975\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.20 batch/s]\n",
            "Epoch 16/20 - Train Loss: 0.7983, Train Accuracy: 0.6992\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.08 batch/s]\n",
            "Epoch 17/20 - Train Loss: 0.7421, Train Accuracy: 0.7208\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.33 batch/s]\n",
            "Epoch 18/20 - Train Loss: 0.7538, Train Accuracy: 0.7133\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.46 batch/s]\n",
            "Epoch 19/20 - Train Loss: 0.7153, Train Accuracy: 0.7325\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.31 batch/s]\n",
            "Epoch 20/20 - Train Loss: 0.7438, Train Accuracy: 0.7125\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, train_losses, val_losses, train_accuracies, val_accuracies = train_model(\n",
        "    model, train_loader, val_loader, device, criterion, optimizer, lr_scheduler, num_epochs=num_epochs,\n",
        "    checkpoint_path='/content/drive/MyDrive/models/model9.pth'\n",
        ")\n",
        "\n",
        "plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rirUaAqWnjXE",
        "outputId": "366f49a6-7015-424d-ce6f-221dbdb991a7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.50 batch/s]\n",
            "Epoch 1/20 - Train Loss: 0.7633, Train Accuracy: 0.7142\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.60 batch/s]\n",
            "Epoch 2/20 - Train Loss: 0.7280, Train Accuracy: 0.7242\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  8.47 batch/s]\n",
            "Epoch 3/20 - Train Loss: 0.7474, Train Accuracy: 0.7133\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.03 batch/s]\n",
            "Epoch 4/20 - Train Loss: 0.7231, Train Accuracy: 0.7242\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.43 batch/s]\n",
            "Epoch 5/20 - Train Loss: 0.7550, Train Accuracy: 0.7075\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.41 batch/s]\n",
            "Epoch 6/20 - Train Loss: 0.7398, Train Accuracy: 0.7108\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.05 batch/s]\n",
            "Epoch 7/20 - Train Loss: 0.7297, Train Accuracy: 0.7192\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.27 batch/s]\n",
            "Epoch 8/20 - Train Loss: 0.7435, Train Accuracy: 0.7150\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.07 batch/s]\n",
            "Epoch 9/20 - Train Loss: 0.7727, Train Accuracy: 0.7058\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.54 batch/s]\n",
            "Epoch 10/20 - Train Loss: 0.7823, Train Accuracy: 0.7067\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.03 batch/s]\n",
            "Epoch 11/20 - Train Loss: 0.7286, Train Accuracy: 0.7133\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.27 batch/s]\n",
            "Epoch 12/20 - Train Loss: 0.7625, Train Accuracy: 0.7158\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  8.25 batch/s]\n",
            "Epoch 13/20 - Train Loss: 0.7488, Train Accuracy: 0.7050\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.38 batch/s]\n",
            "Epoch 14/20 - Train Loss: 0.7677, Train Accuracy: 0.7000\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.46 batch/s]\n",
            "Epoch 15/20 - Train Loss: 0.7238, Train Accuracy: 0.7117\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00,  9.62 batch/s]\n",
            "Epoch 16/20 - Train Loss: 0.7276, Train Accuracy: 0.7050\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.10 batch/s]\n",
            "Epoch 17/20 - Train Loss: 0.7287, Train Accuracy: 0.7242\n",
            "Evaluating: 100%|| 25/25 [00:03<00:00,  7.95 batch/s]\n",
            "Epoch 18/20 - Train Loss: 0.7760, Train Accuracy: 0.7033\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.44 batch/s]\n",
            "Epoch 19/20 - Train Loss: 0.7871, Train Accuracy: 0.6967\n",
            "Evaluating: 100%|| 25/25 [00:02<00:00, 10.16 batch/s]\n",
            "Epoch 20/20 - Train Loss: 0.7345, Train Accuracy: 0.7108\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}